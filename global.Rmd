---
title: "Students Performance Factors"
author: 
  - "Jairo González Hernández"
  - "Mathis Goujon"
  - "Claudia Teresa Heredia Ceballos"
  - "Pedro López Ruz"
  - "José Antonio Medina García"
---

# Students Performance Factors

**Trabajo Final Data Science**

*Master en Ingeniería del Software: Cloud, Datos y Gestión de TI*

## Descripción del dominio

El rendimiento académico es un tema clave en la educación, ya que influye directamente en las oportunidades que tendrán los jovenes en el día de mañana y en el desarrollo de nuestra sociedad. Comprender qué factores afectan al desempeño de los estudiantes permitirá a las instituciones educativas a mejorar los métodos de enseñanza, diseñar políticas educativas más efectivas y proporcionar un mayor apoyo a aquellos estudiantes que lo necesiten.

### Enfoque del Trabajo

Este estudio analiza los factores que influyen en el rendimiento académico de los estudiantes. Para ello, se hace uso de datos relacionados con aspectos personales, sociales y académicos para identificar patrones y determinar qué variables tienen mayor impacto en el desempeño escolar.

En particular, el estudio se enfoca en responder dos preguntas fundamentales:

1.  **¿Se pueden agrupar a los estudiantes en una clase según sus características?**\
    La organización de los estudiantes dentro del aula puede influir significativamente en su aprendizaje y rendimiento. Por esta razón, se explorará la posibilidad de segmentar a los alumnos con base en características clave como sus calificaciones previas, el tiempo dedicado al estudio, su nivel de motivación, la presencia de discapacidades de aprendizaje y su participación en actividades extracurriculares.

    Este enfoque permitirá una distribución estratégica que potencie el aprendizaje al ubicar a los estudiantes en entornos que favorezcan su desarrollo académico y personal.

2.  **¿Cuántas horas de trabajo personal necesita un estudiante para obtener una alta calificación?**\
    Otro objetivo del estudio es determinar cuántas horas diarias de estudio autónomo son necesarias para que un estudiante alcance una calificación alta (entre 8 y 10). Para ello, se identificarán aquellos factores que tengan mayor influencia con la calificación del estudiante, ya que estos aspectos pueden influir en el rendimiento académico. A través de un modelo de regresión, se buscará cuantificar la relación entre estas variables y el desempeño estudiantil, proporcionando una guía para optimizar los hábitos de estudio.

A través de este análisis, se pretende aportar información valiosa para mejorar las estrategias educativas, optimizar la distribución de los estudiantes en el aula y ofrecer recomendaciones que permitan a los alumnos maximizar su rendimiento académico.

### Interés y motivación del estudio

El mundo en el que vivimos está en constante transformación. Los sistemas educativos, como muchos otros aspectos de nuestra sociedad, deben adaptarse a nuevas realidades y desafíos. En este contexto, resulta crucial comprender los factores que influyen en el rendimiento académico de los estudiantes, con el objetivo de mejorar los procesos de enseñanza y crear un entorno de aprendizaje más inclusivo y eficaz. Lo interesante de este estudio radica en identificar patrones y relaciones entre distintas variables que podrían tener un impacto directo en la forma en que los estudiantes aprenden y se desarrollan.

En particular, nos gustaría subrayar que el rendimiento académico no depende únicamente de la capacidad intelectual del estudiante, sino también de factores como el apoyo familiar, los hábitos de estudio, la motivación personal y la presencia de discapacidades de aprendizaje. Este enfoque permite adoptar una perspectiva más personalizada de la educación, lo que a su vez puede contribuir a una mejor planificación y diseño de estrategias pedagógicas más adaptadas a las necesidades de los estudiantes.

En el grupo de desarrollo de este trabajo, nos encontramos tanto estudiantes de **Ingeniería Informática** como de **Ingeniería de la Salud**. Esta diversidad de perspectivas y formaciones académicas enriquece el enfoque del estudio, ya que, desde distintas disciplinas, reconocemos la importancia de crear un entorno educativo que no solo se base en el rendimiento académico, sino también en el bienestar y las capacidades individuales de cada estudiante. Al ser nosotros mismos estudiantes, sabemos de primera mano que las aulas son cada vez más diversas, y entender cómo organizar y distribuir a los estudiantes de acuerdo con sus necesidades específicas es clave para optimizar su rendimiento.

### Importancia local/nacional y en el contexto actual

A nivel global, la educación es un pilar fundamental para el desarrollo. Países con bajos índices de rendimiento académico suelen enfrentar mayores desafíos económicos y sociales. Además, en un contexto postpandemia, donde la enseñanza a distancia ha cambiado la forma en que los estudiantes aprenden, es más importante que nunca entender qué factores afectan su desempeño y cómo pueden optimizarse los procesos de enseñanza.

## Descripción del dataset

El dataset ha sido extraído de la plataforma Kaggle y proporcionado por el usuario *lainguyn123*. Se puede acceder al conjunto de datos a través del siguiente enlace: [Student Performance Factors Dataset](https://www.kaggle.com/datasets/lainguyn123/student-performance-factors/data).

El archivo que contiene el conjunto de datos se denomina *StudentPerformanceFactors* y está en formato **CSV**, con un tamaño aproximado de **641 kB**.

Este conjunto de datos proviene de una investigación que analiza los factores que afectan el rendimiento académico de los estudiantes. Incluye diversas variables relacionadas con características personales, académicas y sociales, tales como hábitos de estudio, asistencia, participación de los padres, y otros aspectos clave que influyen en el éxito académico de los estudiantes.

En cuanto a sus dimensiones, el dataset consta de un total de:

-   **6,607 Filas**

-   **20 Columnas**

## Librerías

La función ipak está diseñada para facilitar la instalación y carga de paquetes en R. Es útil cuando desea asegurarse de que todos los paquetes necesarios para un script o proyecto se instalan y cargan automáticamente. <https://gist.github.com/stevenworthington/3178163>

```{r}
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if(length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("tidyverse","ggplot2", "dplyr","gridExtra", "reshape2", "car", "ggridges", "factoextra", "cluster", "NbClust", "RColorBrewer")
ipak(packages)
```

## Exploración de datos

Antes de realizar cualquier análisis, es fundamental explorar el conjunto de datos para comprender la estructura de los mismos, identificar posibles inconsistencias y verificar la presencia de valores faltantes. En esta sección, realizamos una inspección inicial del dataset.

### Lectura de los datos

Cargamos el dataset desde el archivo CSV y verificamos su correcta importación:

```{r}
data <- read.csv("data/StudentPerformanceFactors.csv", header=TRUE)
```

A continuación, se presentan las primeras seis filas del conjunto de datos para obtener una vista preliminar de su estructura y los valores de las variables.

```{r}
head(data)
```

Vamos a examinar la estructura del conjunto de datos para obtener un resumen de las variables presentes, su tipo de dato y una visión general de cómo están organizados los datos.

```{r}
str(data)
```

El dataset está compuesto por **6,607 filas** y **20 columnas**, las cuales incluyen atributos de distintos tipos: *numéricos*, *categóricos* y *booleanos*.

A continuación, se describen algunos de estos atributos:

-   **Hours_Studied**: Número de horas de estudio semanales.

-   **Attendance**: Porcentaje de clases a las que ha asistido.

-   **Parental_Involvement**: Nivel de implicación de los padres en la educación del alumno *(Low, Medium, High)*.

-   **Access_to_Resources**: Disponibilidad de recursos educativos *(Low, Medium, High)*.

-   **Extracurricular_Activities**: Participación en actividades extraescolares *(Yes, No)*.

-   **Sleep_Hours**: Número medio de horas de sueño por noche.

-   **Previous_Scores**: Puntuaciones de exámenes anteriores.

-   **Motivation_Level**: Nivel de motivación del estudiante *(Low, Medium, High)*.

-   **Internet_Access**: Disponibilidad de acceso a Internet *(Yes, No)*.

-   **Tutoring_Sessions**: Número de sesiones de tutoría a las que asiste al mes.

-   **Family_Income**: Nivel de ingresos familiares *(Low, Medium, High)*.

-   **Teacher_Quality**: Calidad de los profesores *(Low, Medium, High)*.

-   **School_Type**: Tipo de escuela a la que asistió *(Public, Private)*.

-   **Peer_Influence**: Influencia de los compañeros en el rendimiento académico *(Positive, Neutral, Negative)*.

-   **Physical_Activity**: Número medio de horas de actividad física a la semana.

-   **Learning_Disabilities**: Presencia de dificultades de aprendizaje *(Yes, No)*.

-   **Parental_Education_Level**: Nivel educativo más alto de los padres *(High School, College, Postgraduate)*.

-   **Distance_from_Home**: Distancia de casa a la escuela *(Near, Moderate, Far)*.

-   **Gender**: Género del estudiante *(Male, Female)*.

-   **Exam_Score**: Calificación del examen final.

### Revisión de los datos

A continuación, vamos a observar si existen valores faltantes, erróneos o inconsistentes en el conjunto de datos. Utilizaremos una función que identifica las filas con valores NA o vacíos ("") en cada columna, lo que nos permitirá tener un panorama de los datos.

```{r}
detect_missing_data <- function(df) {
  na_count <- colSums(is.na(df))  # Contar los NA en cada columna
  empty_count <- colSums(sapply(df, function(x) x == ""))  # Contar los valores vacíos en cada columna
  
  missing_data <- data.frame(NA_Count = na_count, Empty_Count = empty_count)
  missing_data <- missing_data[missing_data$NA_Count > 0 | missing_data$Empty_Count > 0, ]
  
  return(missing_data)
}


missing_data <- detect_missing_data(data)
missing_data
```

En el resultado arrojado por la función podemos observar que no existen valores **NA** en las columnas de nuestro dataframe, lo que significa que no hay datos explícitamente faltantes o nulos. Sin embargo, también notamos que hay filas con **valores vacíos** en ciertas variables categóricas.

Al sumar el total de valores faltantes podemos observar que puede haber un máximo de **235 filas** con algún valor faltante. Esto supone aproximadamente el **3.56%** del total de filas del conjunto de datos.

### Análisis descriptivo

#### Variables numéricas

En esta sección, vamos a calcular las **medidas estadísticas básicas** para las variables numéricas, tales como la *media*, *mediana*, *desviación estándar*, y otros estadísticos relevantes. También calcularemos las frecuencias de las variables categóricas para entender mejor la distribución de los datos.

```{r}
# Resumen estadístico de las variables numéricas
numeric_vars <- sapply(data, is.numeric)  
data_numeric <- data[, numeric_vars]
summary(data_numeric)
```

**Observaciones**

-   La mayoría de los estudiantes estudian entre **16 y 24 horas a la semana**, con una distribución bastante centrada en la media y la mediana. Sin embargo, se observa que el *máximo de 44 horas* indica la presencia de algunos estudiantes que estudian significativamente más.

-   La **asistencia (Attendance)** tiende a ser **alta**, con el 50% de los estudiantes asistiendo al menos 80% de las clases. Sin embargo, **hay alumnos con asistencia más baja (60%)**, aunque no encontramos a ningún alumno que no asista al menos a la mitad de las clases.

-   La mayoría de los estudiantes duermen entre **6 y 8 horas**, aunque hay algunos casos que duermen solo 4 horas, lo que podría afectar su rendimiento académico.

-   La **distribución de calificaciones previas está equilibrada**, con la mediana y la media relativamente cercanas. Sin embargo, hay estudiantes con puntajes significativamente más bajos (50), lo que podría indicar dificultades académicas previas.

-   La mayoría de los estudiantes asisten a **1 o 2 sesiones de tutoría al mes**, pero también hay quienes no reciben ninguna tutoría. Respecto a la actividad física, la mayoría de los estudiantes realizan entre 2 y 4 horas, aunque algunos no hacen ninguna actividad, lo que podría impactar su salud y concentración.

-   Respecto a **la calificación final del exámen**, la media y la mediana están alineadas, lo que indica una **distribución simétrica**. La mayoría de los estudiantes obtienen calificaciones **entre 65 y 69**; sin embargo, algunos alcanzan hasta 101, lo que podría deberse a un posible error en los datos o a un estudiante destacado que, gracias a una bonificación adicional, supera la calificación máxima establecida.

Estas conclusiones nos van a orientar sobre los próximos pasos en el preprocesamiento de datos, como identificar grupos de estudiantes con distintos patrones de estudio, asistencia y tutorías. Además, va a ser clave analizar posibles outliers, como la calificación de 101 en el examen final, para determinar si se trata de un error o una excepción justificable.

A continuación calculamos la *desviación estándar* y la *varianza*, lo cual nos da una idea de la dispersión de los datos con los que vamos a trabajar.

```{r}
# Desviación estándar
desviacion_estandar <- sapply(data_numeric, sd)
desviacion_estandar
```

```{r}
# varianza
varianza <- sapply(data_numeric, var)
varianza
```

**Conclusiones**

-   **Variables con alta variabilidad**: `Attendance` y `Previous_Scores` tienen las varianzas más altas, lo que sugiere que hay *grandes diferencias* entre los estudiantes en términos de asistencia y calificaciones previas. Con esta información, podríamos analizar si la variabilidad en Attendance y Previous_Scores impacta directamente en el Exam_Score.

-   **Variables con baja variabilidad**: `Sleep_Hours`, `Tutoring_Sessions`, `Physical_Activity` muestran desviaciones estándar más bajas, lo que indica que la mayoría de los estudiantes tienen *comportamientos similares en estos aspectos*. Es decir, suelen dormir las mismas horas, realizar rutinas de ejercicio similares y sesiones de tutoría parecidas. Por lo que se puede llegar a la conclusión de que estos factores pueden no diferenciar mucho a los estudiantes en términos de rendimiento.

-   **Exam_Score vs Previous_Scores**: *Previous Scores tiene una variabilidad significativamente mayor a Exam_Score* (14.40 vs. 3.89 en desviación estándar), lo que sugiere que las calificaciones en el examen final están más concentradas alrededor de un valor central en comparación con las calificaciones anteriores.

-   Respecto a **Hours_Studied**, su varianza de *35.89* indica una alta dispersión, lo que puede significar que los estudiantes tienen *hábitos de estudio muy variados*. Algunos dedican muchas horas a estudiar, mientras que otros apenas lo hacen. Por ello, puede que el tiempo de estudio sea un factor muy variable y determinante en el rendimiento académico.

#### Variables categóricas

Para las variables categóricas, vamos a calcular las *frecuencias y proporciones de cada categoría* de modo que podamos observar la distribución de las diferentes categorías dentro de cada variable. Para ello, primero seleccionamos las variables categóricas y luego hacemos uso de la función `table()` y `prop.table()` para obtener la distribución de cada una.

```{r}
data <- data %>%
  mutate(across(where(is.character), as.factor))
categorical_vars <- sapply(data, is.factor) 
data_categoric <- data[, categorical_vars] # Filtrar solo variables categóricas
```

```{r}
# Obtener frecuencias absolutas
frecuencias <- lapply(data_categoric, table)
frecuencias
```

Algunas de las observaciones obtenidas son las siguientes:

-   **Parental Involvement**, **Teacher Quality** y **Motivation Level**: La mayoría de los estudiantes tienen un nivel medio (seguido de nivel bajo) de involucramiento familiar, motivación, y calidad docente, lo cual podría indicar áreas clave para intervenir en el proceso educativo.

-   **Internet_Access**, **Extracurricular_Activities**, y **Access_To_Recourses**: Las variables relacionadas con el acceso a recursos muestran una distribución relativamente equilibrada, lo que podría ser positivo para el acceso equitativo a la educación.

-   La distribución de **Family_Income** (ingresos familiares) muestra una ligera mayoría de estudiantes provenientes de familias con ingresos bajos (2672), seguida de familias con ingresos medios (2666), y una menor representación de familias con ingresos altos (1269). Además, la mayoría de los estudiantes asiste a escuelas públicas (4598), con un número considerable en escuelas privadas (2009). Estas diferencias de las variables sugieren que el contexto socioeconómico podría influir en la experiencia educativa de los estudiantes.

-   **Learning disabilities**: La mayoría de los estudiantes no tiene discapacidades de aprendizaje (5912), mientras que una fracción pequeña sí las tiene (695).

- **Peer Influence**: La influencia neutral de los compañeros parece ser la más común (2592), seguida de positiva (2638) y negativa (1377). La influencia de los compañeros es *predominantemente positiva o neutral*, lo que puede indicar que los estudiantes se ven generalmente influenciados de manera favorable.

De forma complementaria, se muestran las proporciones de cada categoría dentro de las variables categóricas del conjunto de datos.

```{r}
# Obtener proporciones relativas
proporciones <- lapply(data_categoric, function(x) prop.table(table(x)))
proporciones
```
En el apartado de visualización de los datos se explorarán más a fondo estas distribuciones y relaciones, lo que permitirá tener una comprensión más clara y detallada de los patrones en el conjunto de datos.

## Preprocesamiento de datos

Durante la exploración de los datos, hemos identificado que existen filas con valores faltantes. Dado que la proporción de instancias con valores faltantes es relativamente baja, hemos decidido **eliminar estas filas**. Consideramos que su eliminación no afectará de manera significativa la integridad general del conjunto de datos, permitiéndonos continuar con el análisis sin introducir sesgos o inconsistencias.

```{r}
clean_missing_data <- function(df) {
  original_row_count <- nrow(df)
  
  df <- df[!apply(df, 1, function(x) any(is.na(x) | x == "")), ] #Borramos las filas
  
  cleaned_row_count <- nrow(df)
  rows_removed <- original_row_count - cleaned_row_count
  cat("Número de filas eliminadas:", rows_removed, "\n")
  
  return(df)
}

data <- clean_missing_data(data)
```

Observamos que se han eliminado 229 filas por lo que el dataset sin ningún valor de faltante constaría de un total de **6378 filas**.

### Detección de outliers

Antes de desarrollar modelos predictivos, es crucial identificar los valores atípicos. Para ello, empleamos el **método del rango intercuartil (IQR)**, que nos permite detectar valores extremos en las variables numéricas, evaluar su impacto en el análisis y determinar posibles tratamientos.

```{r}
numeric_cols <- sapply(data, is.numeric)

count_outliers <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  sum(x < lower_bound | x > upper_bound, na.rm = TRUE)
}


for (col_name in names(data)[numeric_cols]) {
  num_outliers <- count_outliers(data[[col_name]])
  print(paste("Variable:", col_name, "- Outliers:", num_outliers))
}
```

Podemos observar que existen outliers en las variables `Hours_studies`, `Tutoring_Sessions` y `Exam_Score`. Para analizarlos mejor, utilizaremos gráficos de caja o boxplots que nos permitirán visualizar su distribución.

```{r}
plot_boxplots <- function(df) {
  plots <- list()
  numeric_cols <- c("Hours_Studied", "Tutoring_Sessions", "Exam_Score")
  numeric_cols <- numeric_cols[numeric_cols %in% names(df)]
  

  for (var in numeric_cols) {
    p <- ggplot(df, aes_string(y = var)) +
      geom_boxplot(fill = "orange", alpha = 0.7) +
      theme_minimal() +
      labs(title = paste("Outliers in", var), y = var)
    
    plots[[var]] <- p
  }

  for (p in plots) {
    print(p)
  }
}
```

```{r}
plot_boxplots(data)
```

Al observar los gráficos de caja, podemos identificar la presencia de valores atípicos. Sin embargo, no todos estos valores deberían considerarse como anomalías.

En el caso de la variable `tutoring_sessions`, los valores entre 4 y 8 se marcan como atípicos, aunque representan un rango perfectamente válido de horas de tutoría. De manera similar, en `Hours_Studied`, se detectan valores extremos por encima de las 35 horas y por debajo de las 5 horas de estudio. Si bien estos pueden parecer atípicos desde una perspectiva estadística, es posible que reflejen hábitos de estudio reales en algunos estudiantes.

En cambio, en el gráfico de `Exam_Scores`, se pueden notar calificaciones que superan el valor máximo permitido de 100. Para solucionar esto, filtraremos las filas en las que el valor de `Exam_Score` sea superior a 100 y lo estableceremos a la máxima nota posible, es decir, 100.

```{r}
data$Exam_Score[data$Exam_Score > 100] <- 100
max_Exam_score <- max(data$Exam_Score)
print(max_Exam_score)
```

### Codificación

Para preparar los datos de manera óptima para el análisis, aplicamos varias transformaciones a las variables categóricas y ordinales. Esto nos permite estructurar la información de manera que los modelos puedan interpretarla correctamente.

Con esta función convertimos las columnas del data frame en factores ordenados y les asignamos valores enteros, de acuerdo con un orden específico de niveles. Esto es util para las variables que tienen una relación de orden o tienen un nivel jerárquico o progresivo, es decir, que pueden compararse en términos de más o menos, mejor o peor, mayor o menor.

-   `Parental_Involvement`,`Access_to_Resources`,`Motivation_Level`,`Family_Income`,`Teacher_Quality`. Estas variables pueden ordenarse de menor a mayor o viceversa".

-   En `Peer_Influence`, **Positive \> Neutral \> Negative** en términos de impacto en el rendimiento. Por lo que tambien se pueden ordenar.

-   En `Distance_from_Home` ordenamos los valores en términos de **nivel de cercanía** de la escuela a la casa del estudiante.

-   En `Parental_Education_Level` ordenamos los valores en términos de **nivel de estudio de los padres**. Desde menos estudios (High School) hasta más estudios (Postgraduate).

```{r}
convert_to_ordered_int <- function(df, column_names, levels_order, ordered = TRUE) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      df[[col]] <- as.integer(factor(df[[col]], levels = levels_order, ordered = ordered))
    }
  }
  return(df)
}

```

Algunas variables categóricas contienen únicamente valores "Yes" o "No", por lo que es más eficiente transformarlas en valores 0 y 1, 'No' y 'Yes', respectivamente.

Las variables modificadas serán:

-   `Extracurricular_Activities`, `Internet_Access`, `Learning_Disabilities` → Yes = 1, No = 0

```{r}
convert_to_binary <- function(df, column_names) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      df[[col]] <- ifelse(df[[col]] == "Yes", 1, 0)
    }
  }
  return(df)
}

```

Algunas variables no tienen una jerarquía clara, por lo que en lugar de asignar valores ordinales, creamos columnas binarias (dummies) para cada categoría, es decir, aplicamos One-Hot Encoding.

-   `School_Type` pasará a dividirse en dos columnas: `School_Type_Public` y `School_Type_Private`
-   `Gender` se convierte en `Gender_Male` y `Gender_Female`.

```{r}
convert_to_one_hot <- function(df, column_names) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      unique_values <- unique(df[[col]])
      for (val in unique_values) {
        new_col_name <- paste(col, val, sep = "_")
        df[[new_col_name]] <- ifelse(df[[col]] == val, 1, 0)
      }
      df[[col]] <- NULL  # Eliminamos la columna original después de crear las dummy variables
    }
  }
  return(df)
}

```

```{r}
clean_and_filter_data <- function(data) {
  data <- data %>%
    distinct() %>%
    
    # Convertir a valores ordenados (Low < Medium < High)
    convert_to_ordered_int(c("Parental_Involvement", "Access_to_Resources", "Motivation_Level",
                              "Family_Income", "Teacher_Quality"),
                           c("Low", "Medium", "High")) %>%
    
    # Convertir Peer_Influence en valores ordenados (Negative < Neutral < Positive)
    convert_to_ordered_int("Peer_Influence", c("Negative", "Neutral", "Positive")) %>%
    
    # Convertir Parental Education Level en valores ordenados (High School < College < Postgraduate)
    convert_to_ordered_int("Parental_Education_Level", c("High School", "College", "Postgraduate")) %>%
    
    # Convertir Distance_from_Home en valores ordenados (Near < Moderate < Far)
    convert_to_ordered_int("Distance_from_Home", c("Near", "Moderate", "Far")) %>%
    
    # Convertir a valores binarios (No = 0, Yes = 1)
    mutate(
      Extracurricular_Activities = ifelse(Extracurricular_Activities == "Yes", 1, 0),
      Internet_Access = ifelse(Internet_Access == "Yes", 1, 0),
      Learning_Disabilities = ifelse(Learning_Disabilities == "Yes", 1, 0)
    ) %>%
    
    # Aplicar One-Hot Encoding a School_Type y Gender
    mutate(
      School_Type_Private = ifelse(School_Type == "Private", 1, 0),
      School_Type_Public = ifelse(School_Type == "Public", 1, 0),
      Gender_Male = ifelse(Gender == "Male", 1, 0),
      Gender_Female = ifelse(Gender == "Female", 1, 0)
    ) %>%
    
    # Eliminar las columnas originales después de One-Hot Encoding
    select(-School_Type, -Gender)

  return(data)
}

```

```{r}
df_cleaned <- clean_and_filter_data(data)
```

```{r}
df_cleaned
```

Después de la codificación, nuestro dataset consta de estos tipos:

```{r}
str(df_cleaned)
```

### Escalarización

Para que el análisis sea óptimo, también es necesario escalar las variables.

-   `Sleep_Hours` toma como valor las horas de sueño por noche. Supondremos que el estudiante duerme esta cantidad de horas todos los días por lo que modificaremos el valor para que sean horas semanales (Multiplicamos por 7 las horas de sueño diarias).

-   `Tutoring_Sessions` toma como valor las sesiones de tutoria por mes. Para escalar esta variable, se tomará 1 sesión de tutoría = 1 hora y a su vez, se pasará a horas semanales. Por ejemplo, si un estudiante tiene `Tutoring_Sessions` = 4 en un mes, significa que tiene 1 por semana (`Tutoring_Sessions`/ 4 semanas).

```{r}
scale_time_variables <- function(df) {
  df <- df %>%
    mutate(
      Sleep_Hours = Sleep_Hours * 7,  # Convertir de horas por noche a horas por semana
      Tutoring_Sessions = Tutoring_Sessions / 4  # Convertir sesiones a horas/semana
    )
  return(df)
}

df_cleaned <- scale_time_variables(df_cleaned)

print("Sleep_Hours:") 
summary(df_cleaned$Sleep_Hours)  # Debería estar en un rango de 0-56 horas semanales
print("Tutoring_Sessions:")
summary(df_cleaned$Tutoring_Sessions)  # Ahora representará horas de tutoría por semana


```

Como puede observarse, para las horas de sueño semanales, el mínimo es 28, lo cual significa que hay estudiantes que duermen 4 horas por noche (4 \* 7 = 28). La mediana es 49, lo que indica que la mayoría de los estudiantes duermen aproximadamente 7 horas por noche (7 \* 7 = 49). El máximo es 70, lo que implica que algunos estudiantes duermen 10 horas por noche (10 \* 7 = 70).

Por otro lado, para las horas de tutoría por semana, el mínimo es 0, lo cual es correcto, ya que algunos estudiantes no tienen sesiones de tutoría. La mediana es 0.25, lo que significa que muchos estudiantes tienen 1 sesión por mes (1 hora / 4 = 0.25 horas/semana). El máximo es 2, lo que indica que algunos estudiantes tienen 8 sesiones de tutoría por mes, que equivale a 2 horas de tutoría por semana.

## Visualizaciones Iniciales

## Distribución de variables numéricas

```{r}
create_dist_grap <- function(df, variable, binwidth = 1, fill = "cornflowerblue") {
  if (!(variable %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  ggplot(df, aes_string(x = variable)) +
    geom_histogram(binwidth = binwidth, 
                   fill = fill, color = "black", bins = 20) +
    labs(title = paste(variable, "analysis"), x = variable, y = "Count") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5))
}

create_dist_grap(data, "Sleep_Hours")
create_dist_grap(data, "Hours_Studied")
create_dist_grap(data, "Attendance", binwidth = 5)
create_dist_grap(data, "Tutoring_Sessions")
create_dist_grap(data, "Physical_Activity")
create_dist_grap(data, "Previous_Scores")
create_dist_grap(data, "Exam_Score", fill = "orange")
```

## Distribución de variables categóricas

```{r}
create_pie_chart <- function(df, var_name) {
  if (!(var_name %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  dist_var <- as.data.frame(table(df[[var_name]]))
  colnames(dist_var) <- c(var_name, "Count")
  dist_var$Percentage <- round(dist_var$Count / sum(dist_var$Count) * 100, 1)
  

  ggplot(dist_var, aes(x = "", y = Count, fill = get(var_name))) +
    geom_bar(stat = "identity", width = 1) +
    coord_polar(theta = "y") +
    geom_text(aes(label = paste0(Percentage, "%")), position = position_stack(vjust = 0.5), size = 5) +
    labs(title = paste("Distribución de", var_name), fill=var_name) +
    theme_minimal() +
    theme(axis.text.x = element_blank(), 
          axis.ticks = element_blank(),
          panel.grid = element_blank())
}
```

```{r}
barplot_chart <- function(df, var_name, show_percentage = TRUE) {
  if (!(var_name %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  dist_var <- as.data.frame(table(df[[var_name]]))
  colnames(dist_var) <- c(var_name, "Count")
  dist_var$Percentage <- dist_var$Count / sum(dist_var$Count) * 100
  

  colors <- brewer.pal(n = nrow(dist_var), name = "Pastel1")  
  
  p <- ggplot(dist_var, aes_string(x = var_name, y = "Count", fill = var_name)) +
    geom_bar(stat = "identity", color = "black") +
    scale_fill_manual(values = colors) +  
    theme_minimal() +
    labs(title = paste("Distribución de", var_name),
         x = var_name,
         y = "Frecuencia") +
    theme(legend.position = "none") 
  
  if (show_percentage) {
    p <- p + geom_text(aes(label = paste0(round(Percentage, 1), "%")), 
                       vjust = -0.3,
                       color = "black", 
                       size = 4)
  }
  
  print(p)
}
```

```{r}
barplot_chart(data, "Parental_Involvement", show_percentage = FALSE)
barplot_chart(data, "Access_to_Resources", show_percentage = FALSE)
barplot_chart(data, "Parental_Education_Level", show_percentage = FALSE)
barplot_chart(data, "Distance_from_Home", show_percentage = FALSE)
barplot_chart(data, "Extracurricular_Activities")
barplot_chart(data, "School_Type")
barplot_chart(data, "Gender")
```

## Relación entre variables (Diagramas de dispersión)

```{r}
scatter_plot <- function(df, var1, var2) {
  if (!(var1 %in% colnames(df)) | !(var2 %in% colnames(df))) {
    stop("Una o ambas variables no existen en el dataframe.")
  }
  
  if (!is.numeric(df[[var1]]) | !is.numeric(df[[var2]])) {
    stop("Ambas variables deben ser numéricas.")
  }
  
  color_palette <- brewer.pal(9, "Spectral")

  
  # Crear el gráfico de dispersión
  p <- ggplot(df, aes(x = .data[[var1]], y = .data[[var2]])) +
    geom_point(aes(color = .data[[var1]]), size = 3) + 
    scale_color_gradientn(colors = color_palette) + 
    geom_smooth(method = "lm", color = "red", se = FALSE) +  # Línea de regresión
    theme_minimal() +
    labs(title = paste("Gráfico de Dispersión de", var1, "vs", var2),
         x = var1,
         y = var2) +
    theme(plot.title = element_text(hjust = 0.5))  
  
  print(p)
}
```

```{r}
scatter_plot(data, "Hours_Studied", "Exam_Score")
scatter_plot(data, "Attendance", "Exam_Score")
```

## Comparación entre variables categórica y numérica

```{r}
categoric_numeric_barplot <- function(df, cat_var, num_var) {
  if (!(cat_var %in% colnames(df)) | !(num_var %in% colnames(df))) {
    stop("Una o ambas variables no existen en el dataframe.")
  }
  
  color_palette <- brewer.pal(3, "Pastel1")  
  

  p <- ggplot(df, aes_string(x = cat_var, y = num_var, fill = cat_var)) +
    geom_bar(stat = "summary", fun = "mean", color = "black") +
    scale_fill_manual(values = color_palette) +  
    theme_minimal() +
    labs(title = paste("Promedio de", num_var, "por", cat_var),
         x = cat_var,
         y = paste("Promedio de", num_var)) +
    theme(plot.title = element_text(hjust = 0.5)) 
  
  print(p)
}

categoric_numeric_barplot(data,"Parental_Involvement","Previous_Scores")
categoric_numeric_barplot(data,"Access_to_Resources","Previous_Scores")
categoric_numeric_barplot(data,"Motivation_Level","Previous_Scores")
categoric_numeric_barplot(data,"School_Type","Previous_Scores")
```

## Relación entre variables categóricas

```{r}
stacked_barplot <- function(df, var_x, var_fill) {
  if (!(var_x %in% colnames(df)) | !(var_fill %in% colnames(df))) {
    stop("One or both variables do not exist in the dataframe.")
  }
  
  df[[var_x]] <- as.factor(df[[var_x]])
  df[[var_fill]] <- as.factor(df[[var_fill]])
  

  color_palette <- brewer.pal(3, "Pastel1")  
  
  p <- ggplot(df, aes_string(x = var_x, fill = var_fill)) +
    geom_bar(position = "fill") +
    scale_fill_manual(values = color_palette) + 
    theme_minimal() +
    labs(title = paste("Distribution of", var_fill, "by", var_x),
         x = var_x,
         y = "Proportion") +
    theme(plot.title = element_text(hjust = 0.5)) 
  
  print(p)
}

stacked_barplot(data, "School_Type", "Parental_Involvement")
stacked_barplot(data, "School_Type", "Family_Income")
stacked_barplot(data, "School_Type", "Teacher_Quality")
```

```{r}
barplot_school_attendance_avg <- function(df) {
  if (!("School_Type" %in% colnames(df)) | !("Attendance" %in% colnames(df))) {
    stop("Las columnas School_Type y Attendance deben existir en el dataframe.")
  }
  
  avg_attendance <- aggregate(Attendance ~ School_Type, data = df, FUN = mean)
  colors <- brewer.pal(n = nrow(avg_attendance), name = "Pastel1")
  
  p <- ggplot(avg_attendance, aes(x = School_Type, y = Attendance, fill = School_Type)) +
    geom_bar(stat = "identity", color = "black") +
    scale_fill_manual(values = colors) + 
    theme_minimal() +
    labs(title = "Promedio de Asistencia por Tipo de Escuela",
         x = "Tipo de Escuela",
         y = "Promedio de Asistencia") +
    theme(legend.position = "none")
  
  print(p)
}

barplot_school_attendance_avg(data)

```

## Preguntas

### ¿Se pueden agrupar a los estudiantes en una clase según sus características?

-   **Objectivo**: Intentar asignar a los alumnos a grupos de manera que se favorezca su aprendizaje.

En primer lugar, decidimos una estrategia a adoptar para agrupar a los alumnos. Nos enfocamos en diferentes variables según el objetivo a cumplir:

-   **Academic**: Nos interesamos en las variables que reflejan el éxito escolar en términos académicos, como la asistencia, el número de horas de estudio o los resultados obtenidos.

-   **Support**: Aquí, el enfoque está en las necesidades de apoyo del alumno. ¿Necesita horas de tutoría? ¿Tiene dificultades para aprender?

-   **Resource**: ¿Dispone el alumno de los recursos necesarios para favorecer su aprendizaje?

-   **Extra**: Variables relacionadas con el ocio y la vida social. ¿Tiene el alumno actividades extracurriculares? ¿Cuáles son sus relaciones de amistad?

-   **General**: Todas las variables. ¿Que grupos conforman estos datos?

```{r}
academic_columns <- c("Hours_Studied", "Attendance", "Exam_Score", "Previous_Scores")
support_columns <- c("Learning_Disabilities", "Tutoring_Sessions", "Access_to_Resources")
resource_columns <- c("Family_Income", "Access_to_Resources", "Internet_Access", "Parental_Education_Level")
extra_columns <- c("Extracurricular_Activities", "Physical_Activity", "Peer_Influence")
general_columns <- c(
  "Hours_Studied",
  "Attendance",
  "Parental_Involvement",
  "Access_to_Resources",
  "Extracurricular_Activities",
  "Sleep_Hours",
  "Previous_Scores",
  "Motivation_Level",
  "Internet_Access",
  "Tutoring_Sessions",
  "Family_Income",
  "Teacher_Quality",
  "School_Type_Private",
  "School_Type_Public",
  "Peer_Influence",
  "Physical_Activity",
  "Learning_Disabilities",
  "Parental_Education_Level",
  "Distance_from_Home",
  "Gender_Male",
  "Gender_Female",
  "Exam_Score"
)
```

```{r}
df_scaled = as_tibble(scale(df_cleaned))

data_for_cluster_academic <- select(df_scaled, all_of(academic_columns))
data_for_cluster_support <- select(df_scaled, all_of(support_columns))
data_for_cluster_resource <- select(df_scaled, all_of(resource_columns))
data_for_cluster_extra <- select(df_scaled, all_of(extra_columns))
data_for_cluster_general <- select(df_scaled, all_of(general_columns))
```

Para agrupar a los alumnos según estas categorías, utilizaremos el método de **clustering K-Means**.

Primero, definimos una función que nos permita seleccionar el mejor valor de **K**.

```{r}
compare_k <- function(df) {
  print(fviz_nbclust(df, kmeans, method = "wss") + 
    ggtitle("Elbow Method for Optimal K"))

  print(fviz_nbclust(df, kmeans, method = "silhouette") + 
    ggtitle("Silhouette Method for Optimal K"))
}
```

Luego, definimos una función que aplique el clustering y añada la variable **cluster** a nuestro conjunto de datos inicial.

```{r}
applying_kmeans <- function(data_for_clustering, k){
  set.seed(42)
  kmeans_model <- kmeans(data_for_clustering, centers = k, nstart = 25)
  df_with_cluster <- as_tibble(df_cleaned)
  df_with_cluster$Cluster <- as.factor(kmeans_model$cluster)
  return(df_with_cluster)
}
```

Finalmente, definimos una función que nos permita **comparar los grupos formados**:\
- ¿Cuántos alumnos hay en cada cluster?\
- Comparación de las variables utilizadas en el clustering mediante **ridgeline plots**.

```{r}
print_clustering_results <- function(df_with_clusters, data_for_cluster, columns_to_focus){
  cluster_summary <- df_with_clusters %>%
    group_by(Cluster) %>%
    summarise(
      Num_Students = n()
    )
  
  print(ggplot(cluster_summary, aes(x = as.factor(Cluster), y = Num_Students, fill = as.factor(Cluster))) +
          geom_bar(stat = "identity") +
          labs(title = "Number of Students in Each Cluster", x = "Cluster", y = "Student Count") +
          theme_minimal())
  
  for (column in columns_to_focus) {
    print(ggplot(df_with_clusters, aes(x = as.factor(Cluster), y = !!sym(column), fill = as.factor(Cluster))) +
            geom_boxplot() +
            labs(title = paste(column, "Distribution in Each Cluster"), x = "Cluster", y = column) +
            theme_minimal())
  }
  
  print(fviz_cluster(list(data = data_for_cluster, cluster = df_with_clusters$Cluster),
                     geom = "point",
                     ellipse.type = "convex",
                     ggtheme = theme_minimal(),
                     main = "Cluster Visualization (PCA Projection)"))
}

```

```{r}
find_optimal_clusters <- function(data) {
  
  result <- NbClust(data, diss = NULL, distance = "euclidean", 
                    min.nc = 2, max.nc = 4, method = "kmeans")
  
  # Retorna el número óptimo de clusters sugerido
  return(result)
}
```

#### Academic

```{r}
compare_k(data_for_cluster_academic)
```

```{r}
optimal_clusters_academic <- find_optimal_clusters(data_for_cluster_academic)

```

Analizando las gráficas del método del Codo (Elbow Method) y del Coeficiente de Silhouette, llegamos a la conclusión de que el número óptimo de clústeres es 𝑘 = 2 k=2.

Esta conclusión se fundamenta en dos aspectos clave:

**Método del Codo (Elbow Method)**: En esta gráfica, observamos que la mayor reducción en la suma de cuadrados dentro del grupo ocurre hasta 𝑘 = 2 k=2, formando un punto de inflexión o "codo" en ese valor. A partir de 𝑘 = 2 k=2, la disminución en la varianza interna de los clústeres se vuelve menos pronunciada, lo que indica que agregar más clústeres no aporta una mejora significativa en la compactación de los datos.

**Coeficiente de Silhouette (Silhouette Method)**: Este método mide la calidad de la agrupación en función de la cohesión interna y la separación entre clústeres. En la gráfica correspondiente, el valor más alto del coeficiente de Silhouette se encuentra en 𝑘 = 2 k=2, lo que indica que, con este número de clústeres, los grupos están bien diferenciados y los puntos dentro de cada clúster son más homogéneos.

Basándonos en la evaluación de múltiples criterios de clustering mediante `NbClust`, el número óptimo de clusters en los datos es **2**, ya que recibió la mayor cantidad de votos. Esto sugiere que los datos tienen dos grupos bien diferenciados, lo que puede ser validado adicionalmente con métricas como el índice de silueta o gráficos de PCA

Dado que todos los métodos coinciden en que 𝑘 = 2 es el valor óptimo, podemos concluir que dividir los datos en dos grupos proporciona una segmentación adecuada, asegurando un equilibrio entre la reducción de la variabilidad interna y la claridad en la separación entre clústeres.

```{r}
df_cluster_academic <- applying_kmeans(data_for_cluster_academic, 2)
```

```{r}
print_clustering_results(df_cluster_academic, data_for_cluster_academic, academic_columns)
```

El Clúster 1 está compuesto por estudiantes que dedican más horas al estudio en comparación con los del Clúster 2. Sin embargo, la diferencia más notable entre ambos grupos radica en la asistencia a clase, ya que los alumnos del Clúster 1 muestran un nivel de asistencia significativamente mayor. Este factor parece desempeñar un papel clave en su rendimiento académico, ya que la combinación de una mayor dedicación al estudio y una participación más activa en las clases les permite obtener resultados más favorables en comparación con los estudiantes del Clúster 2.

Por otro lado, los alumnos del Clúster 2 no solo estudian menos, sino que también presentan un porcentaje de asistencia más bajo, lo que podría afectar negativamente su comprensión de los contenidos y, en consecuencia, su desempeño académico. Estos hallazgos sugieren que tanto el tiempo de estudio como la asistencia a clase son factores determinantes en el éxito académico de los estudiantes.

#### Support

```{r}
compare_k(data_for_cluster_support)
```

```{r}
optimal_clusters_support <- find_optimal_clusters(data_for_cluster_support)

```

La primera gráfica sigue el **método del codo**, el cual evalúa la suma de los cuadrados dentro de los clusters (WSS) en función del número de clusters. El punto óptimo se encuentra donde la disminución en WSS se vuelve menos pronunciada, formando un "codo" en la curva. En este caso, se observa un cambio notable en la pendiente alrededor de k=4 y k=8, lo que indica que estos valores podrían ser opciones razonables para segmentar los datos de manera eficiente.

Por otro lado, la segunda gráfica utiliza el **método del Silhouette** para determinar el número óptimo de clusters. En este método, se elige el valor de k que maximiza el índice de silhouette, el cual mide qué tan bien separados están los clusters y qué tan cohesivos son. En la gráfica, el valor más alto de silhouette se alcanza en k=8, lo que sugiere que este número de clusters permite una mejor separación entre los grupos y minimiza la superposición entre ellos.

Basándonos en la evaluación de múltiples criterios de clustering mediante `NbClust`, el número óptimo de clusters en los datos es **4**, ya que recibió la mayor cantidad de votos. Esto sugiere que los datos tienen cuatro grupos bien diferenciados, lo que puede ser validado adicionalmente con métricas como el índice de silueta o gráficos de PCA

En conclusión, aunque el método del codo sugiere que tanto k=4 como k=8 son buenas opciones, el método de Silhouette indica que k=8 ofrece la mejor separación entre clusters. Sin embargo, al aplicar el método de múltiples criterios, k=4 obtuvo la mayor cantidad de votos, superando a las demás opciones por 15 votos. Dado que tanto el método del codo como el de múltiples criterios coinciden en k=4, tomamos esta opción como la más adecuada para el clustering.

```{r}
df_cluster_support <- applying_kmeans(data_for_cluster_support, 4)
```

```{r}
print_clustering_results(df_cluster_support, data_for_cluster_support, support_columns)
```

Tras analizar las distintas gráficas obtenidas en el estudio, se han identificado **tres grupos de alumnos** que no presentan dificultades en el aprendizaje, correspondientes a los **clústeres 1, 2 y 4**. Estos estudiantes no parecen experimentar problemas significativos en su rendimiento académico, lo que sugiere que sus hábitos y patrones de estudio pueden estar alineados con el éxito educativo.

Al comparar estos resultados con la **gráfica de sesiones de tutoría**, se observa que el **clúster 1** es el grupo que registra **más horas de tutoría**, lo que podría indicar un mayor interés o compromiso con el refuerzo académico. Por otro lado, los clústeres **2 y 4** presentan una cantidad similar de sesiones de tutoría, lo que sugiere que no requieren un apoyo adicional significativo. Sin embargo, el caso más preocupante se encuentra en el **clúster 3**, ya que **este grupo sí presenta problemas de aprendizaje, pero no asiste a tutorías**. Esta falta de apoyo podría estar contribuyendo a sus dificultades académicas, lo que sugiere la necesidad de intervenciones específicas para mejorar su desempeño.

En cuanto al **acceso a recursos educativos**, la última gráfica revela que el **clúster 4 es el que más acceso tiene**, ocupando el rango más alto en su totalidad. Esto sugiere que estos alumnos disponen de herramientas adecuadas para su aprendizaje, lo que puede estar relacionado con su buen rendimiento. Los **clústeres 1 y 3** comparten un rango medio de acceso a recursos, aunque con variaciones entre casos de acceso bajo y alto, lo que indica cierta desigualdad en la disponibilidad de materiales. Finalmente, el **clúster 2 presenta el nivel más bajo de acceso a recursos**, lo que podría representar una barrera para su desarrollo académico a largo plazo.

El análisis de los datos ha permitido identificar patrones significativos en el aprendizaje de los alumnos y su relación con las tutorías y el acceso a recursos. Se destaca que el **clúster 3 requiere especial atención**, ya que, a pesar de sus dificultades, **no participa en tutorías**, lo que podría agravar sus problemas. Además, el acceso desigual a recursos educativos podría estar influyendo en el rendimiento de algunos grupos. Estos hallazgos sugieren la importancia de fomentar el uso de tutorías en estudiantes con dificultades y garantizar un acceso equitativo a los recursos educativos para mejorar la calidad del aprendizaje.

#### Resources

```{r}
compare_k(data_for_cluster_resource)
```

```{r}
optimal_clusters_resources <- find_optimal_clusters(data_for_cluster_resource)
```

En la primera imagen, correspondiente al **método de Elbow**, se representa la suma de los cuadrados dentro del cluster (*Total Within Sum of Squares, WSS*) en función del número de clusters (*k*). Este método se basa en encontrar el punto donde la disminución de WSS empieza a desacelerarse de manera significativa, formando una especie de “codo” en la gráfica. En este caso, observamos que la curva muestra una reducción brusca hasta aproximadamente *k = 8*, después de lo cual la disminución de WSS se vuelve menos pronunciada. Esto sugiere que *k = 8* es un buen candidato para el número óptimo de clusters, ya que más allá de este punto la ganancia en términos de reducción de varianza dentro de los clusters es menor.

Por otro lado, en la segunda imagen se muestra el resultado del **método de Silhouette**, el cual mide la calidad de la agrupación en función de la cohesión interna y la separación entre los clusters. El objetivo es encontrar el valor de *k* que maximiza el ancho promedio del coeficiente de silueta, lo que indica que los puntos están bien agrupados dentro de sus respectivos clusters y bien separados de otros clusters. En esta gráfica, el valor más alto del coeficiente de silueta se observa en *k = 2*, lo que sugiere que dos clusters proporcionan la mejor separación según este criterio. Sin embargo, también se observa un valor elevado en *k = 8*, lo que indica que esta cantidad de clusters también es una opción viable.

Basándonos en la evaluación de múltiples criterios de clustering mediante `NbClust`, el número óptimo de clusters en los datos es **4**, ya que recibió la mayor cantidad de votos. Esto sugiere que los datos tienen cuatro grupos bien diferenciados, lo que puede ser validado adicionalmente con métricas como el índice de silueta o gráficos de PCA

El análisis de los diferentes métodos de clustering muestra resultados variados sobre la cantidad óptima de clusters. El método de **Elbow** sugiere que **k = 8** es una buena opción, ya que a partir de este punto la reducción de la varianza dentro de los clusters se desacelera significativamente. Por otro lado, el **método de Silhouette** indica que **k = 2** proporciona la mejor separación entre clusters, aunque también destaca **k = 8** como una alternativa viable. Sin embargo, el método de múltiples criterios de **NbClust** señala que **k = 4** es la mejor opción al haber recibido la mayor cantidad de votos, lo que sugiere la existencia de cuatro grupos bien diferenciados en los datos. Dado que NbClust integra varios enfoques de validación, se considera **k = 4** como el número óptimo de clusters, aunque los valores **k = 2 y k = 8** también pueden ser opciones a considerar dependiendo del criterio de segmentación que se priorice.

```{r}
df_cluster_resource <- applying_kmeans(data_for_cluster_resource, 4)
```

```{r}
print_clustering_results(df_cluster_resource, data_for_cluster_resource, resource_columns)
```

El análisis de la primera gráfica, correspondiente a los **ingresos familiares**, revela diversas diferencias entre los clústeres analizados. En términos generales, la mayoría de los grupos presentan ingresos de nivel medio, aunque existen algunas desviaciones significativas que reflejan desigualdades económicas dentro del conjunto de datos. En particular, los **clústeres 2 y 3** se sitúan dentro del rango de ingresos medios, pero con ciertas diferencias notables. El **clúster 2** muestra una mayor presencia de usuarios con ingresos **medios-bajos**, mientras que el **clúster 3** se inclina levemente hacia los **ingresos medios-altos**, aunque sin una diferencia muy pronunciada. En el caso del **clúster 1**, se observa una tendencia hacia ingresos **medios en su mayoría al alza**, sin presencia destacada de ingresos bajos. Sin embargo, el grupo con la situación económica más delicada es el **clúster 4**, que se distingue por presentar **ingresos íntegramente bajos** en comparación con los demás grupos.

Al relacionar estos hallazgos con la segunda gráfica, correspondiente al **acceso a recursos**, se observa que la mayoría de los clústeres tienen valores medios similares en cuanto a disponibilidad de recursos educativos. No obstante, existen algunas fluctuaciones, con ciertos casos que se inclinan hacia un acceso más limitado o, en otros, con mayores facilidades. Un hallazgo relevante es que, a pesar de que el **clúster 4** presenta los ingresos más bajos, su acceso a recursos no es significativamente menor, lo que sugiere la existencia de **programas de ayuda o becas** que compensan la falta de recursos económicos. Esto indica que, aunque las familias de este grupo tengan menos ingresos, han podido acceder a apoyos que mitigan las desigualdades.

En lo que respecta al **acceso a internet**, se evidencia que el **clúster 2** es el único grupo que presenta un valor negativo, es decir, una menor accesibilidad a la conectividad en comparación con el resto. Este dato plantea dos hipótesis posibles: una primera explicación sería que estas familias **no pueden permitirse el acceso a internet** debido a razones económicas; sin embargo, esta teoría resulta inconsistente si consideramos que el **clúster 4**, que cuenta con los ingresos más bajos, sí tiene acceso a internet. Por lo tanto, una hipótesis más plausible es que en el **clúster 2 las familias han restringido el uso de internet a sus hijos por decisión propia**, probablemente por razones educativas, de control parental o de valores familiares.

En cuanto al **nivel académico de los padres**, se observa que, en términos generales, la mayoría de los grupos presentan un nivel de educación secundaria. No obstante, existen diferencias entre los clústeres. El **clúster 1** se caracteriza por estar compuesto en su totalidad por padres con educación **secundaria**. El **clúster 2** también presenta una mayoría con educación secundaria, aunque con la particularidad de que algunos padres han alcanzado estudios **universitarios y de posgrado**. Por otro lado, el **clúster 4** cuenta principalmente con familias con formación en **educación secundaria y grados universitarios**, aunque sin un predominio de estudios avanzados. La situación más particular se encuentra en el **clúster 3**, donde los padres presentan un nivel de estudios **mínimo de grado universitario**, y en algunos casos, **estudios de posgrado**, lo que indica un nivel académico superior en comparación con el resto de los grupos.

El análisis realizado revela importantes diferencias socioeconómicas entre los clústeres analizados. Se ha identificado que el **clúster 4** es el grupo con menores ingresos, pero gracias a algún tipo de apoyo externo, ha podido mantener un acceso a recursos educativos similar al de los otros grupos. En cuanto a la **conectividad a internet**, el **clúster 2** es el único que presenta restricciones, lo que sugiere que la limitación se debe más a una decisión parental que a factores económicos. Respecto al **nivel educativo de los padres**, se observa que la mayoría han alcanzado la educación secundaria, aunque el **clúster 3 destaca por contar con padres con estudios universitarios y de posgrado en mayor proporción**. Estas diferencias pueden influir en el rendimiento académico y el acceso a oportunidades de aprendizaje, lo que subraya la importancia de analizar estos factores para diseñar estrategias de apoyo adecuadas para cada grupo.

#### Social

```{r}
compare_k(data_for_cluster_extra)
```

```{r}
optimal_clusters_extra <- find_optimal_clusters(data_for_cluster_extra)
```

En el gráfico del **método del codo**, se observa que la "Suma de Cuadrados Dentro del Grupo" (**WSS**) disminuye considerablemente hasta aproximadamente k=3, k=4, momento en el cual la pendiente comienza a estabilizarse. Esto indica que a partir de estos valores, agregar más clusters genera una menor ganancia en la reducción de la variabilidad dentro de los grupos, sugiriendo que k=3 o k=4 son opciones razonables.

Por otro lado, el **método del silhouette** muestra que la mejor cohesión interna y separación entre los clusters se obtiene con k=2, lo que sugiere que dividir los datos en dos grupos maximiza la calidad de la segmentación.

Adicionalmente, el **análisis de múltiples criterios** también ha indicado que el número óptimo de clusters es k=2, ya que ha recibido la mayor cantidad de votos (**8 votos**), superando a k=3 y k=4, que han obtenido **5 votos** cada uno.

Los tres enfoques utilizados coinciden en que k=2 es la opción más sólida para la segmentación de los datos. Tanto el método del silhouette como el análisis de múltiples criterios refuerzan esta elección, indicando que dividir los datos en dos grupos proporciona la mejor cohesión y separación entre clusters. Aunque el método del codo sugería que k=3 o k=4 podrían ser alternativas razonables, la evidencia general respalda la elección de k=2 como el número óptimo de clusters en este caso.

```{r}
df_cluster_extra <- applying_kmeans(data_for_cluster_extra, 2)

```

```{r}
print_clustering_results(df_cluster_extra, data_for_cluster_extra, extra_columns)
```

El análisis de los gráficos permite identificar distintos patrones en la relación entre la participación en **actividades extracurriculares**, la cantidad de **horas dedicadas a la actividad física** y la **influencia de los compañeros** en los alumnos. A través de la observación de estos datos, se pueden extraer conclusiones relevantes sobre cómo estas variables se relacionan entre sí y si tienen algún impacto en la vida social y académica de los estudiantes.

En el primer gráfico, correspondiente a la **realización de actividades extracurriculares**, se observa una diferencia clara entre los dos clústeres analizados. El **clúster 1** agrupa a aquellos alumnos que **no participan en actividades extraescolares**, mientras que el **clúster 2** representa a los estudiantes que sí realizan este tipo de actividades. Esta segmentación permite identificar una distinción clara en los hábitos de los alumnos con respecto a su tiempo fuera del entorno académico, lo que podría tener implicaciones en otros aspectos de su desarrollo personal y social.

En lo que respecta al **rango de horas dedicadas a la actividad física**, se observa que ambos clústeres presentan una distribución similar. Esto indica que la participación o no en actividades extracurriculares no tiene un impacto significativo en el tiempo que los estudiantes dedican a la práctica de ejercicio físico. Es decir, tanto los alumnos que realizan actividades extraescolares como los que no lo hacen mantienen hábitos de actividad física similares, lo que sugiere que otros factores, como la rutina diaria o el estilo de vida familiar, podrían ser más determinantes en este aspecto.

Por último, el análisis de la **influencia de los compañeros** muestra que ambos clústeres presentan una distribución equivalente en esta variable. Esto implica que la **realización de actividades extracurriculares no tiene un impacto significativo en el nivel de influencia que los compañeros ejercen sobre los estudiantes**. En otras palabras, la socialización y las dinámicas de grupo parecen mantenerse estables independientemente de si el alumno participa o no en actividades extracurriculares.

El análisis realizado revela que la participación en **actividades extracurriculares** es una característica diferenciadora entre los clústeres, pero no parece influir en otras variables como la **cantidad de horas dedicadas a la actividad física** ni en el **nivel de influencia de los compañeros**. La similitud en la distribución de estas últimas variables sugiere que la actividad extracurricular no es un factor determinante en los hábitos de ejercicio ni en la socialización de los alumnos. Por lo tanto, la decisión de realizar o no actividades extracurriculares podría estar más relacionada con factores personales o familiares que con un impacto significativo en la vida social o los hábitos de los estudiantes.

#### General

```{r}
compare_k(data_for_cluster_general)
```

```{r}
optimal_clusters_general <- find_optimal_clusters(data_for_cluster_general)
```

```{r}
df_cluster_extra <- applying_kmeans(data_for_cluster_extra, 2)
```

```{r}
print_clustering_results(df_cluster_extra, data_for_cluster_extra, extra_columns)
```

### ¿Cuántas horas de trabajo personal necesita un estudiante para obtener una alta calificación?

-   **Objetivo**: Determinar la cantidad óptima de horas semanales de trabajo personal necesarias para que un estudiante alcance una alta calificación.

El primer paso es definir un criterio para clasificar una calificación como "alta". Para ello, establecemos un umbral basado en un **Notable Alto**, lo que equivale aproximadamente a una calificación media de **8 o superior**.

A continuación, debemos identificar a aquellos estudiantes que cumplan con dicho requisito para centrar el análisis en este grupo específico. Para ello, filtramos el conjunto de datos y seleccionamos únicamente las instancias en las que la variable **Previous_Scores** sea superior a **80** (considerando que las calificaciones en el dataset están expresadas en una escala de 0 a 100).

Este filtrado nos permitirá focalizarnos en los estudiantes con alto rendimiento y analizar los factores que podrían haber influido en su desempeño académico.

Para ello, filtramos las observaciones donde la variable `Previous_Scores` tenga un valor superior a 80.

Además, al centrarnos la variables `Previous_Scores` eliminaremos del conjunto de datos la variable `Exam_Score`.

```{r}
data_notas_altas <- df_cleaned[df_cleaned$Previous_Scores >= 80,]
data_notas_altas <- subset(data_notas_altas, select = -Exam_Score)
data_notas_altas
```

Podemos observar en el siguiente gráfico de tarta la distribución de "altas calificaciones" respecto a la variable `Previous_Scores`.

```{r}
data$calificacion_categoria <- ifelse(data$Previous_Scores > 80, "Alta calificación", "Resto de calificaciones")


categoria_counts <- as.data.frame(table(data$calificacion_categoria))
categoria_counts$percentage <- round(100 * categoria_counts$Freq / sum(categoria_counts$Freq), 1)

ggplot(categoria_counts, aes(x = "", y = Freq, fill = Var1)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Distribución de Calificaciones en Previous Exams", 
       x = NULL, y = NULL) +
  theme_minimal() +
  theme(axis.text = element_blank(), 
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  geom_text(aes(label = paste(percentage, "%")), position = position_stack(vjust = 0.5))

```

Para nuestro estudio debemos crear una nueva métrica que refleje de forma general las **horas semanales de trabajo del estudiante**. Para ello, vamos a combinar varias de las variables disponibles para obtener una estimación más completa de las horas de dedicación del estudiante. Algunas de las variables que podrían influir directamente en las horas de trabajo semanales incluyen:

-   `Hours_Studied`: El número de horas que el estudiante estudia.
-   `Tutoring_Sessions`: El número de sesiones de tutoría.

La fórmula para las horas semanales de trabajo es

\$Horas_Semanales_Work = Hours_Studied + Tutoring_Sessions \$.

Donde:

-   `Hours_Studied`: Número de horas estudiadas.

-   `Tutoring_Sessions`: Número de sesiones de tutoría ( 1 hora por sesión).

```{r}
if ("Hours_Studied" %in% names(data_notas_altas) & 
    "Tutoring_Sessions" %in% names(data_notas_altas) & 
    "Physical_Activity" %in% names(data_notas_altas)){
  
  data_notas_altas$Horas_Semanales_Work <- data_notas_altas$Hours_Studied +               data_notas_altas$Tutoring_Sessions

  data_notas_altas <- data_notas_altas[, !(names(data_notas_altas) %in% c("Hours_Studied", "Tutoring_Sessions", "Physical_Activity"))]
} else {
  print("Las columnas necesarias ya han sido eliminadas.")
}
  
summary(data_notas_altas$Horas_Semanales_Work)
```

```{r}
data_numeric <- data_notas_altas[, sapply(data_notas_altas, is.numeric)]
data_scaled <- as.data.frame(scale(data_numeric))
data_notas_altas[, sapply(data_notas_altas, is.numeric)] <- data_scaled
data_notas_altas
```

Una vez identificados los estudiantes con altas calificaciones, el siguiente paso es identificar cuales son aquellos factores que influyen más en las altas calificaciones del alumno. Para ello, generamos una **matriz de correlación** junto con un **mapa de calor**, lo que nos permitirá visualizar de manera clara cómo se relacionan las variables numéricas dentro del conjunto de datos.

Con este análisis podremos detectar si existe una asociación significativa entre las horas de estudio personal y las calificaciones obtenidas. Además, nos permitirá observar la influencia de otros factores, como las horas de sueño, la asistencia a tutorías o la participación en actividades extracurriculares, en el rendimiento académico de los estudiantes con mejores notas.

```{r}
matriz_correlacion <- cor(data_notas_altas)
matriz_melt <- melt(matriz_correlacion)

ggplot(data = matriz_melt, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name = "Correlación") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "Variables", y = "Variables", title = "Mapa de Calor de Correlación")
```

El resultado de la matriz de correlación nos arroja que no existe gran correlación entre variables.

```{r}
model1 = lm(Horas_Semanales_Work ~ ., data = data_notas_altas)
summary(model1)
```

```{r}
data_notas_alta_simplificado <- data_notas_altas %>% dplyr::select(-School_Type_Public, -Gender_Female)
data_notas_alta_simplificado
```

```{r}
vif_values <- vif(lm(Horas_Semanales_Work ~ ., data = data_notas_alta_simplificado))
print(vif_values)
```

```{r}
indices <- sample(1:nrow(data_notas_alta_simplificado), size = 0.7 * nrow(data_notas_alta_simplificado))
train_data <- data_notas_alta_simplificado[indices, ]
test_data <- data_notas_alta_simplificado[-indices, ]
```

```{r}
#library(MASS)
#model_reduced <- stepAIC(lm(Horas_Semanales_Work ~ .^2, data = train_data), direction = "both")
#summary(model_reduced)
```

```{r}
predicciones <- predict(model_reduced, newdata = test_data)
```

```{r}
comparacion <- data.frame(Real = test_data$Horas_Semanales_Work, Predicha = predicciones)
comparacion
```

```{r}
residuos <- comparacion$Real - comparacion$Predicha
rmse <- sqrt(mean(residuos^2))
print(paste("RMSE: ", rmse))
```


### Análisis del Desempeño Académico y Factores que Influyen en la Mejora del Estudiante 

#### Introducción

¿Cuáles son los factores clave que determinan si un estudiante mejorará su rendimiento académico?

El objetivo de este estudio es identificar los factores que influyen en la mejora del rendimiento académico de los estudiantes.
Para lograrlo, se han utilizado técnicas de aprendizaje automático que permiten analizar grandes volúmenes de datos y extraer patrones que pueden ser utilizados para la toma de decisiones en el ámbito educativo.

Dado que las variables del conjunto de datos no presentaban una correlación lineal significativa entre sí, se descartaron métodos estadísticos tradicionales y se optó por modelos basados en árboles de decisión, que permiten capturar relaciones complejas entre las variables y generar reglas interpretables.


#### Preparación y Exploración de Datos

Se parte de un conjunto de datos estructurado con múltiples variables relacionadas con el desempeño académico de los estudiantes, incluyendo horas de estudio, asistencia, nivel de motivación, acceso a recursos, entre otros. Concretamente para responder a esta pregunta se usará el conjunto de datos ya preprocesado "df_cleaned".

Para entender mejor la distribución de las calificaciones, se generaron histogramas de Exam_Score y Previous_Scores:

```{r}
# Distribución de Exam_Score
ggplot(df_cleaned, aes(x = Exam_Score)) +
  geom_histogram(bins = 20, fill = "blue", alpha = 0.7) +
  labs(title = "Distribución de Exam_Score", x = "Exam Score", y = "Frecuencia")

# Distribución de Previous_Scores
ggplot(df_cleaned, aes(x = Previous_Scores)) +
  geom_histogram(bins = 20, fill = "red", alpha = 0.7) +
  labs(title = "Distribución de Previous_Scores", x = "Previous Scores", y = "Frecuencia")

```
'Exam_Score' tiene poca variabilidad, con la mayoría de los estudiantes en el rango de 60 a 75 puntos.
'Previous_Scores' tiene una distribución más uniforme, lo que sugiere que podría ser una mejor variable predictora.


Debido a la baja variabilidad en Exam_Score, decidimos intentar predecir High_Score en lugar de Exam_Score directamente.

El conjunto de datos no contenía una variable explícita para clasificar el rendimiento de los estudiantes.
Para abordar este problema, se creó la variable High_Score, que clasifica a los estudiantes en alto rendimiento y bajo rendimiento con base en su calificación final (Exam_Score).

```{r}
# Crear la variable High_Score (1 si el Exam_Score >= 80, 0 si es menor)
df_cleaned$High_Score <- ifelse(df_cleaned$Previous_Scores >= 80, 1, 0)

# Ver distribución
table(df_cleaned$High_Score)

```

Se seleccionó un umbral de 80 puntos para definir un "alto rendimiento" porque permite diferenciar a los estudiantes con desempeño notable del resto.
Esta clasificación se utilizará en los modelos para predecir qué factores influyen en que un estudiante alcance un alto rendimiento.


### Modelos Utilizados

Para identificar los factores que más influyen en el rendimiento de los estudiantes, se probaron distintos modelos:

1. Regresión Logística
2. Random Forest
3. XGBoost
4. Árbol de Decisión (Mejor Modelo)

##### 1. Regresión Logística
La regresión logística se utilizó inicialmente para predecir High_Score en función de las demás variables.

```{r}
# Entrenar modelo de Regresión Logística
model <- glm(High_Score ~ ., data = df_cleaned %>% select(-Exam_Score), family = binomial)

# Hacer predicciones
y_prob <- predict(model, newdata = df_cleaned, type = "response")
y_pred <- ifelse(y_prob >= 0.5, 1, 0)

# Evaluación
accuracy <- mean(y_pred == df_cleaned$High_Score)
print(paste("Accuracy:", accuracy))

```
Precisión = 99.9%, lo cual es demasiado alto para ser realista.
Se detectó sobreajuste, ya que Previous_Scores predecía High_Score casi perfectamente.
Conclusión: No es un modelo útil para este análisis

##### 2. Random Forest
Se probó Random Forest para capturar relaciones no lineales entre variables.

```{r}
# Cargar librerías necesarias
library(randomForest)
library(caret)

# Dividir datos en entrenamiento (70%) y prueba (30%)
set.seed(42)
trainIndex <- createDataPartition(df_cleaned$High_Score, p = 0.7, list = FALSE)
trainData <- df_cleaned[trainIndex, ]
testData  <- df_cleaned[-trainIndex, ]

# Entrenar el modelo Random Forest (corrigiendo parámetros)
rf_model <- randomForest(factor(High_Score) ~ ., 
                         data = trainData %>% select(-Exam_Score), 
                         ntree = 200,  # Reducimos el número de árboles
                         mtry = floor(sqrt(ncol(trainData) - 1)),  # Ajustamos número de variables por árbol
                         importance = TRUE)

# Hacer predicciones en el conjunto de prueba
rf_pred <- predict(rf_model, newdata = testData, type = "class")

# Evaluar precisión del modelo
rf_accuracy <- mean(rf_pred == testData$High_Score)
print(paste("Random Forest Accuracy:", rf_accuracy))

# Matriz de confusión
rf_conf_matrix <- table(Predicted = rf_pred, Actual = testData$High_Score)
print("Random Forest Confusion Matrix:")
print(rf_conf_matrix)

# Importancia de las variables
importance_df <- as.data.frame(importance(rf_model))
importance_df$Variable <- rownames(importance_df)
importance_df <- importance_df[order(-importance_df$MeanDecreaseGini), ]

# Visualizar importancia de variables
print("Variable Importance in Random Forest:")
print(importance_df)

# Visualización gráfica de importancia de variables
library(ggplot2)
ggplot(importance_df, aes(x = reorder(Variable, -MeanDecreaseGini), y = MeanDecreaseGini)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Importancia de Variables en Random Forest", x = "Variables", y = "Importancia Gini")



```
#### 3. XGBoost

```{r}
# Cargar librería
library(xgboost)

# Preparar datos en formato de matriz para XGBoost
train_matrix <- model.matrix(High_Score ~ . -1, data = trainData %>% select(-Exam_Score))
test_matrix  <- model.matrix(High_Score ~ . -1, data = testData %>% select(-Exam_Score))

# Convertir a formato DMatrix de XGBoost
dtrain <- xgb.DMatrix(data = train_matrix, label = trainData$High_Score)
dtest  <- xgb.DMatrix(data = test_matrix, label = testData$High_Score)

# Definir hiperparámetros del modelo
params <- list(
  objective = "binary:logistic",  # Clasificación binaria
  eval_metric = "error",  # Evaluar por tasa de error
  eta = 0.1,  # Tasa de aprendizaje
  max_depth = 6,  # Profundidad máxima del árbol
  subsample = 0.8,  # Porcentaje de muestras usadas en cada iteración
  colsample_bytree = 0.8  # Proporción de variables usadas en cada árbol
)

# Entrenar el modelo XGBoost
set.seed(42)
xgb_model <- xgb.train(params, dtrain, nrounds = 100, watchlist = list(train = dtrain, test = dtest), verbose = 0)

# Hacer predicciones
xgb_pred_prob <- predict(xgb_model, dtest)
xgb_pred <- ifelse(xgb_pred_prob > 0.5, 1, 0)

# Evaluar precisión del modelo
xgb_accuracy <- mean(xgb_pred == testData$High_Score)
print(paste("XGBoost Accuracy:", xgb_accuracy))

# Matriz de confusión
xgb_conf_matrix <- table(Predicted = xgb_pred, Actual = testData$High_Score)
print("XGBoost Confusion Matrix:")
print(xgb_conf_matrix)

# Importancia de variables en XGBoost
importance_matrix <- xgb.importance(model = xgb_model)
print("Feature Importance in XGBoost:")
print(importance_matrix)

```



#### 4. Árbol de Decisión




```{r}
# Cargar librerías necesarias
library(rpart)
library(rpart.plot)
library(ggplot2)

# Dividir datos en entrenamiento y prueba
set.seed(42)
trainIndex <- createDataPartition(df_cleaned$Improved, p = 0.7, list = FALSE)
trainData <- df_cleaned[trainIndex, ]
testData  <- df_cleaned[-trainIndex, ]

# Entrenar el Árbol de Decisión Optimizado
tree_model <- rpart(Improved ~ ., 
                    data = trainData %>% select(-Exam_Score, -Previous_Scores, -Score_Improvement), 
                    method = "class", 
                    control = rpart.control(cp = 0.005, minsplit = 10, maxdepth = 7))

# Mejora de la visualización con rpart.plot()
rpart.plot(tree_model, 
           type = 2,  # Árbol detallado con nodos rectangulares
           extra = 104,  # Mostrar porcentaje de datos en cada nodo
           box.palette = "BuGn",  # Paleta de colores para los nodos
           tweak = 1.2,  # Ajuste del tamaño del árbol
           main = "Árbol de Decisión Mejorado")

# Guardar imagen en alta resolución
png("Decision_Tree_Optimized.png", width = 1200, height = 800)
rpart.plot(tree_model, type = 2, extra = 104, box.palette = "BuGn", tweak = 1.2, main = "Árbol de Decisión Mejorado")
dev.off()

# Hacer predicciones con el modelo optimizado
tree_pred <- predict(tree_model, newdata = testData, type = "class")

# Evaluar el modelo optimizado
tree_accuracy <- mean(tree_pred == testData$Improved)
tree_conf_matrix <- table(Predicted = tree_pred, Actual = testData$Improved)

# Mostrar resultados
print(paste("Optimized Decision Tree Accuracy:", tree_accuracy))
print("Optimized Decision Tree Confusion Matrix:")
print(tree_conf_matrix)

```

* Si un estudiante ya tiene una calificación alta (High_Score = 1), no se espera una mejora significativa. Es decir, los estudiantes con alto rendimiento tienen menos margen de mejora.

* La asistencia a clases es un factor fundamental para mejorar el rendimiento académico. Si la asistencia (Attendance) es menor a 84%, la probabilidad de mejora es baja (35% de mejora).
Si la asistencia es mayor o igual a 84%, se consideran otros factores adicionales que pueden influir en la mejora.

* Si Attendance >= 84%, la distancia al colegio (Distance_from_Home) afecta la mejora:

    * Si un estudiante vive a más de 3 km, la probabilidad de mejora es 33%.
    * Si un estudiante vive a menos de 3 km, se evalúan otros factores como las horas de estudio.
En conclusión, los estudiantes que viven más lejos tienen menos probabilidad de mejorar, posiblemente debido a tiempos de traslado prolongados y fatiga.
Si un estudiante estudia menos de 20 horas semanales, la tutoría (Tutoring_Sessions) se convierte en un factor relevante:

* Si Tutoring_Sessions < 0.38, la probabilidad de mejorar es 41%.
Si Tutoring_Sessions >= 0.38, la probabilidad de mejora aumenta a 54%.

*Si un estudiante estudia más de 20 horas semanales, la probabilidad de mejorar es 57%. Sin embargo, en este caso, el nivel de involucramiento parental (Parental_Involvement) comienza a ser un factor clave:

* Si Parental_Involvement < 3, la asistencia del estudiante se vuelve un elemento determinante:
    * Si Attendance < 97%, la probabilidad de mejora es 13%.
    * Si Attendance >= 97%, la probabilidad de mejora aumenta a 33%.
* Si Parental_Involvement >= 3, la probabilidad de mejora es 67%.
En conclusión, estudiar más de 20 horas a la semana aumenta significativamente la probabilidad de mejora. Para los estudiantes con menos horas de estudio, recibir tutorías ayuda a mejorar su rendimiento. Además, un alto nivel de involucramiento parental y una asistencia superior al 97% pueden compensar la falta de apoyo familiar.




```{r}
# Cargar librerías necesarias
library(ggplot2)
library(gganimate)
library(gifski)
library(rpart)
library(dplyr)

# Dividir datos en entrenamiento y prueba
set.seed(42)
trainIndex <- createDataPartition(df_cleaned$Improved, p = 0.7, list = FALSE)
trainData <- df_cleaned[trainIndex, ]
testData  <- df_cleaned[-trainIndex, ]

# Entrenar el Árbol de Decisión
tree_model <- rpart(Improved ~ Attendance + Hours_Studied + Tutoring_Sessions, 
                    data = trainData, 
                    method = "class", 
                    control = rpart.control(cp = 0.005, minsplit = 10, maxdepth = 4))

# Definir los pasos del árbol con etiquetas mejoradas
testData <- testData %>%
  mutate(
    step = case_when(
      Attendance < 84 ~ "Paso 1: Asistencia < 84% (Rojo)", 
      Hours_Studied < 20 ~ "Paso 2: Horas de Estudio < 20 (Azul)", 
      Tutoring_Sessions < 0.38 ~ "Paso 3: Tutorías < 0.38 (Verde)", 
      TRUE ~ "Paso 4: Segmentación Final (Morado)"
    ),
    classification = as.factor(Improved) # Guardamos la clasificación
  )

# Asignar colores a las fases del árbol
color_mapping <- c("Paso 1: Asistencia < 84% (Rojo)" = "red", 
                   "Paso 2: Horas de Estudio < 20 (Azul)" = "blue", 
                   "Paso 3: Tutorías < 0.38 (Verde)" = "green",
                   "Paso 4: Segmentación Final (Morado)" = "purple")

# Asignar colores específicos a la clasificación
classification_colors <- c("0" = "black", "1" = "yellow") # Mayor contraste

# Crear una tabla con las reglas del árbol
tree_rules <- data.frame(
  step = c(1, 2, 3, 4), 
  rule = c(
    "Inicio: Todos los datos",
    "División: Asistencia < 84%",
    "División: Horas de Estudio < 20",
    "División: Tutorías < 0.38"
  )
)

# Crear la animación con colores mejorados y movimiento más fluido
animated_plot <- ggplot(testData, aes(x = Attendance, y = Hours_Studied, 
                                      color = classification)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_vline(xintercept = 84, linetype = "dashed", color = "red", size = 1) +  # Regla de asistencia
  geom_hline(yintercept = 20, linetype = "dashed", color = "blue", size = 1) + # Regla de horas de estudio
  labs(title = "Proceso de Decisión en el Árbol de Decisión", 
       subtitle = "{tree_rules$rule[as.integer(frame_time)]}", 
       x = "Asistencia (%)", 
       y = "Horas de Estudio por Semana") +
  scale_color_manual(values = classification_colors, name = "Clasificación Final") +  # Ahora los colores representan 0 o 1
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        plot.subtitle = element_text(size = 12)) +
  transition_states(as.integer(as.factor(step)), 
                    transition_length = 4, # Hace la transición más larga y fluida
                    state_length = 2) + # Tiempo de pausa entre pasos reducido para continuidad
  ease_aes('linear')  # Movimiento más continuo

# Guardar y mostrar animación con duración más lenta y fluida
animate(animated_plot, duration = 12, fps = 8, renderer = gifski_renderer()) # 12s de duración
anim_save("decision_tree_animation_smooth.gif")


```
```{r}
# Cargar librerías necesarias
library(plotly)
library(rpart)
library(dplyr)

# Dividir datos en entrenamiento y prueba
set.seed(42)
trainIndex <- createDataPartition(df_cleaned$Improved, p = 0.7, list = FALSE)
trainData <- df_cleaned[trainIndex, ]
testData  <- df_cleaned[-trainIndex, ]

# Entrenar el Árbol de Decisión
tree_model <- rpart(Improved ~ Attendance + Hours_Studied + Tutoring_Sessions, 
                    data = trainData, 
                    method = "class", 
                    control = rpart.control(cp = 0.005, minsplit = 10, maxdepth = 4))

# Definir los pasos del árbol
testData <- testData %>%
  mutate(
    step = case_when(
      Attendance < 84 ~ "Paso 1: Asistencia < 84%",
      Hours_Studied < 20 ~ "Paso 2: Horas de Estudio < 20",
      Tutoring_Sessions < 0.38 ~ "Paso 3: Tutorías < 0.38",
      TRUE ~ "Paso 4: Segmentación Final"
    )
  )

# Crear la visualización interactiva
interactive_plot <- plot_ly(testData, x = ~Attendance, y = ~Hours_Studied, color = ~step, 
                            colors = c("red", "blue", "green", "purple"),
                            type = 'scatter', mode = 'markers',
                            text = ~paste("Tutorías:", Tutoring_Sessions, "<br>Mejora:", Improved)) %>%
  layout(title = "Evolución de las Decisiones en el Árbol de Decisión",
         xaxis = list(title = "Asistencia (%)"),
         yaxis = list(title = "Horas de Estudio por Semana"),
         legend = list(title = list(text = "Etapa de Segmentación")))

# Mostrar el gráfico interactivo
interactive_plot

```

