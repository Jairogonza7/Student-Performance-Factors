---
title: "R Notebook"
output: html_notebook
---

## Descripción del dominio

El rendimiento académico es un tema clave en la educación, ya que influye directamente en las oportunidades que tendrán los jovenes en el día de mañana y en el desarrollo de nuestra sociedad. Comprender qué factores afectan al desempeño de los estudiantes permitirá a las instituciones educativas a mejorar los métodos de enseñanza, diseñar políticas educativas más efectivas y proporcionar un mayor apoyo a aquellos estudiantes que lo necesiten.

### Enfoque del Trabajo

Este estudio analiza los factores que influyen en el rendimiento académico de los estudiantes. Para ello, se hace uso de datos relacionados con aspectos personales, sociales y académicos para identificar patrones y determinar qué variables tienen mayor impacto en el desempeño escolar.

En particular, el estudio se enfoca en responder dos preguntas fundamentales:

1.  **¿Se pueden agrupar a los estudiantes en una clase según sus características?**\
    La organización de los estudiantes dentro del aula puede influir significativamente en su aprendizaje y rendimiento. Por esta razón, se explorará la posibilidad de segmentar a los alumnos con base en características clave como sus calificaciones previas, el tiempo dedicado al estudio, su nivel de motivación, la presencia de discapacidades de aprendizaje y su participación en actividades extracurriculares.

    Este enfoque permitirá una distribución estratégica que potencie el aprendizaje al ubicar a los estudiantes en entornos que favorezcan su desarrollo académico y personal.

2.  **¿Cuántas horas de trabajo personal necesita un estudiante para obtener una alta calificación?**\
    Otro objetivo del estudio es determinar cuántas horas diarias de estudio autónomo son necesarias para que un estudiante alcance una calificación alta (entre 8 y 10). Para ello, se identificarán aquellos factores que tengan mayor influencia con la calificación del estudiante, ya que estos aspectos pueden influir en el rendimiento académico. A través de un modelo de regresión, se buscará cuantificar la relación entre estas variables y el desempeño estudiantil, proporcionando una guía para optimizar los hábitos de estudio.

A través de este análisis, se pretende aportar información valiosa para mejorar las estrategias educativas, optimizar la distribución de los estudiantes en el aula y ofrecer recomendaciones que permitan a los alumnos maximizar su rendimiento académico.

### Interés y motivación del estudio

El mundo en el que vivimos está en constante transformación. Los sistemas educativos, como muchos otros aspectos de nuestra sociedad, deben adaptarse a nuevas realidades y desafíos. En este contexto, resulta crucial comprender los factores que influyen en el rendimiento académico de los estudiantes, con el objetivo de mejorar los procesos de enseñanza y crear un entorno de aprendizaje más inclusivo y eficaz. Lo interesante de este estudio radica en identificar patrones y relaciones entre distintas variables que podrían tener un impacto directo en la forma en que los estudiantes aprenden y se desarrollan.

En particular, nos gustaría subrayar que el rendimiento académico no depende únicamente de la capacidad intelectual del estudiante, sino también de factores como el apoyo familiar, los hábitos de estudio, la motivación personal y la presencia de discapacidades de aprendizaje. Este enfoque permite adoptar una perspectiva más personalizada de la educación, lo que a su vez puede contribuir a una mejor planificación y diseño de estrategias pedagógicas más adaptadas a las necesidades de los estudiantes.

En el grupo de desarrollo de este trabajo, nos encontramos tanto estudiantes de **Ingeniería Informática** como de **Ingeniería de la Salud**. Esta diversidad de perspectivas y formaciones académicas enriquece el enfoque del estudio, ya que, desde distintas disciplinas, reconocemos la importancia de crear un entorno educativo que no solo se base en el rendimiento académico, sino también en el bienestar y las capacidades individuales de cada estudiante. Al ser nosotros mismos estudiantes, sabemos de primera mano que las aulas son cada vez más diversas, y entender cómo organizar y distribuir a los estudiantes de acuerdo con sus necesidades específicas es clave para optimizar su rendimiento.

### **Importancia local/nacional y en el contexto actual**

A nivel global, la educación es un pilar fundamental para el desarrollo. Países con bajos índices de rendimiento académico suelen enfrentar mayores desafíos económicos y sociales. Además, en un contexto postpandemia, donde la enseñanza a distancia ha cambiado la forma en que los estudiantes aprenden, es más importante que nunca entender qué factores afectan su desempeño y cómo pueden optimizarse los procesos de enseñanza.

## Descripción del dataset

El dataset ha sido extraído de la plataforma Kaggle y proporcionado por el usuario *lainguyn123*. Se puede acceder al conjunto de datos a través del siguiente enlace: [Student Performance Factors Dataset](https://www.kaggle.com/datasets/lainguyn123/student-performance-factors/data).

El archivo que contiene el conjunto de datos se denomina *StudentPerformanceFactors* y está en formato **CSV**, con un tamaño aproximado de **641 kB**.

Este conjunto de datos proviene de una investigación que analiza los factores que afectan el rendimiento académico de los estudiantes. Incluye diversas variables relacionadas con características personales, académicas y sociales, tales como hábitos de estudio, asistencia, participación de los padres, y otros aspectos clave que influyen en el éxito académico de los estudiantes.

En cuanto a sus dimensiones, el dataset consta de un total de:

-   **6,607 Filas**

-   **20 Columnas**

## Librerías

La función ipak está diseñada para facilitar la instalación y carga de paquetes en R. Es útil cuando desea asegurarse de que todos los paquetes necesarios para un script o proyecto se instalan y cargan automáticamente. <https://gist.github.com/stevenworthington/3178163>

```{r}
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if(length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("tidyverse","ggplot2", "dplyr","gridExtra", "reshape2", "car", "ggridges", "factoextra", "cluster", "NbClust")
ipak(packages)
```

## Exploración de datos

### Lectura de los datos

```{r}
data <- read.csv("data/StudentPerformanceFactors.csv", header=TRUE)
```

### Visualizar las 6 primeras instancias del data frame

```{r}
head(data)
```

### Estructura resumida del data frame

```{r}
str(data)
```

El dataset está compuesto por 6,607 filas y 20 columnas, las cuales incluyen atributos de distintos tipos: numéricos, categóricos y booleanos.

A continuación, se describen algunos de estos atributos:

-   **Hours_Studied**: Número de horas de estudio semanales.

-   **Attendance**: Porcentaje de clases a las que ha asistido.

-   **Parental_Involvement**: Nivel de implicación de los padres en la educación del alumno *(Low, Medium, High)*.

-   **Access_to_Resources**: Disponibilidad de recursos educativos *(Low, Medium, High)*.

-   **Extracurricular_Activities**: Participación en actividades extraescolares *(Yes, No)*.

-   **Sleep_Hours**: Número medio de horas de sueño por noche.

-   **Previous_Scores**: Puntuaciones de exámenes anteriores.

-   **Motivation_Level**: Nivel de motivación del estudiante *(Low, Medium, High)*.

-   **Internet_Access**: Disponibilidad de acceso a Internet *(Yes, No)*.

-   **Tutoring_Sessions**: Número de sesiones de tutoría a las que asiste al mes.

-   **Family_Income**: Nivel de ingresos familiares *(Low, Medium, High)*.

-   **Teacher_Quality**: Calidad de los profesores *(Low, Medium, High)*.

-   **School_Type**: Tipo de escuela a la que asistió *(Public, Private)*.

-   **Peer_Influence**: Influencia de los compañeros en el rendimiento académico *(Positive, Neutral, Negative)*.

-   **Physical_Activity**: Número medio de horas de actividad física a la semana.

-   **Learning_Disabilities**: Presencia de dificultades de aprendizaje *(Yes, No)*.

-   **Parental_Education_Level**: Nivel educativo más alto de los padres *(High School, College, Postgraduate)*.

-   **Distance_from_Home**: Distancia de casa a la escuela *(Near, Moderate, Far)*.

-   **Gender**: Género del estudiante *(Male, Female)*.

-   **Exam_Score**: Calificación del examen final.

## Preprocesamiento de los datos

Esta función muestra las filas con valores NA o valores vacios("").

```{r}
detect_missing_data <- function(df) {
  na_count <- colSums(is.na(df))  # Contar los NA en cada columna
  empty_count <- colSums(sapply(df, function(x) x == ""))  # Contar los valores vacíos en cada columna
  
  missing_data <- data.frame(NA_Count = na_count, Empty_Count = empty_count)
  missing_data <- missing_data[missing_data$NA_Count > 0 | missing_data$Empty_Count > 0, ]
  
  return(missing_data)
}


missing_data <- detect_missing_data(data)
missing_data
```

En el resultado arrojado por la función podemos observar que no existen valores **NA** en las columnas de nuestro dataframe, lo que significa que no hay datos explícitamente faltantes o nulos. Sin embargo, también notamos que hay filas con **valores vacíos** en ciertas variables categóricas.

Al sumar el total de valores faltantes podemos observar que puede haber un máximo de **235 filas** con algún valor faltante. Esto supone aproximadamente el **3.56%** del total de filas del conjunto de datos.

Dado que la proporción de filas con valores faltantes es relativamente baja, consideramos eliminar estas instancias ya que creemos que no tendrá un impacto significativo en la integridad general del dataset.

```{r}
clean_missing_data <- function(df) {
  original_row_count <- nrow(df)
  
  df <- df[!apply(df, 1, function(x) any(is.na(x) | x == "")), ] #Borramos las filas
  
  cleaned_row_count <- nrow(df)
  rows_removed <- original_row_count - cleaned_row_count
  cat("Número de filas eliminadas:", rows_removed, "\n")
  
  return(df)
}

data <- clean_missing_data(data)
```

Observamos que se han eliminado 229 filas por lo que el dataset sin ningún valor de faltante constaría de un total de **6378 filas**.

### Detección de outliers

```{r}
numeric_cols <- sapply(data, is.numeric)

count_outliers <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  sum(x < lower_bound | x > upper_bound, na.rm = TRUE)
}


for (col_name in names(data)[numeric_cols]) {
  num_outliers <- count_outliers(data[[col_name]])
  print(paste("Variable:", col_name, "- Outliers:", num_outliers))
}
```

Podemos observar que existen outliers en las variables `Hours_studies`, `Tutoring_Sessions` y `Exam_Score`. Vamos a visualizar dichos valores mediante gráficos de caja para observar la distribución de ciertos valores.

```{r}
plot_boxplots <- function(df) {
  plots <- list()
  numeric_cols <- c("Hours_Studied", "Tutoring_Sessions", "Exam_Score")
  numeric_cols <- numeric_cols[numeric_cols %in% names(df)]
  

  for (var in numeric_cols) {
    p <- ggplot(df, aes_string(y = var)) +
      geom_boxplot(fill = "orange", alpha = 0.7) +
      theme_minimal() +
      labs(title = paste("Outliers in", var), y = var)
    
    plots[[var]] <- p
  }

  for (p in plots) {
    print(p)
  }
}
```

```{r}
plot_boxplots(data)
```

Al observar los gráficos de caja, podemos identificar la presencia de valores atípicos. Sin embargo, algunos de estos valores no deben considerarse como tales. Por ejemplo, 8 horas de tutorías es un valor completamente válido. En cambio, en el gráfico de `Exam_Scores`, se pueden notar calificaciones que superan el valor máximo permitido de 100, lo que indica un posible error en los datos.

Para solucionar esto, filtraremos las filas en las que el valor de `Exam_Score` sea superior a 100 y lo estableceremos a la máxima nota posible, es decir, 100.

```{r}
data$Exam_Score[data$Exam_Score > 100] <- 100
max_Exam_score <- max(data$Exam_Score)
print(max_Exam_score)
```

### Codificación

Para preparar los datos de manera óptima para el análisis, aplicamos varias transformaciones a las variables categóricas y ordinales. Esto nos permite estructurar la información de manera que los modelos puedan interpretarla correctamente.

Con esta función convertimos las columnas del data frame en factores ordenados y les asignamos valores enteros, de acuerdo con un orden específico de niveles. Esto es util para las variables que tienen una relación de orden o tienen un nivel jerárquico o progresivo, es decir, que pueden compararse en términos de más o menos, mejor o peor, mayor o menor.

-   `Parental_Involvement`,`Access_to_Resources`,`Motivation_Level`,`Family_Income`,`Teacher_Quality` Estas variables pueden ordenarse de menor a mayor o viceversa".

-   En `Peer_Influence`, **Positive \> Neutral \> Negative** en términos de impacto en el rendimiento. Por lo que tambien se pueden ordenar.

-   En `Distance_from_Home` ordenamos los valores en términos de **nivel de cercanía** de la escuela a la casa del estudiante.

-   En `Parental_Education_Level` ordenamos los valores en términos de **nivel de estudio de los padres**. Desde menos estudios (High School) hasta más estudios (Postgraduate).

```{r}
convert_to_ordered_int <- function(df, column_names, levels_order, ordered = TRUE) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      df[[col]] <- as.integer(factor(df[[col]], levels = levels_order, ordered = ordered))
    }
  }
  return(df)
}

```

Algunas variables categóricas contienen únicamente valores "Yes" o "No", por lo que es más eficiente transformarlas en valores 0 y 1, 'No' y 'Yes', respectivamente.

Las variables modificadas serán:

-   `Extracurricular_Activities`, `Internet_Access`, `Learning_Disabilities` → Yes = 1, No = 0

```{r}
convert_to_binary <- function(df, column_names) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      df[[col]] <- ifelse(df[[col]] == "Yes", 1, 0)
    }
  }
  return(df)
}

```

Algunas variables no tienen una jerarquía clara, por lo que en lugar de asignar valores ordinales, creamos columnas binarias (dummies) para cada categoría, es decir, aplicamos One-Hot Encoding.

-   `School_Type` pasará a dividirse en dos columnas: `School_Type_Public` y `School_Type_Private`
-   `Gender` se convierte en `Gender_Male` y `Gender_Female`.

```{r}
convert_to_one_hot <- function(df, column_names) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      unique_values <- unique(df[[col]])
      for (val in unique_values) {
        new_col_name <- paste(col, val, sep = "_")
        df[[new_col_name]] <- ifelse(df[[col]] == val, 1, 0)
      }
      df[[col]] <- NULL  # Eliminamos la columna original después de crear las dummy variables
    }
  }
  return(df)
}

```

```{r}
clean_and_filter_data <- function(data) {
  data <- data %>%
    distinct() %>%
    
    # Convertir a valores ordenados (Low < Medium < High)
    convert_to_ordered_int(c("Parental_Involvement", "Access_to_Resources", "Motivation_Level",
                              "Family_Income", "Teacher_Quality"),
                           c("Low", "Medium", "High")) %>%
    
    # Convertir Peer_Influence en valores ordenados (Negative < Neutral < Positive)
    convert_to_ordered_int("Peer_Influence", c("Negative", "Neutral", "Positive")) %>%
    
    # Convertir Parental Education Level en valores ordenados (High School < College < Postgraduate)
    convert_to_ordered_int("Parental_Education_Level", c("High School", "College", "Postgraduate")) %>%
    
    # Convertir Distance_from_Home en valores ordenados (Near < Moderate < Far)
    convert_to_ordered_int("Distance_from_Home", c("Near", "Moderate", "Far")) %>%
    
    # Convertir a valores binarios (No = 0, Yes = 1)
    mutate(
      Extracurricular_Activities = ifelse(Extracurricular_Activities == "Yes", 1, 0),
      Internet_Access = ifelse(Internet_Access == "Yes", 1, 0),
      Learning_Disabilities = ifelse(Learning_Disabilities == "Yes", 1, 0)
    ) %>%
    
    # Aplicar One-Hot Encoding a School_Type y Gender
    mutate(
      School_Type_Private = ifelse(School_Type == "Private", 1, 0),
      School_Type_Public = ifelse(School_Type == "Public", 1, 0),
      Gender_Male = ifelse(Gender == "Male", 1, 0),
      Gender_Female = ifelse(Gender == "Female", 1, 0)
    ) %>%
    
    # Eliminar las columnas originales después de One-Hot Encoding
    select(-School_Type, -Gender)

  return(data)
}

```

```{r}
df_cleaned <- clean_and_filter_data(data)
```

```{r}
df_cleaned
```

Después de la codificación, nuestro dataset consta de estos tipos:

```{r}
str(df_cleaned)
```

### Escalarización

Para que el análisis sea óptimo, también es necesario escalar las variables.

-   `Sleep_Hours` toma como valor las horas de sueño por noche. Supondremos que el estudiante duerme esta cantidad de horas todos los días por lo que modificaremos el valor para que sean horas semanales (Multiplicamos por 7 las horas de sueño diarias).

-   `Tutoring_Sessions` toma como valor las sesiones de tutoria por mes. Para escalar esta variable, se tomará 1 sesión de tutoría = 1 hora y a su vez, se pasará a horas semanales. Por ejemplo, si un estudiante tiene `Tutoring_Sessions` = 4 en un mes, significa que tiene 1 por semana (`Tutoring_Sessions`/ 4 semanas).

```{r}
scale_time_variables <- function(df) {
  df <- df %>%
    mutate(
      Sleep_Hours = Sleep_Hours * 7,  # Convertir de horas por noche a horas por semana
      Tutoring_Sessions = Tutoring_Sessions / 4  # Convertir sesiones a horas/semana
    )
  return(df)
}

df_cleaned <- scale_time_variables(df_cleaned)

print("Sleep_Hours:") 
summary(df_cleaned$Sleep_Hours)  # Debería estar en un rango de 0-56 horas semanales
print("Tutoring_Sessions:")
summary(df_cleaned$Tutoring_Sessions)  # Ahora representará horas de tutoría por semana


```

Como puede observarse, para las horas de sueño semanales, el mínimo es 28, lo cual significa que hay estudiantes que duermen 4 horas por noche (4 \* 7 = 28). La mediana es 49, lo que indica que la mayoría de los estudiantes duermen aproximadamente 7 horas por noche (7 \* 7 = 49). El máximo es 70, lo que implica que algunos estudiantes duermen 10 horas por noche (10 \* 7 = 70).

Por otro lado, para las horas de tutoría por semana, el mínimo es 0, lo cual es correcto, ya que algunos estudiantes no tienen sesiones de tutoría. La mediana es 0.25, lo que significa que muchos estudiantes tienen 1 sesión por mes (1 hora / 4 = 0.25 horas/semana). El máximo es 2, lo que indica que algunos estudiantes tienen 8 sesiones de tutoría por mes, que equivale a 2 horas de tutoría por semana.

## Visualizaciones Iniciales

## Distribución de variables numéricas

```{r}
create_dist_grap <- function(df, variable, binwidth = 1, fill = "cornflowerblue") {
  if (!(variable %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  ggplot(df, aes_string(x = variable)) +
    geom_histogram(binwidth = binwidth, 
                   fill = fill, color = "black", bins = 20) +
    labs(title = paste(variable, "analysis"), x = variable, y = "Count") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5))
}

create_dist_grap(data, "Sleep_Hours")
create_dist_grap(data, "Hours_Studied")
create_dist_grap(data, "Tutoring_Sessions")
create_dist_grap(data, "Attendance", binwidth = 5)
create_dist_grap(data, "Previous_Scores")
create_dist_grap(data, "Exam_Score", fill = "orange")
```

## Distribución de variables categóricas

```{r}
create_pie_chart <- function(df, var_name) {
  if (!(var_name %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  dist_var <- as.data.frame(table(df[[var_name]]))
  colnames(dist_var) <- c(var_name, "Count")
  dist_var$Percentage <- round(dist_var$Count / sum(dist_var$Count) * 100, 1)
  

  ggplot(dist_var, aes(x = "", y = Count, fill = get(var_name))) +
    geom_bar(stat = "identity", width = 1) +
    coord_polar(theta = "y") +
    geom_text(aes(label = paste0(Percentage, "%")), position = position_stack(vjust = 0.5), size = 5) +
    labs(title = paste("Distribución de", var_name), fill=var_name) +
    theme_minimal() +
    theme(axis.text.x = element_blank(), 
          axis.ticks = element_blank(),
          panel.grid = element_blank())
}
```

```{r}
create_pie_chart(data, "Parental_Involvement")
create_pie_chart(data, "Access_to_Resources")
create_pie_chart(data, "Parental_Education_Level")
create_pie_chart(data, "Distance_from_Home")
create_pie_chart(data, "Extracurricular_Activities")
create_pie_chart(data, "School_Type")
create_pie_chart(data, "Gender")
```

## Preguntas

### ¿**Se pueden agrupar a los estudiantes en una clase según sus características?**

-   **Objectivo**: Intentar asignar a los alumnos a grupos de manera que se favorezca su aprendizaje.

En primer lugar, decidimos una estrategia a adoptar para agrupar a los alumnos. Nos enfocamos en diferentes variables según el objetivo a cumplir:

-   **Academic**: Nos interesamos en las variables que reflejan el éxito escolar en términos académicos, como la asistencia, el número de horas de estudio o los resultados obtenidos.

-   **Support**: Aquí, el enfoque está en las necesidades de apoyo del alumno. ¿Necesita horas de tutoría? ¿Tiene dificultades para aprender?

-   **Resource**: ¿Dispone el alumno de los recursos necesarios para favorecer su aprendizaje?

-   **Extra**: Variables relacionadas con el ocio y la vida social. ¿Tiene el alumno actividades extracurriculares? ¿Cuáles son sus relaciones de amistad?

-   **General**: Todas las variables. ¿Que grupos conforman estos datos?

```{r}
academic_columns <- c("Hours_Studied", "Attendance", "Exam_Score", "Previous_Scores")
support_columns <- c("Learning_Disabilities", "Tutoring_Sessions", "Access_to_Resources")
resource_columns <- c("Family_Income", "Access_to_Resources", "Internet_Access", "Parental_Education_Level")
extra_columns <- c("Extracurricular_Activities", "Physical_Activity", "Peer_Influence")
general_columns <- c(
  "Hours_Studied",
  "Attendance",
  "Parental_Involvement",
  "Access_to_Resources",
  "Extracurricular_Activities",
  "Sleep_Hours",
  "Previous_Scores",
  "Motivation_Level",
  "Internet_Access",
  "Tutoring_Sessions",
  "Family_Income",
  "Teacher_Quality",
  "School_Type_Private",
  "School_Type_Public",
  "Peer_Influence",
  "Physical_Activity",
  "Learning_Disabilities",
  "Parental_Education_Level",
  "Distance_from_Home",
  "Gender_Male",
  "Gender_Female",
  "Exam_Score"
)
```

```{r}
df_scaled = as_tibble(scale(df_cleaned))

data_for_cluster_academic <- select(df_scaled, all_of(academic_columns))
data_for_cluster_support <- select(df_scaled, all_of(support_columns))
data_for_cluster_resource <- select(df_scaled, all_of(resource_columns))
data_for_cluster_extra <- select(df_scaled, all_of(extra_columns))
data_for_cluster_general <- select(df_scaled, all_of(general_columns))
```

Para agrupar a los alumnos según estas categorías, utilizaremos el método de **clustering K-Means**.

Primero, definimos una función que nos permita seleccionar el mejor valor de **K**.

```{r}
compare_k <- function(df) {
  print(fviz_nbclust(df, kmeans, method = "wss") + 
    ggtitle("Elbow Method for Optimal K"))

  print(fviz_nbclust(df, kmeans, method = "silhouette") + 
    ggtitle("Silhouette Method for Optimal K"))
}
```

Luego, definimos una función que aplique el clustering y añada la variable **cluster** a nuestro conjunto de datos inicial.

```{r}
applying_kmeans <- function(data_for_clustering, k){
  set.seed(42)
  kmeans_model <- kmeans(data_for_clustering, centers = k, nstart = 25)
  df_with_cluster <- as_tibble(df_cleaned)
  df_with_cluster$Cluster <- as.factor(kmeans_model$cluster)
  return(df_with_cluster)
}
```

Finalmente, definimos una función que nos permita **comparar los grupos formados**:\
- ¿Cuántos alumnos hay en cada cluster?\
- Comparación de las variables utilizadas en el clustering mediante **ridgeline plots**.

```{r}
print_clustering_results <- function(df_with_clusters, data_for_cluster, columns_to_focus){
  cluster_summary <- df_with_clusters %>%
    group_by(Cluster) %>%
    summarise(
      Num_Students = n()
    )
  
  print(ggplot(cluster_summary, aes(x = as.factor(Cluster), y = Num_Students, fill = as.factor(Cluster))) +
          geom_bar(stat = "identity") +
          labs(title = "Number of Students in Each Cluster", x = "Cluster", y = "Student Count") +
          theme_minimal())
  
  for (column in columns_to_focus) {
    print(ggplot(df_with_clusters, aes(x = as.factor(Cluster), y = !!sym(column), fill = as.factor(Cluster))) +
            geom_boxplot() +
            labs(title = paste(column, "Distribution in Each Cluster"), x = "Cluster", y = column) +
            theme_minimal())
  }
  
  print(fviz_cluster(list(data = data_for_cluster, cluster = df_with_clusters$Cluster),
                     geom = "point",
                     ellipse.type = "convex",
                     ggtheme = theme_minimal(),
                     main = "Cluster Visualization (PCA Projection)"))
}

```

```{r}
find_optimal_clusters <- function(data) {
  
  result <- NbClust(data, diss = NULL, distance = "euclidean", 
                    min.nc = 2, max.nc = 4, method = "kmeans")
  
  # Retorna el número óptimo de clusters sugerido
  return(result)
}
```

#### Academic

```{r}
compare_k(data_for_cluster_academic)
```

```{r}
optimal_clusters_academic <- find_optimal_clusters(data_for_cluster_academic)

```

Analizando las gráficas del método del Codo (Elbow Method) y del Coeficiente de Silhouette, llegamos a la conclusión de que el número óptimo de clústeres es 𝑘 = 2 k=2.

Esta conclusión se fundamenta en dos aspectos clave:

**Método del Codo (Elbow Method)**: En esta gráfica, observamos que la mayor reducción en la suma de cuadrados dentro del grupo ocurre hasta 𝑘 = 2 k=2, formando un punto de inflexión o "codo" en ese valor. A partir de 𝑘 = 2 k=2, la disminución en la varianza interna de los clústeres se vuelve menos pronunciada, lo que indica que agregar más clústeres no aporta una mejora significativa en la compactación de los datos.

**Coeficiente de Silhouette (Silhouette Method)**: Este método mide la calidad de la agrupación en función de la cohesión interna y la separación entre clústeres. En la gráfica correspondiente, el valor más alto del coeficiente de Silhouette se encuentra en 𝑘 = 2 k=2, lo que indica que, con este número de clústeres, los grupos están bien diferenciados y los puntos dentro de cada clúster son más homogéneos.

Basándonos en la evaluación de múltiples criterios de clustering mediante `NbClust`, el número óptimo de clusters en los datos es **2**, ya que recibió la mayor cantidad de votos. Esto sugiere que los datos tienen dos grupos bien diferenciados, lo que puede ser validado adicionalmente con métricas como el índice de silueta o gráficos de PCA

Dado que todos los métodos coinciden en que 𝑘 = 2 es el valor óptimo, podemos concluir que dividir los datos en dos grupos proporciona una segmentación adecuada, asegurando un equilibrio entre la reducción de la variabilidad interna y la claridad en la separación entre clústeres.

```{r}
df_cluster_academic <- applying_kmeans(data_for_cluster_academic, 2)
```

```{r}
print_clustering_results(df_cluster_academic, data_for_cluster_academic, academic_columns)
```

El Clúster 1 está compuesto por estudiantes que dedican más horas al estudio en comparación con los del Clúster 2. Sin embargo, la diferencia más notable entre ambos grupos radica en la asistencia a clase, ya que los alumnos del Clúster 1 muestran un nivel de asistencia significativamente mayor. Este factor parece desempeñar un papel clave en su rendimiento académico, ya que la combinación de una mayor dedicación al estudio y una participación más activa en las clases les permite obtener resultados más favorables en comparación con los estudiantes del Clúster 2.

Por otro lado, los alumnos del Clúster 2 no solo estudian menos, sino que también presentan un porcentaje de asistencia más bajo, lo que podría afectar negativamente su comprensión de los contenidos y, en consecuencia, su desempeño académico. Estos hallazgos sugieren que tanto el tiempo de estudio como la asistencia a clase son factores determinantes en el éxito académico de los estudiantes.

#### Support

```{r}
compare_k(data_for_cluster_support)
```

```{r}
optimal_clusters_support <- find_optimal_clusters(data_for_cluster_support)

```

La primera gráfica sigue el **método del codo**, el cual evalúa la suma de los cuadrados dentro de los clusters (WSS) en función del número de clusters. El punto óptimo se encuentra donde la disminución en WSS se vuelve menos pronunciada, formando un "codo" en la curva. En este caso, se observa un cambio notable en la pendiente alrededor de k=4 y k=8, lo que indica que estos valores podrían ser opciones razonables para segmentar los datos de manera eficiente.

Por otro lado, la segunda gráfica utiliza el **método del Silhouette** para determinar el número óptimo de clusters. En este método, se elige el valor de k que maximiza el índice de silhouette, el cual mide qué tan bien separados están los clusters y qué tan cohesivos son. En la gráfica, el valor más alto de silhouette se alcanza en k=8, lo que sugiere que este número de clusters permite una mejor separación entre los grupos y minimiza la superposición entre ellos.

Basándonos en la evaluación de múltiples criterios de clustering mediante `NbClust`, el número óptimo de clusters en los datos es **4**, ya que recibió la mayor cantidad de votos. Esto sugiere que los datos tienen cuatro grupos bien diferenciados, lo que puede ser validado adicionalmente con métricas como el índice de silueta o gráficos de PCA

En conclusión, aunque el método del codo sugiere que tanto k=4 como k=8 son buenas opciones, el método de Silhouette indica que k=8 ofrece la mejor separación entre clusters. Sin embargo, al aplicar el método de múltiples criterios, k=4 obtuvo la mayor cantidad de votos, superando a las demás opciones por 15 votos. Dado que tanto el método del codo como el de múltiples criterios coinciden en k=4, tomamos esta opción como la más adecuada para el clustering.

```{r}
df_cluster_support <- applying_kmeans(data_for_cluster_support, 4)
```

```{r}
print_clustering_results(df_cluster_support, data_for_cluster_support, support_columns)
```

Tras analizar las distintas gráficas obtenidas en el estudio, se han identificado **tres grupos de alumnos** que no presentan dificultades en el aprendizaje, correspondientes a los **clústeres 1, 2 y 4**. Estos estudiantes no parecen experimentar problemas significativos en su rendimiento académico, lo que sugiere que sus hábitos y patrones de estudio pueden estar alineados con el éxito educativo.

Al comparar estos resultados con la **gráfica de sesiones de tutoría**, se observa que el **clúster 1** es el grupo que registra **más horas de tutoría**, lo que podría indicar un mayor interés o compromiso con el refuerzo académico. Por otro lado, los clústeres **2 y 4** presentan una cantidad similar de sesiones de tutoría, lo que sugiere que no requieren un apoyo adicional significativo. Sin embargo, el caso más preocupante se encuentra en el **clúster 3**, ya que **este grupo sí presenta problemas de aprendizaje, pero no asiste a tutorías**. Esta falta de apoyo podría estar contribuyendo a sus dificultades académicas, lo que sugiere la necesidad de intervenciones específicas para mejorar su desempeño.

En cuanto al **acceso a recursos educativos**, la última gráfica revela que el **clúster 4 es el que más acceso tiene**, ocupando el rango más alto en su totalidad. Esto sugiere que estos alumnos disponen de herramientas adecuadas para su aprendizaje, lo que puede estar relacionado con su buen rendimiento. Los **clústeres 1 y 3** comparten un rango medio de acceso a recursos, aunque con variaciones entre casos de acceso bajo y alto, lo que indica cierta desigualdad en la disponibilidad de materiales. Finalmente, el **clúster 2 presenta el nivel más bajo de acceso a recursos**, lo que podría representar una barrera para su desarrollo académico a largo plazo.

El análisis de los datos ha permitido identificar patrones significativos en el aprendizaje de los alumnos y su relación con las tutorías y el acceso a recursos. Se destaca que el **clúster 3 requiere especial atención**, ya que, a pesar de sus dificultades, **no participa en tutorías**, lo que podría agravar sus problemas. Además, el acceso desigual a recursos educativos podría estar influyendo en el rendimiento de algunos grupos. Estos hallazgos sugieren la importancia de fomentar el uso de tutorías en estudiantes con dificultades y garantizar un acceso equitativo a los recursos educativos para mejorar la calidad del aprendizaje.

#### Resources

```{r}
compare_k(data_for_cluster_resource)
```

```{r}
optimal_clusters_resources <- find_optimal_clusters(data_for_cluster_resource)
```

En la primera imagen, correspondiente al **método de Elbow**, se representa la suma de los cuadrados dentro del cluster (*Total Within Sum of Squares, WSS*) en función del número de clusters (*k*). Este método se basa en encontrar el punto donde la disminución de WSS empieza a desacelerarse de manera significativa, formando una especie de “codo” en la gráfica. En este caso, observamos que la curva muestra una reducción brusca hasta aproximadamente *k = 8*, después de lo cual la disminución de WSS se vuelve menos pronunciada. Esto sugiere que *k = 8* es un buen candidato para el número óptimo de clusters, ya que más allá de este punto la ganancia en términos de reducción de varianza dentro de los clusters es menor.

Por otro lado, en la segunda imagen se muestra el resultado del **método de Silhouette**, el cual mide la calidad de la agrupación en función de la cohesión interna y la separación entre los clusters. El objetivo es encontrar el valor de *k* que maximiza el ancho promedio del coeficiente de silueta, lo que indica que los puntos están bien agrupados dentro de sus respectivos clusters y bien separados de otros clusters. En esta gráfica, el valor más alto del coeficiente de silueta se observa en *k = 2*, lo que sugiere que dos clusters proporcionan la mejor separación según este criterio. Sin embargo, también se observa un valor elevado en *k = 8*, lo que indica que esta cantidad de clusters también es una opción viable.

Basándonos en la evaluación de múltiples criterios de clustering mediante `NbClust`, el número óptimo de clusters en los datos es **4**, ya que recibió la mayor cantidad de votos. Esto sugiere que los datos tienen cuatro grupos bien diferenciados, lo que puede ser validado adicionalmente con métricas como el índice de silueta o gráficos de PCA

El análisis de los diferentes métodos de clustering muestra resultados variados sobre la cantidad óptima de clusters. El método de **Elbow** sugiere que **k = 8** es una buena opción, ya que a partir de este punto la reducción de la varianza dentro de los clusters se desacelera significativamente. Por otro lado, el **método de Silhouette** indica que **k = 2** proporciona la mejor separación entre clusters, aunque también destaca **k = 8** como una alternativa viable. Sin embargo, el método de múltiples criterios de **NbClust** señala que **k = 4** es la mejor opción al haber recibido la mayor cantidad de votos, lo que sugiere la existencia de cuatro grupos bien diferenciados en los datos. Dado que NbClust integra varios enfoques de validación, se considera **k = 4** como el número óptimo de clusters, aunque los valores **k = 2 y k = 8** también pueden ser opciones a considerar dependiendo del criterio de segmentación que se priorice.

```{r}
df_cluster_resource <- applying_kmeans(data_for_cluster_resource, 4)
```

```{r}
print_clustering_results(df_cluster_resource, data_for_cluster_resource, resource_columns)
```

El análisis de la primera gráfica, correspondiente a los **ingresos familiares**, revela diversas diferencias entre los clústeres analizados. En términos generales, la mayoría de los grupos presentan ingresos de nivel medio, aunque existen algunas desviaciones significativas que reflejan desigualdades económicas dentro del conjunto de datos. En particular, los **clústeres 2 y 3** se sitúan dentro del rango de ingresos medios, pero con ciertas diferencias notables. El **clúster 2** muestra una mayor presencia de usuarios con ingresos **medios-bajos**, mientras que el **clúster 3** se inclina levemente hacia los **ingresos medios-altos**, aunque sin una diferencia muy pronunciada. En el caso del **clúster 1**, se observa una tendencia hacia ingresos **medios en su mayoría al alza**, sin presencia destacada de ingresos bajos. Sin embargo, el grupo con la situación económica más delicada es el **clúster 4**, que se distingue por presentar **ingresos íntegramente bajos** en comparación con los demás grupos.

Al relacionar estos hallazgos con la segunda gráfica, correspondiente al **acceso a recursos**, se observa que la mayoría de los clústeres tienen valores medios similares en cuanto a disponibilidad de recursos educativos. No obstante, existen algunas fluctuaciones, con ciertos casos que se inclinan hacia un acceso más limitado o, en otros, con mayores facilidades. Un hallazgo relevante es que, a pesar de que el **clúster 4** presenta los ingresos más bajos, su acceso a recursos no es significativamente menor, lo que sugiere la existencia de **programas de ayuda o becas** que compensan la falta de recursos económicos. Esto indica que, aunque las familias de este grupo tengan menos ingresos, han podido acceder a apoyos que mitigan las desigualdades.

En lo que respecta al **acceso a internet**, se evidencia que el **clúster 2** es el único grupo que presenta un valor negativo, es decir, una menor accesibilidad a la conectividad en comparación con el resto. Este dato plantea dos hipótesis posibles: una primera explicación sería que estas familias **no pueden permitirse el acceso a internet** debido a razones económicas; sin embargo, esta teoría resulta inconsistente si consideramos que el **clúster 4**, que cuenta con los ingresos más bajos, sí tiene acceso a internet. Por lo tanto, una hipótesis más plausible es que en el **clúster 2 las familias han restringido el uso de internet a sus hijos por decisión propia**, probablemente por razones educativas, de control parental o de valores familiares.

En cuanto al **nivel académico de los padres**, se observa que, en términos generales, la mayoría de los grupos presentan un nivel de educación secundaria. No obstante, existen diferencias entre los clústeres. El **clúster 1** se caracteriza por estar compuesto en su totalidad por padres con educación **secundaria**. El **clúster 2** también presenta una mayoría con educación secundaria, aunque con la particularidad de que algunos padres han alcanzado estudios **universitarios y de posgrado**. Por otro lado, el **clúster 4** cuenta principalmente con familias con formación en **educación secundaria y grados universitarios**, aunque sin un predominio de estudios avanzados. La situación más particular se encuentra en el **clúster 3**, donde los padres presentan un nivel de estudios **mínimo de grado universitario**, y en algunos casos, **estudios de posgrado**, lo que indica un nivel académico superior en comparación con el resto de los grupos.

El análisis realizado revela importantes diferencias socioeconómicas entre los clústeres analizados. Se ha identificado que el **clúster 4** es el grupo con menores ingresos, pero gracias a algún tipo de apoyo externo, ha podido mantener un acceso a recursos educativos similar al de los otros grupos. En cuanto a la **conectividad a internet**, el **clúster 2** es el único que presenta restricciones, lo que sugiere que la limitación se debe más a una decisión parental que a factores económicos. Respecto al **nivel educativo de los padres**, se observa que la mayoría han alcanzado la educación secundaria, aunque el **clúster 3 destaca por contar con padres con estudios universitarios y de posgrado en mayor proporción**. Estas diferencias pueden influir en el rendimiento académico y el acceso a oportunidades de aprendizaje, lo que subraya la importancia de analizar estos factores para diseñar estrategias de apoyo adecuadas para cada grupo.

#### Social

```{r}
compare_k(data_for_cluster_extra)
```

```{r}
optimal_clusters_extra <- find_optimal_clusters(data_for_cluster_extra)
```

En el gráfico del **método del codo**, se observa que la "Suma de Cuadrados Dentro del Grupo" (**WSS**) disminuye considerablemente hasta aproximadamente k=3, k=4, momento en el cual la pendiente comienza a estabilizarse. Esto indica que a partir de estos valores, agregar más clusters genera una menor ganancia en la reducción de la variabilidad dentro de los grupos, sugiriendo que k=3 o k=4 son opciones razonables.

Por otro lado, el **método del silhouette** muestra que la mejor cohesión interna y separación entre los clusters se obtiene con k=2, lo que sugiere que dividir los datos en dos grupos maximiza la calidad de la segmentación.

Adicionalmente, el **análisis de múltiples criterios** también ha indicado que el número óptimo de clusters es k=2, ya que ha recibido la mayor cantidad de votos (**8 votos**), superando a k=3 y k=4, que han obtenido **5 votos** cada uno.

Los tres enfoques utilizados coinciden en que k=2 es la opción más sólida para la segmentación de los datos. Tanto el método del silhouette como el análisis de múltiples criterios refuerzan esta elección, indicando que dividir los datos en dos grupos proporciona la mejor cohesión y separación entre clusters. Aunque el método del codo sugería que k=3 o k=4 podrían ser alternativas razonables, la evidencia general respalda la elección de k=2 como el número óptimo de clusters en este caso.

```{r}
df_cluster_extra <- applying_kmeans(data_for_cluster_extra, 2)

```

```{r}
print_clustering_results(df_cluster_extra, data_for_cluster_extra, extra_columns)
```

El análisis de los gráficos permite identificar distintos patrones en la relación entre la participación en **actividades extracurriculares**, la cantidad de **horas dedicadas a la actividad física** y la **influencia de los compañeros** en los alumnos. A través de la observación de estos datos, se pueden extraer conclusiones relevantes sobre cómo estas variables se relacionan entre sí y si tienen algún impacto en la vida social y académica de los estudiantes.

En el primer gráfico, correspondiente a la **realización de actividades extracurriculares**, se observa una diferencia clara entre los dos clústeres analizados. El **clúster 1** agrupa a aquellos alumnos que **no participan en actividades extraescolares**, mientras que el **clúster 2** representa a los estudiantes que sí realizan este tipo de actividades. Esta segmentación permite identificar una distinción clara en los hábitos de los alumnos con respecto a su tiempo fuera del entorno académico, lo que podría tener implicaciones en otros aspectos de su desarrollo personal y social.

En lo que respecta al **rango de horas dedicadas a la actividad física**, se observa que ambos clústeres presentan una distribución similar. Esto indica que la participación o no en actividades extracurriculares no tiene un impacto significativo en el tiempo que los estudiantes dedican a la práctica de ejercicio físico. Es decir, tanto los alumnos que realizan actividades extraescolares como los que no lo hacen mantienen hábitos de actividad física similares, lo que sugiere que otros factores, como la rutina diaria o el estilo de vida familiar, podrían ser más determinantes en este aspecto.

Por último, el análisis de la **influencia de los compañeros** muestra que ambos clústeres presentan una distribución equivalente en esta variable. Esto implica que la **realización de actividades extracurriculares no tiene un impacto significativo en el nivel de influencia que los compañeros ejercen sobre los estudiantes**. En otras palabras, la socialización y las dinámicas de grupo parecen mantenerse estables independientemente de si el alumno participa o no en actividades extracurriculares.

El análisis realizado revela que la participación en **actividades extracurriculares** es una característica diferenciadora entre los clústeres, pero no parece influir en otras variables como la **cantidad de horas dedicadas a la actividad física** ni en el **nivel de influencia de los compañeros**. La similitud en la distribución de estas últimas variables sugiere que la actividad extracurricular no es un factor determinante en los hábitos de ejercicio ni en la socialización de los alumnos. Por lo tanto, la decisión de realizar o no actividades extracurriculares podría estar más relacionada con factores personales o familiares que con un impacto significativo en la vida social o los hábitos de los estudiantes.

#### General

```{r}
compare_k(data_for_cluster_general)
```

```{r}
optimal_clusters_general <- find_optimal_clusters(data_for_cluster_general)
```

```{r}
df_cluster_extra <- applying_kmeans(data_for_cluster_extra, 2)
```

```{r}
print_clustering_results(df_cluster_extra, data_for_cluster_extra, extra_columns)
```

### ¿Cuántas horas de trabajo personal necesita un estudiante para obtener una alta calificación?

-   **Objetivo**: Determinar la cantidad óptima de horas semanales de trabajo personal necesarias para que un estudiante alcance una alta calificación.

El primer paso es definir un criterio para clasificar una calificación como "alta". Para ello, establecemos un umbral basado en un **Notable Alto**, lo que equivale aproximadamente a una calificación media de **8 o superior**.

A continuación, debemos identificar a aquellos estudiantes que cumplan con dicho requisito para centrar el análisis en este grupo específico. Para ello, filtramos el conjunto de datos y seleccionamos únicamente las instancias en las que la variable **Previous_Scores** sea superior a **80** (considerando que las calificaciones en el dataset están expresadas en una escala de 0 a 100).

Este filtrado nos permitirá focalizarnos en los estudiantes con alto rendimiento y analizar los factores que podrían haber influido en su desempeño académico.

Para ello, filtramos las observaciones donde la variable `Previous_Scores` tenga un valor superior a 80.

Además, al centrarnos la variables `Previous_Scores` eliminaremos del conjunto de datos la variable `Exam_Score`.

```{r}
data_notas_altas <- df_cleaned[df_cleaned$Previous_Scores >= 80,]
data_notas_altas <- subset(data_notas_altas, select = -Exam_Score)
data_notas_altas
```

Podemos observar en el siguiente gráfico de tarta la distribución de "altas calificaciones" respecto a la variable `Previous_Scores`.

```{r}
data$calificacion_categoria <- ifelse(data$Previous_Scores > 80, "Alta calificación", "Resto de calificaciones")


categoria_counts <- as.data.frame(table(data$calificacion_categoria))
categoria_counts$percentage <- round(100 * categoria_counts$Freq / sum(categoria_counts$Freq), 1)

ggplot(categoria_counts, aes(x = "", y = Freq, fill = Var1)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Distribución de Calificaciones en Previous Exams", 
       x = NULL, y = NULL) +
  theme_minimal() +
  theme(axis.text = element_blank(), 
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  geom_text(aes(label = paste(percentage, "%")), position = position_stack(vjust = 0.5))

```

Para nuestro estudio debemos crear una nueva métrica que refleje de forma general las **horas semanales de trabajo del estudiante**. Para ello, vamos a combinar varias de las variables disponibles para obtener una estimación más completa de las horas de dedicación del estudiante. Algunas de las variables que podrían influir directamente en las horas de trabajo semanales incluyen:

-   `Hours_Studied`: El número de horas que el estudiante estudia.
-   `Tutoring_Sessions`: El número de sesiones de tutoría.

La fórmula para las horas semanales de trabajo es

\$Horas_Semanales_Work = Hours_Studied + Tutoring_Sessions \$.

Donde:

-   `Hours_Studied`: Número de horas estudiadas.

-   `Tutoring_Sessions`: Número de sesiones de tutoría ( 1 hora por sesión).

```{r}
if ("Hours_Studied" %in% names(data_notas_altas) & 
    "Tutoring_Sessions" %in% names(data_notas_altas) & 
    "Physical_Activity" %in% names(data_notas_altas)){
  
  data_notas_altas$Horas_Semanales_Work <- data_notas_altas$Hours_Studied +               data_notas_altas$Tutoring_Sessions

  data_notas_altas <- data_notas_altas[, !(names(data_notas_altas) %in% c("Hours_Studied", "Tutoring_Sessions", "Physical_Activity"))]
} else {
  print("Las columnas necesarias ya han sido eliminadas.")
}
  
summary(data_notas_altas$Horas_Semanales_Work)
```

```{r}
data_numeric <- data_notas_altas[, sapply(data_notas_altas, is.numeric)]
data_scaled <- as.data.frame(scale(data_numeric))
data_notas_altas[, sapply(data_notas_altas, is.numeric)] <- data_scaled
data_notas_altas
```

Una vez identificados los estudiantes con altas calificaciones, el siguiente paso es identificar cuales son aquellos factores que influyen más en las altas calificaciones del alumno. Para ello, generamos una **matriz de correlación** junto con un **mapa de calor**, lo que nos permitirá visualizar de manera clara cómo se relacionan las variables numéricas dentro del conjunto de datos.

Con este análisis podremos detectar si existe una asociación significativa entre las horas de estudio personal y las calificaciones obtenidas. Además, nos permitirá observar la influencia de otros factores, como las horas de sueño, la asistencia a tutorías o la participación en actividades extracurriculares, en el rendimiento académico de los estudiantes con mejores notas.

```{r}
matriz_correlacion <- cor(data_notas_altas)
matriz_melt <- melt(matriz_correlacion)

ggplot(data = matriz_melt, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name = "Correlación") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "Variables", y = "Variables", title = "Mapa de Calor de Correlación")
```

El resultado de la matriz de correlación nos arroja que no existe gran correlación entre variables.

```{r}
model1 = lm(Horas_Semanales_Work ~ ., data = data_notas_altas)
summary(model1)
```

```{r}
data_notas_alta_simplificado <- data_notas_altas %>% dplyr::select(-School_Type_Public, -Gender_Female)
data_notas_alta_simplificado
```

```{r}
vif_values <- vif(lm(Horas_Semanales_Work ~ ., data = data_notas_alta_simplificado))
print(vif_values)
```

```{r}
indices <- sample(1:nrow(data_notas_alta_simplificado), size = 0.7 * nrow(data_notas_alta_simplificado))
train_data <- data_notas_alta_simplificado[indices, ]
test_data <- data_notas_alta_simplificado[-indices, ]
```

```{r}
library(MASS)
model_reduced <- stepAIC(lm(Horas_Semanales_Work ~ .^2, data = train_data), direction = "both")
summary(model_reduced)
```

```{r}
predicciones <- predict(model_reduced, newdata = test_data)
```

```{r}
comparacion <- data.frame(Real = test_data$Horas_Semanales_Work, Predicha = predicciones)
comparacion
```

```{r}
residuos <- comparacion$Real - comparacion$Predicha
rmse <- sqrt(mean(residuos^2))
print(paste("RMSE: ", rmse))
```
