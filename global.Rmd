---
title: "R Notebook"
output: html_notebook
---

## Descripci√≥n del dominio

El rendimiento acad√©mico es un tema clave en la educaci√≥n, ya que influye directamente en las oportunidades que tendr√°n los jovenes en el d√≠a de ma√±ana y en el desarrollo de nuestra sociedad. Comprender qu√© factores afectan al desempe√±o de los estudiantes permitir√° a las instituciones educativas a mejorar los m√©todos de ense√±anza, dise√±ar pol√≠ticas educativas m√°s efectivas y proporcionar un mayor apoyo a aquellos estudiantes que lo necesiten.

### Enfoque del Trabajo

Este estudio analiza los factores que influyen en el rendimiento acad√©mico de los estudiantes. Para ello, se hace uso de datos relacionados con aspectos personales, sociales y acad√©micos para identificar patrones y determinar qu√© variables tienen mayor impacto en el desempe√±o escolar.

En particular, el estudio se enfoca en responder dos preguntas fundamentales:

1.  **¬øSe pueden agrupar a los estudiantes en una clase seg√∫n sus caracter√≠sticas?**\
    La organizaci√≥n de los estudiantes dentro del aula puede influir significativamente en su aprendizaje y rendimiento. Por esta raz√≥n, se explorar√° la posibilidad de segmentar a los alumnos con base en caracter√≠sticas clave como sus calificaciones previas, el tiempo dedicado al estudio, su nivel de motivaci√≥n, la presencia de discapacidades de aprendizaje y su participaci√≥n en actividades extracurriculares.

    Este enfoque permitir√° una distribuci√≥n estrat√©gica que potencie el aprendizaje al ubicar a los estudiantes en entornos que favorezcan su desarrollo acad√©mico y personal.

2.  **¬øCu√°ntas horas de trabajo personal necesita un estudiante para obtener una alta calificaci√≥n?**\
    Otro objetivo del estudio es determinar cu√°ntas horas diarias de estudio aut√≥nomo son necesarias para que un estudiante alcance una calificaci√≥n alta (entre 8 y 10). Para ello, se identificar√°n aquellos factores que tengan mayor influencia con la calificaci√≥n del estudiante, ya que estos aspectos pueden influir en el rendimiento acad√©mico. A trav√©s de un modelo de regresi√≥n, se buscar√° cuantificar la relaci√≥n entre estas variables y el desempe√±o estudiantil, proporcionando una gu√≠a para optimizar los h√°bitos de estudio.

A trav√©s de este an√°lisis, se pretende aportar informaci√≥n valiosa para mejorar las estrategias educativas, optimizar la distribuci√≥n de los estudiantes en el aula y ofrecer recomendaciones que permitan a los alumnos maximizar su rendimiento acad√©mico.

### Inter√©s y motivaci√≥n del estudio

El mundo en el que vivimos est√° en constante transformaci√≥n. Los sistemas educativos, como muchos otros aspectos de nuestra sociedad, deben adaptarse a nuevas realidades y desaf√≠os. En este contexto, resulta crucial comprender los factores que influyen en el rendimiento acad√©mico de los estudiantes, con el objetivo de mejorar los procesos de ense√±anza y crear un entorno de aprendizaje m√°s inclusivo y eficaz. Lo interesante de este estudio radica en identificar patrones y relaciones entre distintas variables que podr√≠an tener un impacto directo en la forma en que los estudiantes aprenden y se desarrollan.

En particular, nos gustar√≠a subrayar que el rendimiento acad√©mico no depende √∫nicamente de la capacidad intelectual del estudiante, sino tambi√©n de factores como el apoyo familiar, los h√°bitos de estudio, la motivaci√≥n personal y la presencia de discapacidades de aprendizaje. Este enfoque permite adoptar una perspectiva m√°s personalizada de la educaci√≥n, lo que a su vez puede contribuir a una mejor planificaci√≥n y dise√±o de estrategias pedag√≥gicas m√°s adaptadas a las necesidades de los estudiantes.

En el grupo de desarrollo de este trabajo, nos encontramos tanto estudiantes de **Ingenier√≠a Inform√°tica** como de **Ingenier√≠a de la Salud**. Esta diversidad de perspectivas y formaciones acad√©micas enriquece el enfoque del estudio, ya que, desde distintas disciplinas, reconocemos la importancia de crear un entorno educativo que no solo se base en el rendimiento acad√©mico, sino tambi√©n en el bienestar y las capacidades individuales de cada estudiante. Al ser nosotros mismos estudiantes, sabemos de primera mano que las aulas son cada vez m√°s diversas, y entender c√≥mo organizar y distribuir a los estudiantes de acuerdo con sus necesidades espec√≠ficas es clave para optimizar su rendimiento.

### **Importancia local/nacional y en el contexto actual**

A nivel global, la educaci√≥n es un pilar fundamental para el desarrollo. Pa√≠ses con bajos √≠ndices de rendimiento acad√©mico suelen enfrentar mayores desaf√≠os econ√≥micos y sociales. Adem√°s, en un contexto postpandemia, donde la ense√±anza a distancia ha cambiado la forma en que los estudiantes aprenden, es m√°s importante que nunca entender qu√© factores afectan su desempe√±o y c√≥mo pueden optimizarse los procesos de ense√±anza.

## Descripci√≥n del dataset

El dataset ha sido extra√≠do de la plataforma Kaggle y proporcionado por el usuario *lainguyn123*. Se puede acceder al conjunto de datos a trav√©s del siguiente enlace: [Student Performance Factors Dataset](https://www.kaggle.com/datasets/lainguyn123/student-performance-factors/data).

El archivo que contiene el conjunto de datos se denomina *StudentPerformanceFactors* y est√° en formato **CSV**, con un tama√±o aproximado de **641 kB**.

Este conjunto de datos proviene de una investigaci√≥n que analiza los factores que afectan el rendimiento acad√©mico de los estudiantes. Incluye diversas variables relacionadas con caracter√≠sticas personales, acad√©micas y sociales, tales como h√°bitos de estudio, asistencia, participaci√≥n de los padres, y otros aspectos clave que influyen en el √©xito acad√©mico de los estudiantes.

En cuanto a sus dimensiones, el dataset consta de un total de:

-   **6,607 Filas**

-   **20 Columnas**

## Librer√≠as

La funci√≥n ipak est√° dise√±ada para facilitar la instalaci√≥n y carga de paquetes en R. Es √∫til cuando desea asegurarse de que todos los paquetes necesarios para un script o proyecto se instalan y cargan autom√°ticamente. <https://gist.github.com/stevenworthington/3178163>

```{r}
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if(length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("tidyverse","ggplot2", "dplyr","gridExtra", "reshape2", "car", "ggridges", "factoextra", "cluster", "NbClust")
ipak(packages)
```

## Exploraci√≥n de datos

### Lectura de los datos

```{r}
data <- read.csv("data/StudentPerformanceFactors.csv", header=TRUE)
```

### Visualizar las 6 primeras instancias del data frame

```{r}
head(data)
```

### Estructura resumida del data frame

```{r}
str(data)
```

El dataset est√° compuesto por 6,607 filas y 20 columnas, las cuales incluyen atributos de distintos tipos: num√©ricos, categ√≥ricos y booleanos.

A continuaci√≥n, se describen algunos de estos atributos:

-   **Hours_Studied**: N√∫mero de horas de estudio semanales.

-   **Attendance**: Porcentaje de clases a las que ha asistido.

-   **Parental_Involvement**: Nivel de implicaci√≥n de los padres en la educaci√≥n del alumno *(Low, Medium, High)*.

-   **Access_to_Resources**: Disponibilidad de recursos educativos *(Low, Medium, High)*.

-   **Extracurricular_Activities**: Participaci√≥n en actividades extraescolares *(Yes, No)*.

-   **Sleep_Hours**: N√∫mero medio de horas de sue√±o por noche.

-   **Previous_Scores**: Puntuaciones de ex√°menes anteriores.

-   **Motivation_Level**: Nivel de motivaci√≥n del estudiante *(Low, Medium, High)*.

-   **Internet_Access**: Disponibilidad de acceso a Internet *(Yes, No)*.

-   **Tutoring_Sessions**: N√∫mero de sesiones de tutor√≠a a las que asiste al mes.

-   **Family_Income**: Nivel de ingresos familiares *(Low, Medium, High)*.

-   **Teacher_Quality**: Calidad de los profesores *(Low, Medium, High)*.

-   **School_Type**: Tipo de escuela a la que asisti√≥ *(Public, Private)*.

-   **Peer_Influence**: Influencia de los compa√±eros en el rendimiento acad√©mico *(Positive, Neutral, Negative)*.

-   **Physical_Activity**: N√∫mero medio de horas de actividad f√≠sica a la semana.

-   **Learning_Disabilities**: Presencia de dificultades de aprendizaje *(Yes, No)*.

-   **Parental_Education_Level**: Nivel educativo m√°s alto de los padres *(High School, College, Postgraduate)*.

-   **Distance_from_Home**: Distancia de casa a la escuela *(Near, Moderate, Far)*.

-   **Gender**: G√©nero del estudiante *(Male, Female)*.

-   **Exam_Score**: Calificaci√≥n del examen final.

## Preprocesamiento de los datos

Esta funci√≥n muestra las filas con valores NA o valores vacios("").

```{r}
detect_missing_data <- function(df) {
  na_count <- colSums(is.na(df))  # Contar los NA en cada columna
  empty_count <- colSums(sapply(df, function(x) x == ""))  # Contar los valores vac√≠os en cada columna
  
  missing_data <- data.frame(NA_Count = na_count, Empty_Count = empty_count)
  missing_data <- missing_data[missing_data$NA_Count > 0 | missing_data$Empty_Count > 0, ]
  
  return(missing_data)
}


missing_data <- detect_missing_data(data)
missing_data
```

En el resultado arrojado por la funci√≥n podemos observar que no existen valores **NA** en las columnas de nuestro dataframe, lo que significa que no hay datos expl√≠citamente faltantes o nulos. Sin embargo, tambi√©n notamos que hay filas con **valores vac√≠os** en ciertas variables categ√≥ricas.

Al sumar el total de valores faltantes podemos observar que puede haber un m√°ximo de **235 filas** con alg√∫n valor faltante. Esto supone aproximadamente el **3.56%** del total de filas del conjunto de datos.

Dado que la proporci√≥n de filas con valores faltantes es relativamente baja, consideramos eliminar estas instancias ya que creemos que no tendr√° un impacto significativo en la integridad general del dataset.

```{r}
clean_missing_data <- function(df) {
  original_row_count <- nrow(df)
  
  df <- df[!apply(df, 1, function(x) any(is.na(x) | x == "")), ] #Borramos las filas
  
  cleaned_row_count <- nrow(df)
  rows_removed <- original_row_count - cleaned_row_count
  cat("N√∫mero de filas eliminadas:", rows_removed, "\n")
  
  return(df)
}

data <- clean_missing_data(data)
```

Observamos que se han eliminado 229 filas por lo que el dataset sin ning√∫n valor de faltante constar√≠a de un total de **6378 filas**.

### Detecci√≥n de outliers

```{r}
numeric_cols <- sapply(data, is.numeric)

count_outliers <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  sum(x < lower_bound | x > upper_bound, na.rm = TRUE)
}


for (col_name in names(data)[numeric_cols]) {
  num_outliers <- count_outliers(data[[col_name]])
  print(paste("Variable:", col_name, "- Outliers:", num_outliers))
}
```

Podemos observar que existen outliers en las variables `Hours_studies`, `Tutoring_Sessions` y `Exam_Score`. Vamos a visualizar dichos valores mediante gr√°ficos de caja para observar la distribuci√≥n de ciertos valores.

```{r}
plot_boxplots <- function(df) {
  plots <- list()
  numeric_cols <- c("Hours_Studied", "Tutoring_Sessions", "Exam_Score")
  numeric_cols <- numeric_cols[numeric_cols %in% names(df)]
  

  for (var in numeric_cols) {
    p <- ggplot(df, aes_string(y = var)) +
      geom_boxplot(fill = "orange", alpha = 0.7) +
      theme_minimal() +
      labs(title = paste("Outliers in", var), y = var)
    
    plots[[var]] <- p
  }

  for (p in plots) {
    print(p)
  }
}
```

```{r}
plot_boxplots(data)
```

Al observar los gr√°ficos de caja, podemos identificar la presencia de valores at√≠picos. Sin embargo, algunos de estos valores no deben considerarse como tales. Por ejemplo, 8 horas de tutor√≠as es un valor completamente v√°lido. En cambio, en el gr√°fico de `Exam_Scores`, se pueden notar calificaciones que superan el valor m√°ximo permitido de 100, lo que indica un posible error en los datos.

Para solucionar esto, filtraremos las filas en las que el valor de `Exam_Score` sea superior a 100 y lo estableceremos a la m√°xima nota posible, es decir, 100.

```{r}
data$Exam_Score[data$Exam_Score > 100] <- 100
max_Exam_score <- max(data$Exam_Score)
print(max_Exam_score)
```

### Codificaci√≥n

Para preparar los datos de manera √≥ptima para el an√°lisis, aplicamos varias transformaciones a las variables categ√≥ricas y ordinales. Esto nos permite estructurar la informaci√≥n de manera que los modelos puedan interpretarla correctamente.

Con esta funci√≥n convertimos las columnas del data frame en factores ordenados y les asignamos valores enteros, de acuerdo con un orden espec√≠fico de niveles. Esto es util para las variables que tienen una relaci√≥n de orden o tienen un nivel jer√°rquico o progresivo, es decir, que pueden compararse en t√©rminos de m√°s o menos, mejor o peor, mayor o menor.

-   `Parental_Involvement`,`Access_to_Resources`,`Motivation_Level`,`Family_Income`,`Teacher_Quality` Estas variables pueden ordenarse de menor a mayor o viceversa".

-   En `Peer_Influence`, **Positive \> Neutral \> Negative** en t√©rminos de impacto en el rendimiento. Por lo que tambien se pueden ordenar.

-   En `Distance_from_Home` ordenamos los valores en t√©rminos de **nivel de cercan√≠a** de la escuela a la casa del estudiante.

-   En `Parental_Education_Level` ordenamos los valores en t√©rminos de **nivel de estudio de los padres**. Desde menos estudios (High School) hasta m√°s estudios (Postgraduate).

```{r}
convert_to_ordered_int <- function(df, column_names, levels_order, ordered = TRUE) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      df[[col]] <- as.integer(factor(df[[col]], levels = levels_order, ordered = ordered))
    }
  }
  return(df)
}

```

Algunas variables categ√≥ricas contienen √∫nicamente valores "Yes" o "No", por lo que es m√°s eficiente transformarlas en valores 0 y 1, 'No' y 'Yes', respectivamente.

Las variables modificadas ser√°n:

-   `Extracurricular_Activities`, `Internet_Access`, `Learning_Disabilities` ‚Üí Yes = 1, No = 0

```{r}
convert_to_binary <- function(df, column_names) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      df[[col]] <- ifelse(df[[col]] == "Yes", 1, 0)
    }
  }
  return(df)
}

```

Algunas variables no tienen una jerarqu√≠a clara, por lo que en lugar de asignar valores ordinales, creamos columnas binarias (dummies) para cada categor√≠a, es decir, aplicamos One-Hot Encoding.

-   `School_Type` pasar√° a dividirse en dos columnas: `School_Type_Public` y `School_Type_Private`
-   `Gender` se convierte en `Gender_Male` y `Gender_Female`.

```{r}
convert_to_one_hot <- function(df, column_names) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      unique_values <- unique(df[[col]])
      for (val in unique_values) {
        new_col_name <- paste(col, val, sep = "_")
        df[[new_col_name]] <- ifelse(df[[col]] == val, 1, 0)
      }
      df[[col]] <- NULL  # Eliminamos la columna original despu√©s de crear las dummy variables
    }
  }
  return(df)
}

```

```{r}
clean_and_filter_data <- function(data) {
  data <- data %>%
    distinct() %>%
    
    # Convertir a valores ordenados (Low < Medium < High)
    convert_to_ordered_int(c("Parental_Involvement", "Access_to_Resources", "Motivation_Level",
                              "Family_Income", "Teacher_Quality"),
                           c("Low", "Medium", "High")) %>%
    
    # Convertir Peer_Influence en valores ordenados (Negative < Neutral < Positive)
    convert_to_ordered_int("Peer_Influence", c("Negative", "Neutral", "Positive")) %>%
    
    # Convertir Parental Education Level en valores ordenados (High School < College < Postgraduate)
    convert_to_ordered_int("Parental_Education_Level", c("High School", "College", "Postgraduate")) %>%
    
    # Convertir Distance_from_Home en valores ordenados (Near < Moderate < Far)
    convert_to_ordered_int("Distance_from_Home", c("Near", "Moderate", "Far")) %>%
    
    # Convertir a valores binarios (No = 0, Yes = 1)
    mutate(
      Extracurricular_Activities = ifelse(Extracurricular_Activities == "Yes", 1, 0),
      Internet_Access = ifelse(Internet_Access == "Yes", 1, 0),
      Learning_Disabilities = ifelse(Learning_Disabilities == "Yes", 1, 0)
    ) %>%
    
    # Aplicar One-Hot Encoding a School_Type y Gender
    mutate(
      School_Type_Private = ifelse(School_Type == "Private", 1, 0),
      School_Type_Public = ifelse(School_Type == "Public", 1, 0),
      Gender_Male = ifelse(Gender == "Male", 1, 0),
      Gender_Female = ifelse(Gender == "Female", 1, 0)
    ) %>%
    
    # Eliminar las columnas originales despu√©s de One-Hot Encoding
    select(-School_Type, -Gender)

  return(data)
}

```

```{r}
df_cleaned <- clean_and_filter_data(data)
```

```{r}
df_cleaned
```

Despu√©s de la codificaci√≥n, nuestro dataset consta de estos tipos:

```{r}
str(df_cleaned)
```

### Escalarizaci√≥n

Para que el an√°lisis sea √≥ptimo, tambi√©n es necesario escalar las variables.

-   `Sleep_Hours` toma como valor las horas de sue√±o por noche. Supondremos que el estudiante duerme esta cantidad de horas todos los d√≠as por lo que modificaremos el valor para que sean horas semanales (Multiplicamos por 7 las horas de sue√±o diarias).

-   `Tutoring_Sessions` toma como valor las sesiones de tutoria por mes. Para escalar esta variable, se tomar√° 1 sesi√≥n de tutor√≠a = 1 hora y a su vez, se pasar√° a horas semanales. Por ejemplo, si un estudiante tiene `Tutoring_Sessions` = 4 en un mes, significa que tiene 1 por semana (`Tutoring_Sessions`/ 4 semanas).

```{r}
scale_time_variables <- function(df) {
  df <- df %>%
    mutate(
      Sleep_Hours = Sleep_Hours * 7,  # Convertir de horas por noche a horas por semana
      Tutoring_Sessions = Tutoring_Sessions / 4  # Convertir sesiones a horas/semana
    )
  return(df)
}

df_cleaned <- scale_time_variables(df_cleaned)

print("Sleep_Hours:") 
summary(df_cleaned$Sleep_Hours)  # Deber√≠a estar en un rango de 0-56 horas semanales
print("Tutoring_Sessions:")
summary(df_cleaned$Tutoring_Sessions)  # Ahora representar√° horas de tutor√≠a por semana


```

Como puede observarse, para las horas de sue√±o semanales, el m√≠nimo es 28, lo cual significa que hay estudiantes que duermen 4 horas por noche (4 \* 7 = 28). La mediana es 49, lo que indica que la mayor√≠a de los estudiantes duermen aproximadamente 7 horas por noche (7 \* 7 = 49). El m√°ximo es 70, lo que implica que algunos estudiantes duermen 10 horas por noche (10 \* 7 = 70).

Por otro lado, para las horas de tutor√≠a por semana, el m√≠nimo es 0, lo cual es correcto, ya que algunos estudiantes no tienen sesiones de tutor√≠a. La mediana es 0.25, lo que significa que muchos estudiantes tienen 1 sesi√≥n por mes (1 hora / 4 = 0.25 horas/semana). El m√°ximo es 2, lo que indica que algunos estudiantes tienen 8 sesiones de tutor√≠a por mes, que equivale a 2 horas de tutor√≠a por semana.

## Visualizaciones Iniciales

## Distribuci√≥n de variables num√©ricas

```{r}
create_dist_grap <- function(df, variable, binwidth = 1, fill = "cornflowerblue") {
  if (!(variable %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  ggplot(df, aes_string(x = variable)) +
    geom_histogram(binwidth = binwidth, 
                   fill = fill, color = "black", bins = 20) +
    labs(title = paste(variable, "analysis"), x = variable, y = "Count") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5))
}

create_dist_grap(data, "Sleep_Hours")
create_dist_grap(data, "Hours_Studied")
create_dist_grap(data, "Tutoring_Sessions")
create_dist_grap(data, "Attendance", binwidth = 5)
create_dist_grap(data, "Previous_Scores")
create_dist_grap(data, "Exam_Score", fill = "orange")
```

## Distribuci√≥n de variables categ√≥ricas

```{r}
create_pie_chart <- function(df, var_name) {
  if (!(var_name %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  dist_var <- as.data.frame(table(df[[var_name]]))
  colnames(dist_var) <- c(var_name, "Count")
  dist_var$Percentage <- round(dist_var$Count / sum(dist_var$Count) * 100, 1)
  

  ggplot(dist_var, aes(x = "", y = Count, fill = get(var_name))) +
    geom_bar(stat = "identity", width = 1) +
    coord_polar(theta = "y") +
    geom_text(aes(label = paste0(Percentage, "%")), position = position_stack(vjust = 0.5), size = 5) +
    labs(title = paste("Distribuci√≥n de", var_name), fill=var_name) +
    theme_minimal() +
    theme(axis.text.x = element_blank(), 
          axis.ticks = element_blank(),
          panel.grid = element_blank())
}
```

```{r}
create_pie_chart(data, "Parental_Involvement")
create_pie_chart(data, "Access_to_Resources")
create_pie_chart(data, "Parental_Education_Level")
create_pie_chart(data, "Distance_from_Home")
create_pie_chart(data, "Extracurricular_Activities")
create_pie_chart(data, "School_Type")
create_pie_chart(data, "Gender")
```

## Preguntas

### ¬ø**Se pueden agrupar a los estudiantes en una clase seg√∫n sus caracter√≠sticas?**

-   **Objectivo**: Intentar asignar a los alumnos a grupos de manera que se favorezca su aprendizaje.

En primer lugar, decidimos una estrategia a adoptar para agrupar a los alumnos. Nos enfocamos en diferentes variables seg√∫n el objetivo a cumplir:

-   **Academic**: Nos interesamos en las variables que reflejan el √©xito escolar en t√©rminos acad√©micos, como la asistencia, el n√∫mero de horas de estudio o los resultados obtenidos.

-   **Support**: Aqu√≠, el enfoque est√° en las necesidades de apoyo del alumno. ¬øNecesita horas de tutor√≠a? ¬øTiene dificultades para aprender?

-   **Resource**: ¬øDispone el alumno de los recursos necesarios para favorecer su aprendizaje?

-   **Extra**: Variables relacionadas con el ocio y la vida social. ¬øTiene el alumno actividades extracurriculares? ¬øCu√°les son sus relaciones de amistad?

-   **General**: Todas las variables. ¬øQue grupos conforman estos datos?

```{r}
academic_columns <- c("Hours_Studied", "Attendance", "Exam_Score", "Previous_Scores")
support_columns <- c("Learning_Disabilities", "Tutoring_Sessions", "Access_to_Resources")
resource_columns <- c("Family_Income", "Access_to_Resources", "Internet_Access", "Parental_Education_Level")
extra_columns <- c("Extracurricular_Activities", "Physical_Activity", "Peer_Influence")
general_columns <- c(
  "Hours_Studied",
  "Attendance",
  "Parental_Involvement",
  "Access_to_Resources",
  "Extracurricular_Activities",
  "Sleep_Hours",
  "Previous_Scores",
  "Motivation_Level",
  "Internet_Access",
  "Tutoring_Sessions",
  "Family_Income",
  "Teacher_Quality",
  "School_Type_Private",
  "School_Type_Public",
  "Peer_Influence",
  "Physical_Activity",
  "Learning_Disabilities",
  "Parental_Education_Level",
  "Distance_from_Home",
  "Gender_Male",
  "Gender_Female",
  "Exam_Score"
)
```

```{r}
df_scaled = as_tibble(scale(df_cleaned))

data_for_cluster_academic <- select(df_scaled, all_of(academic_columns))
data_for_cluster_support <- select(df_scaled, all_of(support_columns))
data_for_cluster_resource <- select(df_scaled, all_of(resource_columns))
data_for_cluster_extra <- select(df_scaled, all_of(extra_columns))
data_for_cluster_general <- select(df_scaled, all_of(general_columns))
```

Para agrupar a los alumnos seg√∫n estas categor√≠as, utilizaremos el m√©todo de **clustering K-Means**.

Primero, definimos una funci√≥n que nos permita seleccionar el mejor valor de **K**.

```{r}
compare_k <- function(df) {
  print(fviz_nbclust(df, kmeans, method = "wss") + 
    ggtitle("Elbow Method for Optimal K"))

  print(fviz_nbclust(df, kmeans, method = "silhouette") + 
    ggtitle("Silhouette Method for Optimal K"))
}
```

Luego, definimos una funci√≥n que aplique el clustering y a√±ada la variable **cluster** a nuestro conjunto de datos inicial.

```{r}
applying_kmeans <- function(data_for_clustering, k){
  set.seed(42)
  kmeans_model <- kmeans(data_for_clustering, centers = k, nstart = 25)
  df_with_cluster <- as_tibble(df_cleaned)
  df_with_cluster$Cluster <- as.factor(kmeans_model$cluster)
  return(df_with_cluster)
}
```

Finalmente, definimos una funci√≥n que nos permita **comparar los grupos formados**:\
- ¬øCu√°ntos alumnos hay en cada cluster?\
- Comparaci√≥n de las variables utilizadas en el clustering mediante **ridgeline plots**.

```{r}
print_clustering_results <- function(df_with_clusters, data_for_cluster, columns_to_focus){
  cluster_summary <- df_with_clusters %>%
    group_by(Cluster) %>%
    summarise(
      Num_Students = n()
    )
  
  print(ggplot(cluster_summary, aes(x = as.factor(Cluster), y = Num_Students, fill = as.factor(Cluster))) +
          geom_bar(stat = "identity") +
          labs(title = "Number of Students in Each Cluster", x = "Cluster", y = "Student Count") +
          theme_minimal())
  
  for (column in columns_to_focus) {
    print(ggplot(df_with_clusters, aes(x = as.factor(Cluster), y = !!sym(column), fill = as.factor(Cluster))) +
            geom_boxplot() +
            labs(title = paste(column, "Distribution in Each Cluster"), x = "Cluster", y = column) +
            theme_minimal())
  }
  
  print(fviz_cluster(list(data = data_for_cluster, cluster = df_with_clusters$Cluster),
                     geom = "point",
                     ellipse.type = "convex",
                     ggtheme = theme_minimal(),
                     main = "Cluster Visualization (PCA Projection)"))
}

```

```{r}
find_optimal_clusters <- function(data) {
  
  result <- NbClust(data, diss = NULL, distance = "euclidean", 
                    min.nc = 2, max.nc = 4, method = "kmeans")
  
  # Retorna el n√∫mero √≥ptimo de clusters sugerido
  return(result)
}
```

#### Academic

```{r}
compare_k(data_for_cluster_academic)
```

```{r}
optimal_clusters_academic <- find_optimal_clusters(data_for_cluster_academic)

```

Analizando las gr√°ficas del m√©todo del Codo (Elbow Method) y del Coeficiente de Silhouette, llegamos a la conclusi√≥n de que el n√∫mero √≥ptimo de cl√∫steres es ùëò = 2 k=2.

Esta conclusi√≥n se fundamenta en dos aspectos clave:

**M√©todo del Codo (Elbow Method)**: En esta gr√°fica, observamos que la mayor reducci√≥n en la suma de cuadrados dentro del grupo ocurre hasta ùëò = 2 k=2, formando un punto de inflexi√≥n o "codo" en ese valor. A partir de ùëò = 2 k=2, la disminuci√≥n en la varianza interna de los cl√∫steres se vuelve menos pronunciada, lo que indica que agregar m√°s cl√∫steres no aporta una mejora significativa en la compactaci√≥n de los datos.

**Coeficiente de Silhouette (Silhouette Method)**: Este m√©todo mide la calidad de la agrupaci√≥n en funci√≥n de la cohesi√≥n interna y la separaci√≥n entre cl√∫steres. En la gr√°fica correspondiente, el valor m√°s alto del coeficiente de Silhouette se encuentra en ùëò = 2 k=2, lo que indica que, con este n√∫mero de cl√∫steres, los grupos est√°n bien diferenciados y los puntos dentro de cada cl√∫ster son m√°s homog√©neos.

Bas√°ndonos en la evaluaci√≥n de m√∫ltiples criterios de clustering mediante `NbClust`, el n√∫mero √≥ptimo de clusters en los datos es **2**, ya que recibi√≥ la mayor cantidad de votos. Esto sugiere que los datos tienen dos grupos bien diferenciados, lo que puede ser validado adicionalmente con m√©tricas como el √≠ndice de silueta o gr√°ficos de PCA

Dado que todos los m√©todos coinciden en que ùëò = 2 es el valor √≥ptimo, podemos concluir que dividir los datos en dos grupos proporciona una segmentaci√≥n adecuada, asegurando un equilibrio entre la reducci√≥n de la variabilidad interna y la claridad en la separaci√≥n entre cl√∫steres.

```{r}
df_cluster_academic <- applying_kmeans(data_for_cluster_academic, 2)
```

```{r}
print_clustering_results(df_cluster_academic, data_for_cluster_academic, academic_columns)
```

El Cl√∫ster 1 est√° compuesto por estudiantes que dedican m√°s horas al estudio en comparaci√≥n con los del Cl√∫ster 2. Sin embargo, la diferencia m√°s notable entre ambos grupos radica en la asistencia a clase, ya que los alumnos del Cl√∫ster 1 muestran un nivel de asistencia significativamente mayor. Este factor parece desempe√±ar un papel clave en su rendimiento acad√©mico, ya que la combinaci√≥n de una mayor dedicaci√≥n al estudio y una participaci√≥n m√°s activa en las clases les permite obtener resultados m√°s favorables en comparaci√≥n con los estudiantes del Cl√∫ster 2.

Por otro lado, los alumnos del Cl√∫ster 2 no solo estudian menos, sino que tambi√©n presentan un porcentaje de asistencia m√°s bajo, lo que podr√≠a afectar negativamente su comprensi√≥n de los contenidos y, en consecuencia, su desempe√±o acad√©mico. Estos hallazgos sugieren que tanto el tiempo de estudio como la asistencia a clase son factores determinantes en el √©xito acad√©mico de los estudiantes.

#### Support

```{r}
compare_k(data_for_cluster_support)
```

```{r}
optimal_clusters_support <- find_optimal_clusters(data_for_cluster_support)

```

La primera gr√°fica sigue el **m√©todo del codo**, el cual eval√∫a la suma de los cuadrados dentro de los clusters (WSS) en funci√≥n del n√∫mero de clusters. El punto √≥ptimo se encuentra donde la disminuci√≥n en WSS se vuelve menos pronunciada, formando un "codo" en la curva. En este caso, se observa un cambio notable en la pendiente alrededor de k=4 y k=8, lo que indica que estos valores podr√≠an ser opciones razonables para segmentar los datos de manera eficiente.

Por otro lado, la segunda gr√°fica utiliza el **m√©todo del Silhouette** para determinar el n√∫mero √≥ptimo de clusters. En este m√©todo, se elige el valor de k que maximiza el √≠ndice de silhouette, el cual mide qu√© tan bien separados est√°n los clusters y qu√© tan cohesivos son. En la gr√°fica, el valor m√°s alto de silhouette se alcanza en k=8, lo que sugiere que este n√∫mero de clusters permite una mejor separaci√≥n entre los grupos y minimiza la superposici√≥n entre ellos.

Bas√°ndonos en la evaluaci√≥n de m√∫ltiples criterios de clustering mediante `NbClust`, el n√∫mero √≥ptimo de clusters en los datos es **4**, ya que recibi√≥ la mayor cantidad de votos. Esto sugiere que los datos tienen cuatro grupos bien diferenciados, lo que puede ser validado adicionalmente con m√©tricas como el √≠ndice de silueta o gr√°ficos de PCA

En conclusi√≥n, aunque el m√©todo del codo sugiere que tanto k=4 como k=8 son buenas opciones, el m√©todo de Silhouette indica que k=8 ofrece la mejor separaci√≥n entre clusters. Sin embargo, al aplicar el m√©todo de m√∫ltiples criterios, k=4 obtuvo la mayor cantidad de votos, superando a las dem√°s opciones por 15 votos. Dado que tanto el m√©todo del codo como el de m√∫ltiples criterios coinciden en k=4, tomamos esta opci√≥n como la m√°s adecuada para el clustering.

```{r}
df_cluster_support <- applying_kmeans(data_for_cluster_support, 4)
```

```{r}
print_clustering_results(df_cluster_support, data_for_cluster_support, support_columns)
```

Tras analizar las distintas gr√°ficas obtenidas en el estudio, se han identificado **tres grupos de alumnos** que no presentan dificultades en el aprendizaje, correspondientes a los **cl√∫steres 1, 2 y 4**. Estos estudiantes no parecen experimentar problemas significativos en su rendimiento acad√©mico, lo que sugiere que sus h√°bitos y patrones de estudio pueden estar alineados con el √©xito educativo.

Al comparar estos resultados con la **gr√°fica de sesiones de tutor√≠a**, se observa que el **cl√∫ster 1** es el grupo que registra **m√°s horas de tutor√≠a**, lo que podr√≠a indicar un mayor inter√©s o compromiso con el refuerzo acad√©mico. Por otro lado, los cl√∫steres **2 y 4** presentan una cantidad similar de sesiones de tutor√≠a, lo que sugiere que no requieren un apoyo adicional significativo. Sin embargo, el caso m√°s preocupante se encuentra en el **cl√∫ster 3**, ya que **este grupo s√≠ presenta problemas de aprendizaje, pero no asiste a tutor√≠as**. Esta falta de apoyo podr√≠a estar contribuyendo a sus dificultades acad√©micas, lo que sugiere la necesidad de intervenciones espec√≠ficas para mejorar su desempe√±o.

En cuanto al **acceso a recursos educativos**, la √∫ltima gr√°fica revela que el **cl√∫ster 4 es el que m√°s acceso tiene**, ocupando el rango m√°s alto en su totalidad. Esto sugiere que estos alumnos disponen de herramientas adecuadas para su aprendizaje, lo que puede estar relacionado con su buen rendimiento. Los **cl√∫steres 1 y 3** comparten un rango medio de acceso a recursos, aunque con variaciones entre casos de acceso bajo y alto, lo que indica cierta desigualdad en la disponibilidad de materiales. Finalmente, el **cl√∫ster 2 presenta el nivel m√°s bajo de acceso a recursos**, lo que podr√≠a representar una barrera para su desarrollo acad√©mico a largo plazo.

El an√°lisis de los datos ha permitido identificar patrones significativos en el aprendizaje de los alumnos y su relaci√≥n con las tutor√≠as y el acceso a recursos. Se destaca que el **cl√∫ster 3 requiere especial atenci√≥n**, ya que, a pesar de sus dificultades, **no participa en tutor√≠as**, lo que podr√≠a agravar sus problemas. Adem√°s, el acceso desigual a recursos educativos podr√≠a estar influyendo en el rendimiento de algunos grupos. Estos hallazgos sugieren la importancia de fomentar el uso de tutor√≠as en estudiantes con dificultades y garantizar un acceso equitativo a los recursos educativos para mejorar la calidad del aprendizaje.

#### Resources

```{r}
compare_k(data_for_cluster_resource)
```

```{r}
optimal_clusters_resources <- find_optimal_clusters(data_for_cluster_resource)
```

En la primera imagen, correspondiente al **m√©todo de Elbow**, se representa la suma de los cuadrados dentro del cluster (*Total Within Sum of Squares, WSS*) en funci√≥n del n√∫mero de clusters (*k*). Este m√©todo se basa en encontrar el punto donde la disminuci√≥n de WSS empieza a desacelerarse de manera significativa, formando una especie de ‚Äúcodo‚Äù en la gr√°fica. En este caso, observamos que la curva muestra una reducci√≥n brusca hasta aproximadamente *k = 8*, despu√©s de lo cual la disminuci√≥n de WSS se vuelve menos pronunciada. Esto sugiere que *k = 8* es un buen candidato para el n√∫mero √≥ptimo de clusters, ya que m√°s all√° de este punto la ganancia en t√©rminos de reducci√≥n de varianza dentro de los clusters es menor.

Por otro lado, en la segunda imagen se muestra el resultado del **m√©todo de Silhouette**, el cual mide la calidad de la agrupaci√≥n en funci√≥n de la cohesi√≥n interna y la separaci√≥n entre los clusters. El objetivo es encontrar el valor de *k* que maximiza el ancho promedio del coeficiente de silueta, lo que indica que los puntos est√°n bien agrupados dentro de sus respectivos clusters y bien separados de otros clusters. En esta gr√°fica, el valor m√°s alto del coeficiente de silueta se observa en *k = 2*, lo que sugiere que dos clusters proporcionan la mejor separaci√≥n seg√∫n este criterio. Sin embargo, tambi√©n se observa un valor elevado en *k = 8*, lo que indica que esta cantidad de clusters tambi√©n es una opci√≥n viable.

Bas√°ndonos en la evaluaci√≥n de m√∫ltiples criterios de clustering mediante `NbClust`, el n√∫mero √≥ptimo de clusters en los datos es **4**, ya que recibi√≥ la mayor cantidad de votos. Esto sugiere que los datos tienen cuatro grupos bien diferenciados, lo que puede ser validado adicionalmente con m√©tricas como el √≠ndice de silueta o gr√°ficos de PCA

El an√°lisis de los diferentes m√©todos de clustering muestra resultados variados sobre la cantidad √≥ptima de clusters. El m√©todo de **Elbow** sugiere que **k = 8** es una buena opci√≥n, ya que a partir de este punto la reducci√≥n de la varianza dentro de los clusters se desacelera significativamente. Por otro lado, el **m√©todo de Silhouette** indica que **k = 2** proporciona la mejor separaci√≥n entre clusters, aunque tambi√©n destaca **k = 8** como una alternativa viable. Sin embargo, el m√©todo de m√∫ltiples criterios de **NbClust** se√±ala que **k = 4** es la mejor opci√≥n al haber recibido la mayor cantidad de votos, lo que sugiere la existencia de cuatro grupos bien diferenciados en los datos. Dado que NbClust integra varios enfoques de validaci√≥n, se considera **k = 4** como el n√∫mero √≥ptimo de clusters, aunque los valores **k = 2 y k = 8** tambi√©n pueden ser opciones a considerar dependiendo del criterio de segmentaci√≥n que se priorice.

```{r}
df_cluster_resource <- applying_kmeans(data_for_cluster_resource, 4)
```

```{r}
print_clustering_results(df_cluster_resource, data_for_cluster_resource, resource_columns)
```

El an√°lisis de la primera gr√°fica, correspondiente a los **ingresos familiares**, revela diversas diferencias entre los cl√∫steres analizados. En t√©rminos generales, la mayor√≠a de los grupos presentan ingresos de nivel medio, aunque existen algunas desviaciones significativas que reflejan desigualdades econ√≥micas dentro del conjunto de datos. En particular, los **cl√∫steres 2 y 3** se sit√∫an dentro del rango de ingresos medios, pero con ciertas diferencias notables. El **cl√∫ster 2** muestra una mayor presencia de usuarios con ingresos **medios-bajos**, mientras que el **cl√∫ster 3** se inclina levemente hacia los **ingresos medios-altos**, aunque sin una diferencia muy pronunciada. En el caso del **cl√∫ster 1**, se observa una tendencia hacia ingresos **medios en su mayor√≠a al alza**, sin presencia destacada de ingresos bajos. Sin embargo, el grupo con la situaci√≥n econ√≥mica m√°s delicada es el **cl√∫ster 4**, que se distingue por presentar **ingresos √≠ntegramente bajos** en comparaci√≥n con los dem√°s grupos.

Al relacionar estos hallazgos con la segunda gr√°fica, correspondiente al **acceso a recursos**, se observa que la mayor√≠a de los cl√∫steres tienen valores medios similares en cuanto a disponibilidad de recursos educativos. No obstante, existen algunas fluctuaciones, con ciertos casos que se inclinan hacia un acceso m√°s limitado o, en otros, con mayores facilidades. Un hallazgo relevante es que, a pesar de que el **cl√∫ster 4** presenta los ingresos m√°s bajos, su acceso a recursos no es significativamente menor, lo que sugiere la existencia de **programas de ayuda o becas** que compensan la falta de recursos econ√≥micos. Esto indica que, aunque las familias de este grupo tengan menos ingresos, han podido acceder a apoyos que mitigan las desigualdades.

En lo que respecta al **acceso a internet**, se evidencia que el **cl√∫ster 2** es el √∫nico grupo que presenta un valor negativo, es decir, una menor accesibilidad a la conectividad en comparaci√≥n con el resto. Este dato plantea dos hip√≥tesis posibles: una primera explicaci√≥n ser√≠a que estas familias **no pueden permitirse el acceso a internet** debido a razones econ√≥micas; sin embargo, esta teor√≠a resulta inconsistente si consideramos que el **cl√∫ster 4**, que cuenta con los ingresos m√°s bajos, s√≠ tiene acceso a internet. Por lo tanto, una hip√≥tesis m√°s plausible es que en el **cl√∫ster 2 las familias han restringido el uso de internet a sus hijos por decisi√≥n propia**, probablemente por razones educativas, de control parental o de valores familiares.

En cuanto al **nivel acad√©mico de los padres**, se observa que, en t√©rminos generales, la mayor√≠a de los grupos presentan un nivel de educaci√≥n secundaria. No obstante, existen diferencias entre los cl√∫steres. El **cl√∫ster 1** se caracteriza por estar compuesto en su totalidad por padres con educaci√≥n **secundaria**. El **cl√∫ster 2** tambi√©n presenta una mayor√≠a con educaci√≥n secundaria, aunque con la particularidad de que algunos padres han alcanzado estudios **universitarios y de posgrado**. Por otro lado, el **cl√∫ster 4** cuenta principalmente con familias con formaci√≥n en **educaci√≥n secundaria y grados universitarios**, aunque sin un predominio de estudios avanzados. La situaci√≥n m√°s particular se encuentra en el **cl√∫ster 3**, donde los padres presentan un nivel de estudios **m√≠nimo de grado universitario**, y en algunos casos, **estudios de posgrado**, lo que indica un nivel acad√©mico superior en comparaci√≥n con el resto de los grupos.

El an√°lisis realizado revela importantes diferencias socioecon√≥micas entre los cl√∫steres analizados. Se ha identificado que el **cl√∫ster 4** es el grupo con menores ingresos, pero gracias a alg√∫n tipo de apoyo externo, ha podido mantener un acceso a recursos educativos similar al de los otros grupos. En cuanto a la **conectividad a internet**, el **cl√∫ster 2** es el √∫nico que presenta restricciones, lo que sugiere que la limitaci√≥n se debe m√°s a una decisi√≥n parental que a factores econ√≥micos. Respecto al **nivel educativo de los padres**, se observa que la mayor√≠a han alcanzado la educaci√≥n secundaria, aunque el **cl√∫ster 3 destaca por contar con padres con estudios universitarios y de posgrado en mayor proporci√≥n**. Estas diferencias pueden influir en el rendimiento acad√©mico y el acceso a oportunidades de aprendizaje, lo que subraya la importancia de analizar estos factores para dise√±ar estrategias de apoyo adecuadas para cada grupo.

#### Social

```{r}
compare_k(data_for_cluster_extra)
```

```{r}
optimal_clusters_extra <- find_optimal_clusters(data_for_cluster_extra)
```

En el gr√°fico del **m√©todo del codo**, se observa que la "Suma de Cuadrados Dentro del Grupo" (**WSS**) disminuye considerablemente hasta aproximadamente k=3, k=4, momento en el cual la pendiente comienza a estabilizarse. Esto indica que a partir de estos valores, agregar m√°s clusters genera una menor ganancia en la reducci√≥n de la variabilidad dentro de los grupos, sugiriendo que k=3 o k=4 son opciones razonables.

Por otro lado, el **m√©todo del silhouette** muestra que la mejor cohesi√≥n interna y separaci√≥n entre los clusters se obtiene con k=2, lo que sugiere que dividir los datos en dos grupos maximiza la calidad de la segmentaci√≥n.

Adicionalmente, el **an√°lisis de m√∫ltiples criterios** tambi√©n ha indicado que el n√∫mero √≥ptimo de clusters es k=2, ya que ha recibido la mayor cantidad de votos (**8 votos**), superando a k=3 y k=4, que han obtenido **5 votos** cada uno.

Los tres enfoques utilizados coinciden en que k=2 es la opci√≥n m√°s s√≥lida para la segmentaci√≥n de los datos. Tanto el m√©todo del silhouette como el an√°lisis de m√∫ltiples criterios refuerzan esta elecci√≥n, indicando que dividir los datos en dos grupos proporciona la mejor cohesi√≥n y separaci√≥n entre clusters. Aunque el m√©todo del codo suger√≠a que k=3 o k=4 podr√≠an ser alternativas razonables, la evidencia general respalda la elecci√≥n de k=2 como el n√∫mero √≥ptimo de clusters en este caso.

```{r}
df_cluster_extra <- applying_kmeans(data_for_cluster_extra, 2)

```

```{r}
print_clustering_results(df_cluster_extra, data_for_cluster_extra, extra_columns)
```

El an√°lisis de los gr√°ficos permite identificar distintos patrones en la relaci√≥n entre la participaci√≥n en **actividades extracurriculares**, la cantidad de **horas dedicadas a la actividad f√≠sica** y la **influencia de los compa√±eros** en los alumnos. A trav√©s de la observaci√≥n de estos datos, se pueden extraer conclusiones relevantes sobre c√≥mo estas variables se relacionan entre s√≠ y si tienen alg√∫n impacto en la vida social y acad√©mica de los estudiantes.

En el primer gr√°fico, correspondiente a la **realizaci√≥n de actividades extracurriculares**, se observa una diferencia clara entre los dos cl√∫steres analizados. El **cl√∫ster 1** agrupa a aquellos alumnos que **no participan en actividades extraescolares**, mientras que el **cl√∫ster 2** representa a los estudiantes que s√≠ realizan este tipo de actividades. Esta segmentaci√≥n permite identificar una distinci√≥n clara en los h√°bitos de los alumnos con respecto a su tiempo fuera del entorno acad√©mico, lo que podr√≠a tener implicaciones en otros aspectos de su desarrollo personal y social.

En lo que respecta al **rango de horas dedicadas a la actividad f√≠sica**, se observa que ambos cl√∫steres presentan una distribuci√≥n similar. Esto indica que la participaci√≥n o no en actividades extracurriculares no tiene un impacto significativo en el tiempo que los estudiantes dedican a la pr√°ctica de ejercicio f√≠sico. Es decir, tanto los alumnos que realizan actividades extraescolares como los que no lo hacen mantienen h√°bitos de actividad f√≠sica similares, lo que sugiere que otros factores, como la rutina diaria o el estilo de vida familiar, podr√≠an ser m√°s determinantes en este aspecto.

Por √∫ltimo, el an√°lisis de la **influencia de los compa√±eros** muestra que ambos cl√∫steres presentan una distribuci√≥n equivalente en esta variable. Esto implica que la **realizaci√≥n de actividades extracurriculares no tiene un impacto significativo en el nivel de influencia que los compa√±eros ejercen sobre los estudiantes**. En otras palabras, la socializaci√≥n y las din√°micas de grupo parecen mantenerse estables independientemente de si el alumno participa o no en actividades extracurriculares.

El an√°lisis realizado revela que la participaci√≥n en **actividades extracurriculares** es una caracter√≠stica diferenciadora entre los cl√∫steres, pero no parece influir en otras variables como la **cantidad de horas dedicadas a la actividad f√≠sica** ni en el **nivel de influencia de los compa√±eros**. La similitud en la distribuci√≥n de estas √∫ltimas variables sugiere que la actividad extracurricular no es un factor determinante en los h√°bitos de ejercicio ni en la socializaci√≥n de los alumnos. Por lo tanto, la decisi√≥n de realizar o no actividades extracurriculares podr√≠a estar m√°s relacionada con factores personales o familiares que con un impacto significativo en la vida social o los h√°bitos de los estudiantes.

#### General

```{r}
compare_k(data_for_cluster_general)
```

```{r}
optimal_clusters_general <- find_optimal_clusters(data_for_cluster_general)
```

```{r}
df_cluster_extra <- applying_kmeans(data_for_cluster_extra, 2)
```

```{r}
print_clustering_results(df_cluster_extra, data_for_cluster_extra, extra_columns)
```

### ¬øCu√°ntas horas de trabajo personal necesita un estudiante para obtener una alta calificaci√≥n?

-   **Objetivo**: Determinar la cantidad √≥ptima de horas semanales de trabajo personal necesarias para que un estudiante alcance una alta calificaci√≥n.

El primer paso es definir un criterio para clasificar una calificaci√≥n como "alta". Para ello, establecemos un umbral basado en un **Notable Alto**, lo que equivale aproximadamente a una calificaci√≥n media de **8 o superior**.

A continuaci√≥n, debemos identificar a aquellos estudiantes que cumplan con dicho requisito para centrar el an√°lisis en este grupo espec√≠fico. Para ello, filtramos el conjunto de datos y seleccionamos √∫nicamente las instancias en las que la variable **Previous_Scores** sea superior a **80** (considerando que las calificaciones en el dataset est√°n expresadas en una escala de 0 a 100).

Este filtrado nos permitir√° focalizarnos en los estudiantes con alto rendimiento y analizar los factores que podr√≠an haber influido en su desempe√±o acad√©mico.

Para ello, filtramos las observaciones donde la variable `Previous_Scores` tenga un valor superior a 80.

Adem√°s, al centrarnos la variables `Previous_Scores` eliminaremos del conjunto de datos la variable `Exam_Score`.

```{r}
data_notas_altas <- df_cleaned[df_cleaned$Previous_Scores >= 80,]
data_notas_altas <- subset(data_notas_altas, select = -Exam_Score)
data_notas_altas
```

Podemos observar en el siguiente gr√°fico de tarta la distribuci√≥n de "altas calificaciones" respecto a la variable `Previous_Scores`.

```{r}
data$calificacion_categoria <- ifelse(data$Previous_Scores > 80, "Alta calificaci√≥n", "Resto de calificaciones")


categoria_counts <- as.data.frame(table(data$calificacion_categoria))
categoria_counts$percentage <- round(100 * categoria_counts$Freq / sum(categoria_counts$Freq), 1)

ggplot(categoria_counts, aes(x = "", y = Freq, fill = Var1)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Distribuci√≥n de Calificaciones en Previous Exams", 
       x = NULL, y = NULL) +
  theme_minimal() +
  theme(axis.text = element_blank(), 
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  geom_text(aes(label = paste(percentage, "%")), position = position_stack(vjust = 0.5))

```

Para nuestro estudio debemos crear una nueva m√©trica que refleje de forma general las **horas semanales de trabajo del estudiante**. Para ello, vamos a combinar varias de las variables disponibles para obtener una estimaci√≥n m√°s completa de las horas de dedicaci√≥n del estudiante. Algunas de las variables que podr√≠an influir directamente en las horas de trabajo semanales incluyen:

-   `Hours_Studied`: El n√∫mero de horas que el estudiante estudia.
-   `Tutoring_Sessions`: El n√∫mero de sesiones de tutor√≠a.

La f√≥rmula para las horas semanales de trabajo es

\$Horas_Semanales_Work = Hours_Studied + Tutoring_Sessions \$.

Donde:

-   `Hours_Studied`: N√∫mero de horas estudiadas.

-   `Tutoring_Sessions`: N√∫mero de sesiones de tutor√≠a ( 1 hora por sesi√≥n).

```{r}
if ("Hours_Studied" %in% names(data_notas_altas) & 
    "Tutoring_Sessions" %in% names(data_notas_altas) & 
    "Physical_Activity" %in% names(data_notas_altas)){
  
  data_notas_altas$Horas_Semanales_Work <- data_notas_altas$Hours_Studied +               data_notas_altas$Tutoring_Sessions

  data_notas_altas <- data_notas_altas[, !(names(data_notas_altas) %in% c("Hours_Studied", "Tutoring_Sessions", "Physical_Activity"))]
} else {
  print("Las columnas necesarias ya han sido eliminadas.")
}
  
summary(data_notas_altas$Horas_Semanales_Work)
```

```{r}
data_numeric <- data_notas_altas[, sapply(data_notas_altas, is.numeric)]
data_scaled <- as.data.frame(scale(data_numeric))
data_notas_altas[, sapply(data_notas_altas, is.numeric)] <- data_scaled
data_notas_altas
```

Una vez identificados los estudiantes con altas calificaciones, el siguiente paso es identificar cuales son aquellos factores que influyen m√°s en las altas calificaciones del alumno. Para ello, generamos una **matriz de correlaci√≥n** junto con un **mapa de calor**, lo que nos permitir√° visualizar de manera clara c√≥mo se relacionan las variables num√©ricas dentro del conjunto de datos.

Con este an√°lisis podremos detectar si existe una asociaci√≥n significativa entre las horas de estudio personal y las calificaciones obtenidas. Adem√°s, nos permitir√° observar la influencia de otros factores, como las horas de sue√±o, la asistencia a tutor√≠as o la participaci√≥n en actividades extracurriculares, en el rendimiento acad√©mico de los estudiantes con mejores notas.

```{r}
matriz_correlacion <- cor(data_notas_altas)
matriz_melt <- melt(matriz_correlacion)

ggplot(data = matriz_melt, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name = "Correlaci√≥n") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "Variables", y = "Variables", title = "Mapa de Calor de Correlaci√≥n")
```

El resultado de la matriz de correlaci√≥n nos arroja que no existe gran correlaci√≥n entre variables.

```{r}
model1 = lm(Horas_Semanales_Work ~ ., data = data_notas_altas)
summary(model1)
```

```{r}
data_notas_alta_simplificado <- data_notas_altas %>% dplyr::select(-School_Type_Public, -Gender_Female)
data_notas_alta_simplificado
```

```{r}
vif_values <- vif(lm(Horas_Semanales_Work ~ ., data = data_notas_alta_simplificado))
print(vif_values)
```

```{r}
indices <- sample(1:nrow(data_notas_alta_simplificado), size = 0.7 * nrow(data_notas_alta_simplificado))
train_data <- data_notas_alta_simplificado[indices, ]
test_data <- data_notas_alta_simplificado[-indices, ]
```

```{r}
library(MASS)
model_reduced <- stepAIC(lm(Horas_Semanales_Work ~ .^2, data = train_data), direction = "both")
summary(model_reduced)
```

```{r}
predicciones <- predict(model_reduced, newdata = test_data)
```

```{r}
comparacion <- data.frame(Real = test_data$Horas_Semanales_Work, Predicha = predicciones)
comparacion
```

```{r}
residuos <- comparacion$Real - comparacion$Predicha
rmse <- sqrt(mean(residuos^2))
print(paste("RMSE: ", rmse))
```
