---
title: "Students Performance Factors"
author: 
  - "Jairo Gonz√°lez Hern√°ndez"
  - "Mathis Goujon"
  - "Claudia Teresa Heredia Ceballos"
  - "Pedro L√≥pez Ruz"
  - "Jos√© Antonio Medina Garc√≠a"
---

# Students Performance Factors

**Trabajo Final Data Science**

*Master en Ingenier√≠a del Software: Cloud, Datos y Gesti√≥n de TI*

## Descripci√≥n del dominio

El rendimiento acad√©mico es un tema clave en la educaci√≥n, ya que influye directamente en las oportunidades que tendr√°n los jovenes en el d√≠a de ma√±ana y en el desarrollo de nuestra sociedad. Comprender qu√© factores afectan al desempe√±o de los estudiantes permitir√° a las instituciones educativas a mejorar los m√©todos de ense√±anza, dise√±ar pol√≠ticas educativas m√°s efectivas y proporcionar un mayor apoyo a aquellos estudiantes que lo necesiten.

### Enfoque del Trabajo

Este estudio analiza los factores que influyen en el rendimiento acad√©mico de los estudiantes. Para ello, se hace uso de datos relacionados con aspectos personales, sociales y acad√©micos para identificar patrones y determinar qu√© variables tienen mayor impacto en el desempe√±o escolar.

En particular, el estudio se enfoca en responder dos preguntas fundamentales:

1.  **¬øSe pueden agrupar a los estudiantes en una clase seg√∫n sus caracter√≠sticas?**\
    La organizaci√≥n de los estudiantes dentro del aula puede influir significativamente en su aprendizaje y rendimiento. Por esta raz√≥n, se explorar√° la posibilidad de segmentar a los alumnos con base en caracter√≠sticas clave como sus calificaciones previas, el tiempo dedicado al estudio, su nivel de motivaci√≥n, la presencia de discapacidades de aprendizaje y su participaci√≥n en actividades extracurriculares.

    Este enfoque permitir√° una distribuci√≥n estrat√©gica que potencie el aprendizaje al ubicar a los estudiantes en entornos que favorezcan su desarrollo acad√©mico y personal.

2.  **¬øCu√°ntas horas de trabajo personal necesita un estudiante para obtener una alta calificaci√≥n?**\
    Otro objetivo del estudio es determinar cu√°ntas horas diarias de estudio aut√≥nomo son necesarias para que un estudiante alcance una calificaci√≥n alta (entre 8 y 10). Para ello, se identificar√°n aquellos factores que tengan mayor influencia con la calificaci√≥n del estudiante, ya que estos aspectos pueden influir en el rendimiento acad√©mico. A trav√©s de un modelo de regresi√≥n, se buscar√° cuantificar la relaci√≥n entre estas variables y el desempe√±o estudiantil, proporcionando una gu√≠a para optimizar los h√°bitos de estudio.

A trav√©s de este an√°lisis, se pretende aportar informaci√≥n valiosa para mejorar las estrategias educativas, optimizar la distribuci√≥n de los estudiantes en el aula y ofrecer recomendaciones que permitan a los alumnos maximizar su rendimiento acad√©mico.

### Inter√©s y motivaci√≥n del estudio

El mundo en el que vivimos est√° en constante transformaci√≥n. Los sistemas educativos, como muchos otros aspectos de nuestra sociedad, deben adaptarse a nuevas realidades y desaf√≠os. En este contexto, resulta crucial comprender los factores que influyen en el rendimiento acad√©mico de los estudiantes, con el objetivo de mejorar los procesos de ense√±anza y crear un entorno de aprendizaje m√°s inclusivo y eficaz. Lo interesante de este estudio radica en identificar patrones y relaciones entre distintas variables que podr√≠an tener un impacto directo en la forma en que los estudiantes aprenden y se desarrollan.

En particular, nos gustar√≠a subrayar que el rendimiento acad√©mico no depende √∫nicamente de la capacidad intelectual del estudiante, sino tambi√©n de factores como el apoyo familiar, los h√°bitos de estudio, la motivaci√≥n personal y la presencia de discapacidades de aprendizaje. Este enfoque permite adoptar una perspectiva m√°s personalizada de la educaci√≥n, lo que a su vez puede contribuir a una mejor planificaci√≥n y dise√±o de estrategias pedag√≥gicas m√°s adaptadas a las necesidades de los estudiantes.

En el grupo de desarrollo de este trabajo, nos encontramos tanto estudiantes de **Ingenier√≠a Inform√°tica** como de **Ingenier√≠a de la Salud**. Esta diversidad de perspectivas y formaciones acad√©micas enriquece el enfoque del estudio, ya que, desde distintas disciplinas, reconocemos la importancia de crear un entorno educativo que no solo se base en el rendimiento acad√©mico, sino tambi√©n en el bienestar y las capacidades individuales de cada estudiante. Al ser nosotros mismos estudiantes, sabemos de primera mano que las aulas son cada vez m√°s diversas, y entender c√≥mo organizar y distribuir a los estudiantes de acuerdo con sus necesidades espec√≠ficas es clave para optimizar su rendimiento.

### Importancia local/nacional y en el contexto actual

A nivel global, la educaci√≥n es un pilar fundamental para el desarrollo. Pa√≠ses con bajos √≠ndices de rendimiento acad√©mico suelen enfrentar mayores desaf√≠os econ√≥micos y sociales. Adem√°s, en un contexto postpandemia, donde la ense√±anza a distancia ha cambiado la forma en que los estudiantes aprenden, es m√°s importante que nunca entender qu√© factores afectan su desempe√±o y c√≥mo pueden optimizarse los procesos de ense√±anza.

## Descripci√≥n del dataset

El dataset ha sido extra√≠do de la plataforma Kaggle y proporcionado por el usuario *lainguyn123*. Se puede acceder al conjunto de datos a trav√©s del siguiente enlace: [Student Performance Factors Dataset](https://www.kaggle.com/datasets/lainguyn123/student-performance-factors/data).

El archivo que contiene el conjunto de datos se denomina *StudentPerformanceFactors* y est√° en formato **CSV**, con un tama√±o aproximado de **641 kB**.

Este conjunto de datos proviene de una investigaci√≥n que analiza los factores que afectan el rendimiento acad√©mico de los estudiantes. Incluye diversas variables relacionadas con caracter√≠sticas personales, acad√©micas y sociales, tales como h√°bitos de estudio, asistencia, participaci√≥n de los padres, y otros aspectos clave que influyen en el √©xito acad√©mico de los estudiantes.

En cuanto a sus dimensiones, el dataset consta de un total de:

-   **6,607 Filas**

-   **20 Columnas**

## Librer√≠as

La funci√≥n ipak est√° dise√±ada para facilitar la instalaci√≥n y carga de paquetes en R. Es √∫til cuando desea asegurarse de que todos los paquetes necesarios para un script o proyecto se instalan y cargan autom√°ticamente. <https://gist.github.com/stevenworthington/3178163>

```{r}
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if(length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("tidyverse","ggplot2", "dplyr","gridExtra", "reshape2", "car", "ggridges", "factoextra", "cluster", "NbClust", "RColorBrewer")
ipak(packages)
```

## Exploraci√≥n de datos

Antes de realizar cualquier an√°lisis, es fundamental explorar el conjunto de datos para comprender la estructura de los mismos, identificar posibles inconsistencias y verificar la presencia de valores faltantes. En esta secci√≥n, realizamos una inspecci√≥n inicial del dataset.

### Lectura de los datos

Cargamos el dataset desde el archivo CSV y verificamos su correcta importaci√≥n:

```{r}
data <- read.csv("data/StudentPerformanceFactors.csv", header=TRUE)
```

A continuaci√≥n, se presentan las primeras seis filas del conjunto de datos para obtener una vista preliminar de su estructura y los valores de las variables.

```{r}
head(data)
```

Vamos a examinar la estructura del conjunto de datos para obtener un resumen de las variables presentes, su tipo de dato y una visi√≥n general de c√≥mo est√°n organizados los datos.

```{r}
str(data)
```

El dataset est√° compuesto por **6,607 filas** y **20 columnas**, las cuales incluyen atributos de distintos tipos: *num√©ricos*, *categ√≥ricos* y *booleanos*.

A continuaci√≥n, se describen algunos de estos atributos:

-   **Hours_Studied**: N√∫mero de horas de estudio semanales.

-   **Attendance**: Porcentaje de clases a las que ha asistido.

-   **Parental_Involvement**: Nivel de implicaci√≥n de los padres en la educaci√≥n del alumno *(Low, Medium, High)*.

-   **Access_to_Resources**: Disponibilidad de recursos educativos *(Low, Medium, High)*.

-   **Extracurricular_Activities**: Participaci√≥n en actividades extraescolares *(Yes, No)*.

-   **Sleep_Hours**: N√∫mero medio de horas de sue√±o por noche.

-   **Previous_Scores**: Puntuaciones de ex√°menes anteriores.

-   **Motivation_Level**: Nivel de motivaci√≥n del estudiante *(Low, Medium, High)*.

-   **Internet_Access**: Disponibilidad de acceso a Internet *(Yes, No)*.

-   **Tutoring_Sessions**: N√∫mero de sesiones de tutor√≠a a las que asiste al mes.

-   **Family_Income**: Nivel de ingresos familiares *(Low, Medium, High)*.

-   **Teacher_Quality**: Calidad de los profesores *(Low, Medium, High)*.

-   **School_Type**: Tipo de escuela a la que asisti√≥ *(Public, Private)*.

-   **Peer_Influence**: Influencia de los compa√±eros en el rendimiento acad√©mico *(Positive, Neutral, Negative)*.

-   **Physical_Activity**: N√∫mero medio de horas de actividad f√≠sica a la semana.

-   **Learning_Disabilities**: Presencia de dificultades de aprendizaje *(Yes, No)*.

-   **Parental_Education_Level**: Nivel educativo m√°s alto de los padres *(High School, College, Postgraduate)*.

-   **Distance_from_Home**: Distancia de casa a la escuela *(Near, Moderate, Far)*.

-   **Gender**: G√©nero del estudiante *(Male, Female)*.

-   **Exam_Score**: Calificaci√≥n del examen final.

### Revisi√≥n de los datos

A continuaci√≥n, vamos a observar si existen valores faltantes, err√≥neos o inconsistentes en el conjunto de datos. Utilizaremos una funci√≥n que identifica las filas con valores NA o vac√≠os ("") en cada columna, lo que nos permitir√° tener un panorama de los datos.

```{r}
detect_missing_data <- function(df) {
  na_count <- colSums(is.na(df))  # Contar los NA en cada columna
  empty_count <- colSums(sapply(df, function(x) x == ""))  # Contar los valores vac√≠os en cada columna
  
  missing_data <- data.frame(NA_Count = na_count, Empty_Count = empty_count)
  missing_data <- missing_data[missing_data$NA_Count > 0 | missing_data$Empty_Count > 0, ]
  
  return(missing_data)
}


missing_data <- detect_missing_data(data)
missing_data
```

En el resultado arrojado por la funci√≥n podemos observar que no existen valores **NA** en las columnas de nuestro dataframe, lo que significa que no hay datos expl√≠citamente faltantes o nulos. Sin embargo, tambi√©n notamos que hay filas con **valores vac√≠os** en ciertas variables categ√≥ricas.

Al sumar el total de valores faltantes podemos observar que puede haber un m√°ximo de **235 filas** con alg√∫n valor faltante. Esto supone aproximadamente el **3.56%** del total de filas del conjunto de datos.

### An√°lisis descriptivo

#### Variables num√©ricas

En esta secci√≥n, vamos a calcular las **medidas estad√≠sticas b√°sicas** para las variables num√©ricas, tales como la *media*, *mediana*, *desviaci√≥n est√°ndar*, y otros estad√≠sticos relevantes. Tambi√©n calcularemos las frecuencias de las variables categ√≥ricas para entender mejor la distribuci√≥n de los datos.

```{r}
# Resumen estad√≠stico de las variables num√©ricas
numeric_vars <- sapply(data, is.numeric)  
data_numeric <- data[, numeric_vars]
summary(data_numeric)
```

**Observaciones**

-   La mayor√≠a de los estudiantes estudian entre **16 y 24 horas a la semana**, con una distribuci√≥n bastante centrada en la media y la mediana. Sin embargo, se observa que el *m√°ximo de 44 horas* indica la presencia de algunos estudiantes que estudian significativamente m√°s.

-   La **asistencia (Attendance)** tiende a ser **alta**, con el 50% de los estudiantes asistiendo al menos 80% de las clases. Sin embargo, **hay alumnos con asistencia m√°s baja (60%)**, aunque no encontramos a ning√∫n alumno que no asista al menos a la mitad de las clases.

-   La mayor√≠a de los estudiantes duermen entre **6 y 8 horas**, aunque hay algunos casos que duermen solo 4 horas, lo que podr√≠a afectar su rendimiento acad√©mico.

-   La **distribuci√≥n de calificaciones previas est√° equilibrada**, con la mediana y la media relativamente cercanas. Sin embargo, hay estudiantes con puntajes significativamente m√°s bajos (50), lo que podr√≠a indicar dificultades acad√©micas previas.

-   La mayor√≠a de los estudiantes asisten a **1 o 2 sesiones de tutor√≠a al mes**, pero tambi√©n hay quienes no reciben ninguna tutor√≠a. Respecto a la actividad f√≠sica, la mayor√≠a de los estudiantes realizan entre 2 y 4 horas, aunque algunos no hacen ninguna actividad, lo que podr√≠a impactar su salud y concentraci√≥n.

-   Respecto a **la calificaci√≥n final del ex√°men**, la media y la mediana est√°n alineadas, lo que indica una **distribuci√≥n sim√©trica**. La mayor√≠a de los estudiantes obtienen calificaciones **entre 65 y 69**; sin embargo, algunos alcanzan hasta 101, lo que podr√≠a deberse a un posible error en los datos o a un estudiante destacado que, gracias a una bonificaci√≥n adicional, supera la calificaci√≥n m√°xima establecida.

Estas conclusiones nos van a orientar sobre los pr√≥ximos pasos en el preprocesamiento de datos, como identificar grupos de estudiantes con distintos patrones de estudio, asistencia y tutor√≠as. Adem√°s, va a ser clave analizar posibles outliers, como la calificaci√≥n de 101 en el examen final, para determinar si se trata de un error o una excepci√≥n justificable.

A continuaci√≥n calculamos la *desviaci√≥n est√°ndar* y la *varianza*, lo cual nos da una idea de la dispersi√≥n de los datos con los que vamos a trabajar.

```{r}
# Desviaci√≥n est√°ndar
desviacion_estandar <- sapply(data_numeric, sd)
desviacion_estandar
```

```{r}
# varianza
varianza <- sapply(data_numeric, var)
varianza
```

**Conclusiones**

-   **Variables con alta variabilidad**: `Attendance` y `Previous_Scores` tienen las varianzas m√°s altas, lo que sugiere que hay *grandes diferencias* entre los estudiantes en t√©rminos de asistencia y calificaciones previas. Con esta informaci√≥n, podr√≠amos analizar si la variabilidad en Attendance y Previous_Scores impacta directamente en el Exam_Score.

-   **Variables con baja variabilidad**: `Sleep_Hours`, `Tutoring_Sessions`, `Physical_Activity` muestran desviaciones est√°ndar m√°s bajas, lo que indica que la mayor√≠a de los estudiantes tienen *comportamientos similares en estos aspectos*. Es decir, suelen dormir las mismas horas, realizar rutinas de ejercicio similares y sesiones de tutor√≠a parecidas. Por lo que se puede llegar a la conclusi√≥n de que estos factores pueden no diferenciar mucho a los estudiantes en t√©rminos de rendimiento.

-   **Exam_Score vs Previous_Scores**: *Previous Scores tiene una variabilidad significativamente mayor a Exam_Score* (14.40 vs. 3.89 en desviaci√≥n est√°ndar), lo que sugiere que las calificaciones en el examen final est√°n m√°s concentradas alrededor de un valor central en comparaci√≥n con las calificaciones anteriores.

-   Respecto a **Hours_Studied**, su varianza de *35.89* indica una alta dispersi√≥n, lo que puede significar que los estudiantes tienen *h√°bitos de estudio muy variados*. Algunos dedican muchas horas a estudiar, mientras que otros apenas lo hacen. Por ello, puede que el tiempo de estudio sea un factor muy variable y determinante en el rendimiento acad√©mico.

#### Variables categ√≥ricas

Para las variables categ√≥ricas, vamos a calcular las *frecuencias y proporciones de cada categor√≠a* de modo que podamos observar la distribuci√≥n de las diferentes categor√≠as dentro de cada variable. Para ello, primero seleccionamos las variables categ√≥ricas y luego hacemos uso de la funci√≥n `table()` y `prop.table()` para obtener la distribuci√≥n de cada una.

```{r}
data <- data %>%
  mutate(across(where(is.character), as.factor))
categorical_vars <- sapply(data, is.factor) 
data_categoric <- data[, categorical_vars] # Filtrar solo variables categ√≥ricas
```

```{r}
# Obtener frecuencias absolutas
frecuencias <- lapply(data_categoric, table)
frecuencias
```

Algunas de las observaciones obtenidas son las siguientes:

-   **Parental Involvement**, **Teacher Quality** y **Motivation Level**: La mayor√≠a de los estudiantes tienen un nivel medio (seguido de nivel bajo) de involucramiento familiar, motivaci√≥n, y calidad docente, lo cual podr√≠a indicar √°reas clave para intervenir en el proceso educativo.

-   **Internet_Access**, **Extracurricular_Activities**, y **Access_To_Recourses**: Las variables relacionadas con el acceso a recursos muestran una distribuci√≥n relativamente equilibrada, lo que podr√≠a ser positivo para el acceso equitativo a la educaci√≥n.

-   La distribuci√≥n de **Family_Income** (ingresos familiares) muestra una ligera mayor√≠a de estudiantes provenientes de familias con ingresos bajos (2672), seguida de familias con ingresos medios (2666), y una menor representaci√≥n de familias con ingresos altos (1269). Adem√°s, la mayor√≠a de los estudiantes asiste a escuelas p√∫blicas (4598), con un n√∫mero considerable en escuelas privadas (2009). Estas diferencias de las variables sugieren que el contexto socioecon√≥mico podr√≠a influir en la experiencia educativa de los estudiantes.

-   **Learning disabilities**: La mayor√≠a de los estudiantes no tiene discapacidades de aprendizaje (5912), mientras que una fracci√≥n peque√±a s√≠ las tiene (695).

- **Peer Influence**: La influencia neutral de los compa√±eros parece ser la m√°s com√∫n (2592), seguida de positiva (2638) y negativa (1377). La influencia de los compa√±eros es *predominantemente positiva o neutral*, lo que puede indicar que los estudiantes se ven generalmente influenciados de manera favorable.

De forma complementaria, se muestran las proporciones de cada categor√≠a dentro de las variables categ√≥ricas del conjunto de datos.

```{r}
# Obtener proporciones relativas
proporciones <- lapply(data_categoric, function(x) prop.table(table(x)))
proporciones
```
En el apartado de visualizaci√≥n de los datos se explorar√°n m√°s a fondo estas distribuciones y relaciones, lo que permitir√° tener una comprensi√≥n m√°s clara y detallada de los patrones en el conjunto de datos.

## Preprocesamiento de datos

Durante la exploraci√≥n de los datos, hemos identificado que existen filas con valores faltantes. Dado que la proporci√≥n de instancias con valores faltantes es relativamente baja, hemos decidido **eliminar estas filas**. Consideramos que su eliminaci√≥n no afectar√° de manera significativa la integridad general del conjunto de datos, permiti√©ndonos continuar con el an√°lisis sin introducir sesgos o inconsistencias.

```{r}
clean_missing_data <- function(df) {
  original_row_count <- nrow(df)
  
  df <- df[!apply(df, 1, function(x) any(is.na(x) | x == "")), ] #Borramos las filas
  
  cleaned_row_count <- nrow(df)
  rows_removed <- original_row_count - cleaned_row_count
  cat("N√∫mero de filas eliminadas:", rows_removed, "\n")
  
  return(df)
}

data <- clean_missing_data(data)
```

Observamos que se han eliminado 229 filas por lo que el dataset sin ning√∫n valor de faltante constar√≠a de un total de **6378 filas**.

### Detecci√≥n de outliers

Antes de desarrollar modelos predictivos, es crucial identificar los valores at√≠picos. Para ello, empleamos el **m√©todo del rango intercuartil (IQR)**, que nos permite detectar valores extremos en las variables num√©ricas, evaluar su impacto en el an√°lisis y determinar posibles tratamientos.

```{r}
numeric_cols <- sapply(data, is.numeric)

count_outliers <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  sum(x < lower_bound | x > upper_bound, na.rm = TRUE)
}


for (col_name in names(data)[numeric_cols]) {
  num_outliers <- count_outliers(data[[col_name]])
  print(paste("Variable:", col_name, "- Outliers:", num_outliers))
}
```

Podemos observar que existen outliers en las variables `Hours_studies`, `Tutoring_Sessions` y `Exam_Score`. Para analizarlos mejor, utilizaremos gr√°ficos de caja o boxplots que nos permitir√°n visualizar su distribuci√≥n.

```{r}
plot_boxplots <- function(df) {
  plots <- list()
  numeric_cols <- c("Hours_Studied", "Tutoring_Sessions", "Exam_Score")
  numeric_cols <- numeric_cols[numeric_cols %in% names(df)]
  

  for (var in numeric_cols) {
    p <- ggplot(df, aes_string(y = var)) +
      geom_boxplot(fill = "orange", alpha = 0.7) +
      theme_minimal() +
      labs(title = paste("Outliers in", var), y = var)
    
    plots[[var]] <- p
  }

  for (p in plots) {
    print(p)
  }
}
```

```{r}
plot_boxplots(data)
```

Al observar los gr√°ficos de caja, podemos identificar la presencia de valores at√≠picos. Sin embargo, no todos estos valores deber√≠an considerarse como anomal√≠as.

En el caso de la variable `tutoring_sessions`, los valores entre 4 y 8 se marcan como at√≠picos, aunque representan un rango perfectamente v√°lido de horas de tutor√≠a. De manera similar, en `Hours_Studied`, se detectan valores extremos por encima de las 35 horas y por debajo de las 5 horas de estudio. Si bien estos pueden parecer at√≠picos desde una perspectiva estad√≠stica, es posible que reflejen h√°bitos de estudio reales en algunos estudiantes.

En cambio, en el gr√°fico de `Exam_Scores`, se pueden notar calificaciones que superan el valor m√°ximo permitido de 100. Para solucionar esto, filtraremos las filas en las que el valor de `Exam_Score` sea superior a 100 y lo estableceremos a la m√°xima nota posible, es decir, 100.

```{r}
data$Exam_Score[data$Exam_Score > 100] <- 100
max_Exam_score <- max(data$Exam_Score)
print(max_Exam_score)
```

### Codificaci√≥n

Para preparar los datos de manera √≥ptima para el an√°lisis, aplicamos varias transformaciones a las variables categ√≥ricas y ordinales. Esto nos permite estructurar la informaci√≥n de manera que los modelos puedan interpretarla correctamente.

Con esta funci√≥n convertimos las columnas del data frame en factores ordenados y les asignamos valores enteros, de acuerdo con un orden espec√≠fico de niveles. Esto es util para las variables que tienen una relaci√≥n de orden o tienen un nivel jer√°rquico o progresivo, es decir, que pueden compararse en t√©rminos de m√°s o menos, mejor o peor, mayor o menor.

-   `Parental_Involvement`,`Access_to_Resources`,`Motivation_Level`,`Family_Income`,`Teacher_Quality`. Estas variables pueden ordenarse de menor a mayor o viceversa".

-   En `Peer_Influence`, **Positive \> Neutral \> Negative** en t√©rminos de impacto en el rendimiento. Por lo que tambien se pueden ordenar.

-   En `Distance_from_Home` ordenamos los valores en t√©rminos de **nivel de cercan√≠a** de la escuela a la casa del estudiante.

-   En `Parental_Education_Level` ordenamos los valores en t√©rminos de **nivel de estudio de los padres**. Desde menos estudios (High School) hasta m√°s estudios (Postgraduate).

```{r}
convert_to_ordered_int <- function(df, column_names, levels_order, ordered = TRUE) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      df[[col]] <- as.integer(factor(df[[col]], levels = levels_order, ordered = ordered))
    }
  }
  return(df)
}

```

Algunas variables categ√≥ricas contienen √∫nicamente valores "Yes" o "No", por lo que es m√°s eficiente transformarlas en valores 0 y 1, 'No' y 'Yes', respectivamente.

Las variables modificadas ser√°n:

-   `Extracurricular_Activities`, `Internet_Access`, `Learning_Disabilities` ‚Üí Yes = 1, No = 0

```{r}
convert_to_binary <- function(df, column_names) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      df[[col]] <- ifelse(df[[col]] == "Yes", 1, 0)
    }
  }
  return(df)
}

```

Algunas variables no tienen una jerarqu√≠a clara, por lo que en lugar de asignar valores ordinales, creamos columnas binarias (dummies) para cada categor√≠a, es decir, aplicamos One-Hot Encoding.

-   `School_Type` pasar√° a dividirse en dos columnas: `School_Type_Public` y `School_Type_Private`
-   `Gender` se convierte en `Gender_Male` y `Gender_Female`.

```{r}
convert_to_one_hot <- function(df, column_names) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      unique_values <- unique(df[[col]])
      for (val in unique_values) {
        new_col_name <- paste(col, val, sep = "_")
        df[[new_col_name]] <- ifelse(df[[col]] == val, 1, 0)
      }
      df[[col]] <- NULL  # Eliminamos la columna original despu√©s de crear las dummy variables
    }
  }
  return(df)
}

```

```{r}
clean_and_filter_data <- function(data) {
  data <- data %>%
    distinct() %>%
    
    # Convertir a valores ordenados (Low < Medium < High)
    convert_to_ordered_int(c("Parental_Involvement", "Access_to_Resources", "Motivation_Level",
                              "Family_Income", "Teacher_Quality"),
                           c("Low", "Medium", "High")) %>%
    
    # Convertir Peer_Influence en valores ordenados (Negative < Neutral < Positive)
    convert_to_ordered_int("Peer_Influence", c("Negative", "Neutral", "Positive")) %>%
    
    # Convertir Parental Education Level en valores ordenados (High School < College < Postgraduate)
    convert_to_ordered_int("Parental_Education_Level", c("High School", "College", "Postgraduate")) %>%
    
    # Convertir Distance_from_Home en valores ordenados (Near < Moderate < Far)
    convert_to_ordered_int("Distance_from_Home", c("Near", "Moderate", "Far")) %>%
    
    # Convertir a valores binarios (No = 0, Yes = 1)
    mutate(
      Extracurricular_Activities = ifelse(Extracurricular_Activities == "Yes", 1, 0),
      Internet_Access = ifelse(Internet_Access == "Yes", 1, 0),
      Learning_Disabilities = ifelse(Learning_Disabilities == "Yes", 1, 0)
    ) %>%
    
    # Aplicar One-Hot Encoding a School_Type y Gender
    mutate(
      School_Type_Private = ifelse(School_Type == "Private", 1, 0),
      School_Type_Public = ifelse(School_Type == "Public", 1, 0),
      Gender_Male = ifelse(Gender == "Male", 1, 0),
      Gender_Female = ifelse(Gender == "Female", 1, 0)
    ) %>%
    
    # Eliminar las columnas originales despu√©s de One-Hot Encoding
    select(-School_Type, -Gender)

  return(data)
}

```

```{r}
df_cleaned <- clean_and_filter_data(data)
```

```{r}
df_cleaned
```

Despu√©s de la codificaci√≥n, nuestro dataset consta de estos tipos:

```{r}
str(df_cleaned)
```

### Escalarizaci√≥n

Para que el an√°lisis sea √≥ptimo, tambi√©n es necesario escalar las variables.

-   `Sleep_Hours` toma como valor las horas de sue√±o por noche. Supondremos que el estudiante duerme esta cantidad de horas todos los d√≠as por lo que modificaremos el valor para que sean horas semanales (Multiplicamos por 7 las horas de sue√±o diarias).

-   `Tutoring_Sessions` toma como valor las sesiones de tutoria por mes. Para escalar esta variable, se tomar√° 1 sesi√≥n de tutor√≠a = 1 hora y a su vez, se pasar√° a horas semanales. Por ejemplo, si un estudiante tiene `Tutoring_Sessions` = 4 en un mes, significa que tiene 1 por semana (`Tutoring_Sessions`/ 4 semanas).

```{r}
scale_time_variables <- function(df) {
  df <- df %>%
    mutate(
      Sleep_Hours = Sleep_Hours * 7,  # Convertir de horas por noche a horas por semana
      Tutoring_Sessions = Tutoring_Sessions / 4  # Convertir sesiones a horas/semana
    )
  return(df)
}

df_cleaned <- scale_time_variables(df_cleaned)

print("Sleep_Hours:") 
summary(df_cleaned$Sleep_Hours)  # Deber√≠a estar en un rango de 0-56 horas semanales
print("Tutoring_Sessions:")
summary(df_cleaned$Tutoring_Sessions)  # Ahora representar√° horas de tutor√≠a por semana


```

Como puede observarse, para las horas de sue√±o semanales, el m√≠nimo es 28, lo cual significa que hay estudiantes que duermen 4 horas por noche (4 \* 7 = 28). La mediana es 49, lo que indica que la mayor√≠a de los estudiantes duermen aproximadamente 7 horas por noche (7 \* 7 = 49). El m√°ximo es 70, lo que implica que algunos estudiantes duermen 10 horas por noche (10 \* 7 = 70).

Por otro lado, para las horas de tutor√≠a por semana, el m√≠nimo es 0, lo cual es correcto, ya que algunos estudiantes no tienen sesiones de tutor√≠a. La mediana es 0.25, lo que significa que muchos estudiantes tienen 1 sesi√≥n por mes (1 hora / 4 = 0.25 horas/semana). El m√°ximo es 2, lo que indica que algunos estudiantes tienen 8 sesiones de tutor√≠a por mes, que equivale a 2 horas de tutor√≠a por semana.

## Visualizaciones Iniciales

## Distribuci√≥n de variables num√©ricas

```{r}
create_dist_grap <- function(df, variable, binwidth = 1, fill = "cornflowerblue") {
  if (!(variable %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  ggplot(df, aes_string(x = variable)) +
    geom_histogram(binwidth = binwidth, 
                   fill = fill, color = "black", bins = 20) +
    labs(title = paste(variable, "analysis"), x = variable, y = "Count") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5))
}

create_dist_grap(data, "Sleep_Hours")
create_dist_grap(data, "Hours_Studied")
create_dist_grap(data, "Attendance", binwidth = 5)
create_dist_grap(data, "Tutoring_Sessions")
create_dist_grap(data, "Physical_Activity")
create_dist_grap(data, "Previous_Scores")
create_dist_grap(data, "Exam_Score", fill = "orange")
```

## Distribuci√≥n de variables categ√≥ricas

```{r}
create_pie_chart <- function(df, var_name) {
  if (!(var_name %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  dist_var <- as.data.frame(table(df[[var_name]]))
  colnames(dist_var) <- c(var_name, "Count")
  dist_var$Percentage <- round(dist_var$Count / sum(dist_var$Count) * 100, 1)
  

  ggplot(dist_var, aes(x = "", y = Count, fill = get(var_name))) +
    geom_bar(stat = "identity", width = 1) +
    coord_polar(theta = "y") +
    geom_text(aes(label = paste0(Percentage, "%")), position = position_stack(vjust = 0.5), size = 5) +
    labs(title = paste("Distribuci√≥n de", var_name), fill=var_name) +
    theme_minimal() +
    theme(axis.text.x = element_blank(), 
          axis.ticks = element_blank(),
          panel.grid = element_blank())
}
```

```{r}
barplot_chart <- function(df, var_name, show_percentage = TRUE) {
  if (!(var_name %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  dist_var <- as.data.frame(table(df[[var_name]]))
  colnames(dist_var) <- c(var_name, "Count")
  dist_var$Percentage <- dist_var$Count / sum(dist_var$Count) * 100
  

  colors <- brewer.pal(n = nrow(dist_var), name = "Pastel1")  
  
  p <- ggplot(dist_var, aes_string(x = var_name, y = "Count", fill = var_name)) +
    geom_bar(stat = "identity", color = "black") +
    scale_fill_manual(values = colors) +  
    theme_minimal() +
    labs(title = paste("Distribuci√≥n de", var_name),
         x = var_name,
         y = "Frecuencia") +
    theme(legend.position = "none") 
  
  if (show_percentage) {
    p <- p + geom_text(aes(label = paste0(round(Percentage, 1), "%")), 
                       vjust = -0.3,
                       color = "black", 
                       size = 4)
  }
  
  print(p)
}
```

```{r}
barplot_chart(data, "Parental_Involvement", show_percentage = FALSE)
barplot_chart(data, "Access_to_Resources", show_percentage = FALSE)
barplot_chart(data, "Parental_Education_Level", show_percentage = FALSE)
barplot_chart(data, "Distance_from_Home", show_percentage = FALSE)
barplot_chart(data, "Extracurricular_Activities")
barplot_chart(data, "School_Type")
barplot_chart(data, "Gender")
```

## Relaci√≥n entre variables (Diagramas de dispersi√≥n)

```{r}
scatter_plot <- function(df, var1, var2) {
  if (!(var1 %in% colnames(df)) | !(var2 %in% colnames(df))) {
    stop("Una o ambas variables no existen en el dataframe.")
  }
  
  if (!is.numeric(df[[var1]]) | !is.numeric(df[[var2]])) {
    stop("Ambas variables deben ser num√©ricas.")
  }
  
  color_palette <- brewer.pal(9, "Spectral")

  
  # Crear el gr√°fico de dispersi√≥n
  p <- ggplot(df, aes(x = .data[[var1]], y = .data[[var2]])) +
    geom_point(aes(color = .data[[var1]]), size = 3) + 
    scale_color_gradientn(colors = color_palette) + 
    geom_smooth(method = "lm", color = "red", se = FALSE) +  # L√≠nea de regresi√≥n
    theme_minimal() +
    labs(title = paste("Gr√°fico de Dispersi√≥n de", var1, "vs", var2),
         x = var1,
         y = var2) +
    theme(plot.title = element_text(hjust = 0.5))  
  
  print(p)
}
```

```{r}
scatter_plot(data, "Hours_Studied", "Exam_Score")
scatter_plot(data, "Attendance", "Exam_Score")
```

## Comparaci√≥n entre variables categ√≥rica y num√©rica

```{r}
categoric_numeric_barplot <- function(df, cat_var, num_var) {
  if (!(cat_var %in% colnames(df)) | !(num_var %in% colnames(df))) {
    stop("Una o ambas variables no existen en el dataframe.")
  }
  
  color_palette <- brewer.pal(3, "Pastel1")  
  

  p <- ggplot(df, aes_string(x = cat_var, y = num_var, fill = cat_var)) +
    geom_bar(stat = "summary", fun = "mean", color = "black") +
    scale_fill_manual(values = color_palette) +  
    theme_minimal() +
    labs(title = paste("Promedio de", num_var, "por", cat_var),
         x = cat_var,
         y = paste("Promedio de", num_var)) +
    theme(plot.title = element_text(hjust = 0.5)) 
  
  print(p)
}

categoric_numeric_barplot(data,"Parental_Involvement","Previous_Scores")
categoric_numeric_barplot(data,"Access_to_Resources","Previous_Scores")
categoric_numeric_barplot(data,"Motivation_Level","Previous_Scores")
categoric_numeric_barplot(data,"School_Type","Previous_Scores")
```

## Relaci√≥n entre variables categ√≥ricas

```{r}
stacked_barplot <- function(df, var_x, var_fill) {
  if (!(var_x %in% colnames(df)) | !(var_fill %in% colnames(df))) {
    stop("One or both variables do not exist in the dataframe.")
  }
  
  df[[var_x]] <- as.factor(df[[var_x]])
  df[[var_fill]] <- as.factor(df[[var_fill]])
  

  color_palette <- brewer.pal(3, "Pastel1")  
  
  p <- ggplot(df, aes_string(x = var_x, fill = var_fill)) +
    geom_bar(position = "fill") +
    scale_fill_manual(values = color_palette) + 
    theme_minimal() +
    labs(title = paste("Distribution of", var_fill, "by", var_x),
         x = var_x,
         y = "Proportion") +
    theme(plot.title = element_text(hjust = 0.5)) 
  
  print(p)
}

stacked_barplot(data, "School_Type", "Parental_Involvement")
stacked_barplot(data, "School_Type", "Family_Income")
stacked_barplot(data, "School_Type", "Teacher_Quality")
```

```{r}
barplot_school_attendance_avg <- function(df) {
  if (!("School_Type" %in% colnames(df)) | !("Attendance" %in% colnames(df))) {
    stop("Las columnas School_Type y Attendance deben existir en el dataframe.")
  }
  
  avg_attendance <- aggregate(Attendance ~ School_Type, data = df, FUN = mean)
  colors <- brewer.pal(n = nrow(avg_attendance), name = "Pastel1")
  
  p <- ggplot(avg_attendance, aes(x = School_Type, y = Attendance, fill = School_Type)) +
    geom_bar(stat = "identity", color = "black") +
    scale_fill_manual(values = colors) + 
    theme_minimal() +
    labs(title = "Promedio de Asistencia por Tipo de Escuela",
         x = "Tipo de Escuela",
         y = "Promedio de Asistencia") +
    theme(legend.position = "none")
  
  print(p)
}

barplot_school_attendance_avg(data)

```

## Preguntas

### ¬øSe pueden agrupar a los estudiantes en una clase seg√∫n sus caracter√≠sticas?

-   **Objectivo**: Intentar asignar a los alumnos a grupos de manera que se favorezca su aprendizaje.

En primer lugar, decidimos una estrategia a adoptar para agrupar a los alumnos. Nos enfocamos en diferentes variables seg√∫n el objetivo a cumplir:

-   **Academic**: Nos interesamos en las variables que reflejan el √©xito escolar en t√©rminos acad√©micos, como la asistencia, el n√∫mero de horas de estudio o los resultados obtenidos.

-   **Support**: Aqu√≠, el enfoque est√° en las necesidades de apoyo del alumno. ¬øNecesita horas de tutor√≠a? ¬øTiene dificultades para aprender?

-   **Resource**: ¬øDispone el alumno de los recursos necesarios para favorecer su aprendizaje?

-   **Extra**: Variables relacionadas con el ocio y la vida social. ¬øTiene el alumno actividades extracurriculares? ¬øCu√°les son sus relaciones de amistad?

-   **General**: Todas las variables. ¬øQue grupos conforman estos datos?

```{r}
academic_columns <- c("Hours_Studied", "Attendance", "Exam_Score", "Previous_Scores")
support_columns <- c("Learning_Disabilities", "Tutoring_Sessions", "Access_to_Resources")
resource_columns <- c("Family_Income", "Access_to_Resources", "Internet_Access", "Parental_Education_Level")
extra_columns <- c("Extracurricular_Activities", "Physical_Activity", "Peer_Influence")
general_columns <- c(
  "Hours_Studied",
  "Attendance",
  "Parental_Involvement",
  "Access_to_Resources",
  "Extracurricular_Activities",
  "Sleep_Hours",
  "Previous_Scores",
  "Motivation_Level",
  "Internet_Access",
  "Tutoring_Sessions",
  "Family_Income",
  "Teacher_Quality",
  "School_Type_Private",
  "School_Type_Public",
  "Peer_Influence",
  "Physical_Activity",
  "Learning_Disabilities",
  "Parental_Education_Level",
  "Distance_from_Home",
  "Gender_Male",
  "Gender_Female",
  "Exam_Score"
)
```

```{r}
df_scaled = as_tibble(scale(df_cleaned))

data_for_cluster_academic <- select(df_scaled, all_of(academic_columns))
data_for_cluster_support <- select(df_scaled, all_of(support_columns))
data_for_cluster_resource <- select(df_scaled, all_of(resource_columns))
data_for_cluster_extra <- select(df_scaled, all_of(extra_columns))
data_for_cluster_general <- select(df_scaled, all_of(general_columns))
```

Para agrupar a los alumnos seg√∫n estas categor√≠as, utilizaremos el m√©todo de **clustering K-Means**.

Primero, definimos una funci√≥n que nos permita seleccionar el mejor valor de **K**.

```{r}
compare_k <- function(df) {
  print(fviz_nbclust(df, kmeans, method = "wss") + 
    ggtitle("Elbow Method for Optimal K"))

  print(fviz_nbclust(df, kmeans, method = "silhouette") + 
    ggtitle("Silhouette Method for Optimal K"))
}
```

Luego, definimos una funci√≥n que aplique el clustering y a√±ada la variable **cluster** a nuestro conjunto de datos inicial.

```{r}
applying_kmeans <- function(data_for_clustering, k){
  set.seed(42)
  kmeans_model <- kmeans(data_for_clustering, centers = k, nstart = 25)
  df_with_cluster <- as_tibble(df_cleaned)
  df_with_cluster$Cluster <- as.factor(kmeans_model$cluster)
  return(df_with_cluster)
}
```

Finalmente, definimos una funci√≥n que nos permita **comparar los grupos formados**:\
- ¬øCu√°ntos alumnos hay en cada cluster?\
- Comparaci√≥n de las variables utilizadas en el clustering mediante **ridgeline plots**.

```{r}
print_clustering_results <- function(df_with_clusters, data_for_cluster, columns_to_focus){
  cluster_summary <- df_with_clusters %>%
    group_by(Cluster) %>%
    summarise(
      Num_Students = n()
    )
  
  print(ggplot(cluster_summary, aes(x = as.factor(Cluster), y = Num_Students, fill = as.factor(Cluster))) +
          geom_bar(stat = "identity") +
          labs(title = "Number of Students in Each Cluster", x = "Cluster", y = "Student Count") +
          theme_minimal())
  
  for (column in columns_to_focus) {
    print(ggplot(df_with_clusters, aes(x = as.factor(Cluster), y = !!sym(column), fill = as.factor(Cluster))) +
            geom_boxplot() +
            labs(title = paste(column, "Distribution in Each Cluster"), x = "Cluster", y = column) +
            theme_minimal())
  }
  
  print(fviz_cluster(list(data = data_for_cluster, cluster = df_with_clusters$Cluster),
                     geom = "point",
                     ellipse.type = "convex",
                     ggtheme = theme_minimal(),
                     main = "Cluster Visualization (PCA Projection)"))
}

```

```{r}
find_optimal_clusters <- function(data) {
  
  result <- NbClust(data, diss = NULL, distance = "euclidean", 
                    min.nc = 2, max.nc = 4, method = "kmeans")
  
  # Retorna el n√∫mero √≥ptimo de clusters sugerido
  return(result)
}
```

#### Academic

```{r}
compare_k(data_for_cluster_academic)
```

```{r}
optimal_clusters_academic <- find_optimal_clusters(data_for_cluster_academic)

```

Analizando las gr√°ficas del m√©todo del Codo (Elbow Method) y del Coeficiente de Silhouette, llegamos a la conclusi√≥n de que el n√∫mero √≥ptimo de cl√∫steres es ùëò = 2 k=2.

Esta conclusi√≥n se fundamenta en dos aspectos clave:

**M√©todo del Codo (Elbow Method)**: En esta gr√°fica, observamos que la mayor reducci√≥n en la suma de cuadrados dentro del grupo ocurre hasta ùëò = 2 k=2, formando un punto de inflexi√≥n o "codo" en ese valor. A partir de ùëò = 2 k=2, la disminuci√≥n en la varianza interna de los cl√∫steres se vuelve menos pronunciada, lo que indica que agregar m√°s cl√∫steres no aporta una mejora significativa en la compactaci√≥n de los datos.

**Coeficiente de Silhouette (Silhouette Method)**: Este m√©todo mide la calidad de la agrupaci√≥n en funci√≥n de la cohesi√≥n interna y la separaci√≥n entre cl√∫steres. En la gr√°fica correspondiente, el valor m√°s alto del coeficiente de Silhouette se encuentra en ùëò = 2 k=2, lo que indica que, con este n√∫mero de cl√∫steres, los grupos est√°n bien diferenciados y los puntos dentro de cada cl√∫ster son m√°s homog√©neos.

Bas√°ndonos en la evaluaci√≥n de m√∫ltiples criterios de clustering mediante `NbClust`, el n√∫mero √≥ptimo de clusters en los datos es **2**, ya que recibi√≥ la mayor cantidad de votos. Esto sugiere que los datos tienen dos grupos bien diferenciados, lo que puede ser validado adicionalmente con m√©tricas como el √≠ndice de silueta o gr√°ficos de PCA

Dado que todos los m√©todos coinciden en que ùëò = 2 es el valor √≥ptimo, podemos concluir que dividir los datos en dos grupos proporciona una segmentaci√≥n adecuada, asegurando un equilibrio entre la reducci√≥n de la variabilidad interna y la claridad en la separaci√≥n entre cl√∫steres.

```{r}
df_cluster_academic <- applying_kmeans(data_for_cluster_academic, 2)
```

```{r}
print_clustering_results(df_cluster_academic, data_for_cluster_academic, academic_columns)
```

El Cl√∫ster 1 est√° compuesto por estudiantes que dedican m√°s horas al estudio en comparaci√≥n con los del Cl√∫ster 2. Sin embargo, la diferencia m√°s notable entre ambos grupos radica en la asistencia a clase, ya que los alumnos del Cl√∫ster 1 muestran un nivel de asistencia significativamente mayor. Este factor parece desempe√±ar un papel clave en su rendimiento acad√©mico, ya que la combinaci√≥n de una mayor dedicaci√≥n al estudio y una participaci√≥n m√°s activa en las clases les permite obtener resultados m√°s favorables en comparaci√≥n con los estudiantes del Cl√∫ster 2.

Por otro lado, los alumnos del Cl√∫ster 2 no solo estudian menos, sino que tambi√©n presentan un porcentaje de asistencia m√°s bajo, lo que podr√≠a afectar negativamente su comprensi√≥n de los contenidos y, en consecuencia, su desempe√±o acad√©mico. Estos hallazgos sugieren que tanto el tiempo de estudio como la asistencia a clase son factores determinantes en el √©xito acad√©mico de los estudiantes.

#### Support

```{r}
compare_k(data_for_cluster_support)
```

```{r}
optimal_clusters_support <- find_optimal_clusters(data_for_cluster_support)

```

La primera gr√°fica sigue el **m√©todo del codo**, el cual eval√∫a la suma de los cuadrados dentro de los clusters (WSS) en funci√≥n del n√∫mero de clusters. El punto √≥ptimo se encuentra donde la disminuci√≥n en WSS se vuelve menos pronunciada, formando un "codo" en la curva. En este caso, se observa un cambio notable en la pendiente alrededor de k=4 y k=8, lo que indica que estos valores podr√≠an ser opciones razonables para segmentar los datos de manera eficiente.

Por otro lado, la segunda gr√°fica utiliza el **m√©todo del Silhouette** para determinar el n√∫mero √≥ptimo de clusters. En este m√©todo, se elige el valor de k que maximiza el √≠ndice de silhouette, el cual mide qu√© tan bien separados est√°n los clusters y qu√© tan cohesivos son. En la gr√°fica, el valor m√°s alto de silhouette se alcanza en k=8, lo que sugiere que este n√∫mero de clusters permite una mejor separaci√≥n entre los grupos y minimiza la superposici√≥n entre ellos.

Bas√°ndonos en la evaluaci√≥n de m√∫ltiples criterios de clustering mediante `NbClust`, el n√∫mero √≥ptimo de clusters en los datos es **4**, ya que recibi√≥ la mayor cantidad de votos. Esto sugiere que los datos tienen cuatro grupos bien diferenciados, lo que puede ser validado adicionalmente con m√©tricas como el √≠ndice de silueta o gr√°ficos de PCA

En conclusi√≥n, aunque el m√©todo del codo sugiere que tanto k=4 como k=8 son buenas opciones, el m√©todo de Silhouette indica que k=8 ofrece la mejor separaci√≥n entre clusters. Sin embargo, al aplicar el m√©todo de m√∫ltiples criterios, k=4 obtuvo la mayor cantidad de votos, superando a las dem√°s opciones por 15 votos. Dado que tanto el m√©todo del codo como el de m√∫ltiples criterios coinciden en k=4, tomamos esta opci√≥n como la m√°s adecuada para el clustering.

```{r}
df_cluster_support <- applying_kmeans(data_for_cluster_support, 4)
```

```{r}
print_clustering_results(df_cluster_support, data_for_cluster_support, support_columns)
```

Tras analizar las distintas gr√°ficas obtenidas en el estudio, se han identificado **tres grupos de alumnos** que no presentan dificultades en el aprendizaje, correspondientes a los **cl√∫steres 1, 2 y 4**. Estos estudiantes no parecen experimentar problemas significativos en su rendimiento acad√©mico, lo que sugiere que sus h√°bitos y patrones de estudio pueden estar alineados con el √©xito educativo.

Al comparar estos resultados con la **gr√°fica de sesiones de tutor√≠a**, se observa que el **cl√∫ster 1** es el grupo que registra **m√°s horas de tutor√≠a**, lo que podr√≠a indicar un mayor inter√©s o compromiso con el refuerzo acad√©mico. Por otro lado, los cl√∫steres **2 y 4** presentan una cantidad similar de sesiones de tutor√≠a, lo que sugiere que no requieren un apoyo adicional significativo. Sin embargo, el caso m√°s preocupante se encuentra en el **cl√∫ster 3**, ya que **este grupo s√≠ presenta problemas de aprendizaje, pero no asiste a tutor√≠as**. Esta falta de apoyo podr√≠a estar contribuyendo a sus dificultades acad√©micas, lo que sugiere la necesidad de intervenciones espec√≠ficas para mejorar su desempe√±o.

En cuanto al **acceso a recursos educativos**, la √∫ltima gr√°fica revela que el **cl√∫ster 4 es el que m√°s acceso tiene**, ocupando el rango m√°s alto en su totalidad. Esto sugiere que estos alumnos disponen de herramientas adecuadas para su aprendizaje, lo que puede estar relacionado con su buen rendimiento. Los **cl√∫steres 1 y 3** comparten un rango medio de acceso a recursos, aunque con variaciones entre casos de acceso bajo y alto, lo que indica cierta desigualdad en la disponibilidad de materiales. Finalmente, el **cl√∫ster 2 presenta el nivel m√°s bajo de acceso a recursos**, lo que podr√≠a representar una barrera para su desarrollo acad√©mico a largo plazo.

El an√°lisis de los datos ha permitido identificar patrones significativos en el aprendizaje de los alumnos y su relaci√≥n con las tutor√≠as y el acceso a recursos. Se destaca que el **cl√∫ster 3 requiere especial atenci√≥n**, ya que, a pesar de sus dificultades, **no participa en tutor√≠as**, lo que podr√≠a agravar sus problemas. Adem√°s, el acceso desigual a recursos educativos podr√≠a estar influyendo en el rendimiento de algunos grupos. Estos hallazgos sugieren la importancia de fomentar el uso de tutor√≠as en estudiantes con dificultades y garantizar un acceso equitativo a los recursos educativos para mejorar la calidad del aprendizaje.

#### Resources

```{r}
compare_k(data_for_cluster_resource)
```

```{r}
optimal_clusters_resources <- find_optimal_clusters(data_for_cluster_resource)
```

En la primera imagen, correspondiente al **m√©todo de Elbow**, se representa la suma de los cuadrados dentro del cluster (*Total Within Sum of Squares, WSS*) en funci√≥n del n√∫mero de clusters (*k*). Este m√©todo se basa en encontrar el punto donde la disminuci√≥n de WSS empieza a desacelerarse de manera significativa, formando una especie de ‚Äúcodo‚Äù en la gr√°fica. En este caso, observamos que la curva muestra una reducci√≥n brusca hasta aproximadamente *k = 8*, despu√©s de lo cual la disminuci√≥n de WSS se vuelve menos pronunciada. Esto sugiere que *k = 8* es un buen candidato para el n√∫mero √≥ptimo de clusters, ya que m√°s all√° de este punto la ganancia en t√©rminos de reducci√≥n de varianza dentro de los clusters es menor.

Por otro lado, en la segunda imagen se muestra el resultado del **m√©todo de Silhouette**, el cual mide la calidad de la agrupaci√≥n en funci√≥n de la cohesi√≥n interna y la separaci√≥n entre los clusters. El objetivo es encontrar el valor de *k* que maximiza el ancho promedio del coeficiente de silueta, lo que indica que los puntos est√°n bien agrupados dentro de sus respectivos clusters y bien separados de otros clusters. En esta gr√°fica, el valor m√°s alto del coeficiente de silueta se observa en *k = 2*, lo que sugiere que dos clusters proporcionan la mejor separaci√≥n seg√∫n este criterio. Sin embargo, tambi√©n se observa un valor elevado en *k = 8*, lo que indica que esta cantidad de clusters tambi√©n es una opci√≥n viable.

Bas√°ndonos en la evaluaci√≥n de m√∫ltiples criterios de clustering mediante `NbClust`, el n√∫mero √≥ptimo de clusters en los datos es **4**, ya que recibi√≥ la mayor cantidad de votos. Esto sugiere que los datos tienen cuatro grupos bien diferenciados, lo que puede ser validado adicionalmente con m√©tricas como el √≠ndice de silueta o gr√°ficos de PCA

El an√°lisis de los diferentes m√©todos de clustering muestra resultados variados sobre la cantidad √≥ptima de clusters. El m√©todo de **Elbow** sugiere que **k = 8** es una buena opci√≥n, ya que a partir de este punto la reducci√≥n de la varianza dentro de los clusters se desacelera significativamente. Por otro lado, el **m√©todo de Silhouette** indica que **k = 2** proporciona la mejor separaci√≥n entre clusters, aunque tambi√©n destaca **k = 8** como una alternativa viable. Sin embargo, el m√©todo de m√∫ltiples criterios de **NbClust** se√±ala que **k = 4** es la mejor opci√≥n al haber recibido la mayor cantidad de votos, lo que sugiere la existencia de cuatro grupos bien diferenciados en los datos. Dado que NbClust integra varios enfoques de validaci√≥n, se considera **k = 4** como el n√∫mero √≥ptimo de clusters, aunque los valores **k = 2 y k = 8** tambi√©n pueden ser opciones a considerar dependiendo del criterio de segmentaci√≥n que se priorice.

```{r}
df_cluster_resource <- applying_kmeans(data_for_cluster_resource, 4)
```

```{r}
print_clustering_results(df_cluster_resource, data_for_cluster_resource, resource_columns)
```

El an√°lisis de la primera gr√°fica, correspondiente a los **ingresos familiares**, revela diversas diferencias entre los cl√∫steres analizados. En t√©rminos generales, la mayor√≠a de los grupos presentan ingresos de nivel medio, aunque existen algunas desviaciones significativas que reflejan desigualdades econ√≥micas dentro del conjunto de datos. En particular, los **cl√∫steres 2 y 3** se sit√∫an dentro del rango de ingresos medios, pero con ciertas diferencias notables. El **cl√∫ster 2** muestra una mayor presencia de usuarios con ingresos **medios-bajos**, mientras que el **cl√∫ster 3** se inclina levemente hacia los **ingresos medios-altos**, aunque sin una diferencia muy pronunciada. En el caso del **cl√∫ster 1**, se observa una tendencia hacia ingresos **medios en su mayor√≠a al alza**, sin presencia destacada de ingresos bajos. Sin embargo, el grupo con la situaci√≥n econ√≥mica m√°s delicada es el **cl√∫ster 4**, que se distingue por presentar **ingresos √≠ntegramente bajos** en comparaci√≥n con los dem√°s grupos.

Al relacionar estos hallazgos con la segunda gr√°fica, correspondiente al **acceso a recursos**, se observa que la mayor√≠a de los cl√∫steres tienen valores medios similares en cuanto a disponibilidad de recursos educativos. No obstante, existen algunas fluctuaciones, con ciertos casos que se inclinan hacia un acceso m√°s limitado o, en otros, con mayores facilidades. Un hallazgo relevante es que, a pesar de que el **cl√∫ster 4** presenta los ingresos m√°s bajos, su acceso a recursos no es significativamente menor, lo que sugiere la existencia de **programas de ayuda o becas** que compensan la falta de recursos econ√≥micos. Esto indica que, aunque las familias de este grupo tengan menos ingresos, han podido acceder a apoyos que mitigan las desigualdades.

En lo que respecta al **acceso a internet**, se evidencia que el **cl√∫ster 2** es el √∫nico grupo que presenta un valor negativo, es decir, una menor accesibilidad a la conectividad en comparaci√≥n con el resto. Este dato plantea dos hip√≥tesis posibles: una primera explicaci√≥n ser√≠a que estas familias **no pueden permitirse el acceso a internet** debido a razones econ√≥micas; sin embargo, esta teor√≠a resulta inconsistente si consideramos que el **cl√∫ster 4**, que cuenta con los ingresos m√°s bajos, s√≠ tiene acceso a internet. Por lo tanto, una hip√≥tesis m√°s plausible es que en el **cl√∫ster 2 las familias han restringido el uso de internet a sus hijos por decisi√≥n propia**, probablemente por razones educativas, de control parental o de valores familiares.

En cuanto al **nivel acad√©mico de los padres**, se observa que, en t√©rminos generales, la mayor√≠a de los grupos presentan un nivel de educaci√≥n secundaria. No obstante, existen diferencias entre los cl√∫steres. El **cl√∫ster 1** se caracteriza por estar compuesto en su totalidad por padres con educaci√≥n **secundaria**. El **cl√∫ster 2** tambi√©n presenta una mayor√≠a con educaci√≥n secundaria, aunque con la particularidad de que algunos padres han alcanzado estudios **universitarios y de posgrado**. Por otro lado, el **cl√∫ster 4** cuenta principalmente con familias con formaci√≥n en **educaci√≥n secundaria y grados universitarios**, aunque sin un predominio de estudios avanzados. La situaci√≥n m√°s particular se encuentra en el **cl√∫ster 3**, donde los padres presentan un nivel de estudios **m√≠nimo de grado universitario**, y en algunos casos, **estudios de posgrado**, lo que indica un nivel acad√©mico superior en comparaci√≥n con el resto de los grupos.

El an√°lisis realizado revela importantes diferencias socioecon√≥micas entre los cl√∫steres analizados. Se ha identificado que el **cl√∫ster 4** es el grupo con menores ingresos, pero gracias a alg√∫n tipo de apoyo externo, ha podido mantener un acceso a recursos educativos similar al de los otros grupos. En cuanto a la **conectividad a internet**, el **cl√∫ster 2** es el √∫nico que presenta restricciones, lo que sugiere que la limitaci√≥n se debe m√°s a una decisi√≥n parental que a factores econ√≥micos. Respecto al **nivel educativo de los padres**, se observa que la mayor√≠a han alcanzado la educaci√≥n secundaria, aunque el **cl√∫ster 3 destaca por contar con padres con estudios universitarios y de posgrado en mayor proporci√≥n**. Estas diferencias pueden influir en el rendimiento acad√©mico y el acceso a oportunidades de aprendizaje, lo que subraya la importancia de analizar estos factores para dise√±ar estrategias de apoyo adecuadas para cada grupo.

#### Social

```{r}
compare_k(data_for_cluster_extra)
```

```{r}
optimal_clusters_extra <- find_optimal_clusters(data_for_cluster_extra)
```

En el gr√°fico del **m√©todo del codo**, se observa que la "Suma de Cuadrados Dentro del Grupo" (**WSS**) disminuye considerablemente hasta aproximadamente k=3, k=4, momento en el cual la pendiente comienza a estabilizarse. Esto indica que a partir de estos valores, agregar m√°s clusters genera una menor ganancia en la reducci√≥n de la variabilidad dentro de los grupos, sugiriendo que k=3 o k=4 son opciones razonables.

Por otro lado, el **m√©todo del silhouette** muestra que la mejor cohesi√≥n interna y separaci√≥n entre los clusters se obtiene con k=2, lo que sugiere que dividir los datos en dos grupos maximiza la calidad de la segmentaci√≥n.

Adicionalmente, el **an√°lisis de m√∫ltiples criterios** tambi√©n ha indicado que el n√∫mero √≥ptimo de clusters es k=2, ya que ha recibido la mayor cantidad de votos (**8 votos**), superando a k=3 y k=4, que han obtenido **5 votos** cada uno.

Los tres enfoques utilizados coinciden en que k=2 es la opci√≥n m√°s s√≥lida para la segmentaci√≥n de los datos. Tanto el m√©todo del silhouette como el an√°lisis de m√∫ltiples criterios refuerzan esta elecci√≥n, indicando que dividir los datos en dos grupos proporciona la mejor cohesi√≥n y separaci√≥n entre clusters. Aunque el m√©todo del codo suger√≠a que k=3 o k=4 podr√≠an ser alternativas razonables, la evidencia general respalda la elecci√≥n de k=2 como el n√∫mero √≥ptimo de clusters en este caso.

```{r}
df_cluster_extra <- applying_kmeans(data_for_cluster_extra, 2)

```

```{r}
print_clustering_results(df_cluster_extra, data_for_cluster_extra, extra_columns)
```

El an√°lisis de los gr√°ficos permite identificar distintos patrones en la relaci√≥n entre la participaci√≥n en **actividades extracurriculares**, la cantidad de **horas dedicadas a la actividad f√≠sica** y la **influencia de los compa√±eros** en los alumnos. A trav√©s de la observaci√≥n de estos datos, se pueden extraer conclusiones relevantes sobre c√≥mo estas variables se relacionan entre s√≠ y si tienen alg√∫n impacto en la vida social y acad√©mica de los estudiantes.

En el primer gr√°fico, correspondiente a la **realizaci√≥n de actividades extracurriculares**, se observa una diferencia clara entre los dos cl√∫steres analizados. El **cl√∫ster 1** agrupa a aquellos alumnos que **no participan en actividades extraescolares**, mientras que el **cl√∫ster 2** representa a los estudiantes que s√≠ realizan este tipo de actividades. Esta segmentaci√≥n permite identificar una distinci√≥n clara en los h√°bitos de los alumnos con respecto a su tiempo fuera del entorno acad√©mico, lo que podr√≠a tener implicaciones en otros aspectos de su desarrollo personal y social.

En lo que respecta al **rango de horas dedicadas a la actividad f√≠sica**, se observa que ambos cl√∫steres presentan una distribuci√≥n similar. Esto indica que la participaci√≥n o no en actividades extracurriculares no tiene un impacto significativo en el tiempo que los estudiantes dedican a la pr√°ctica de ejercicio f√≠sico. Es decir, tanto los alumnos que realizan actividades extraescolares como los que no lo hacen mantienen h√°bitos de actividad f√≠sica similares, lo que sugiere que otros factores, como la rutina diaria o el estilo de vida familiar, podr√≠an ser m√°s determinantes en este aspecto.

Por √∫ltimo, el an√°lisis de la **influencia de los compa√±eros** muestra que ambos cl√∫steres presentan una distribuci√≥n equivalente en esta variable. Esto implica que la **realizaci√≥n de actividades extracurriculares no tiene un impacto significativo en el nivel de influencia que los compa√±eros ejercen sobre los estudiantes**. En otras palabras, la socializaci√≥n y las din√°micas de grupo parecen mantenerse estables independientemente de si el alumno participa o no en actividades extracurriculares.

El an√°lisis realizado revela que la participaci√≥n en **actividades extracurriculares** es una caracter√≠stica diferenciadora entre los cl√∫steres, pero no parece influir en otras variables como la **cantidad de horas dedicadas a la actividad f√≠sica** ni en el **nivel de influencia de los compa√±eros**. La similitud en la distribuci√≥n de estas √∫ltimas variables sugiere que la actividad extracurricular no es un factor determinante en los h√°bitos de ejercicio ni en la socializaci√≥n de los alumnos. Por lo tanto, la decisi√≥n de realizar o no actividades extracurriculares podr√≠a estar m√°s relacionada con factores personales o familiares que con un impacto significativo en la vida social o los h√°bitos de los estudiantes.

#### General

```{r}
compare_k(data_for_cluster_general)
```

```{r}
optimal_clusters_general <- find_optimal_clusters(data_for_cluster_general)
```

```{r}
df_cluster_extra <- applying_kmeans(data_for_cluster_extra, 2)
```

```{r}
print_clustering_results(df_cluster_extra, data_for_cluster_extra, extra_columns)
```

### ¬øCu√°ntas horas de trabajo personal necesita un estudiante para obtener una alta calificaci√≥n?

-   **Objetivo**: Determinar la cantidad √≥ptima de horas semanales de trabajo personal necesarias para que un estudiante alcance una alta calificaci√≥n.

El primer paso es definir un criterio para clasificar una calificaci√≥n como "alta". Para ello, establecemos un umbral basado en un **Notable Alto**, lo que equivale aproximadamente a una calificaci√≥n media de **8 o superior**.

A continuaci√≥n, debemos identificar a aquellos estudiantes que cumplan con dicho requisito para centrar el an√°lisis en este grupo espec√≠fico. Para ello, filtramos el conjunto de datos y seleccionamos √∫nicamente las instancias en las que la variable **Previous_Scores** sea superior a **80** (considerando que las calificaciones en el dataset est√°n expresadas en una escala de 0 a 100).

Este filtrado nos permitir√° focalizarnos en los estudiantes con alto rendimiento y analizar los factores que podr√≠an haber influido en su desempe√±o acad√©mico.

Para ello, filtramos las observaciones donde la variable `Previous_Scores` tenga un valor superior a 80.

Adem√°s, al centrarnos la variables `Previous_Scores` eliminaremos del conjunto de datos la variable `Exam_Score`.

```{r}
data_notas_altas <- df_cleaned[df_cleaned$Previous_Scores >= 80,]
data_notas_altas <- subset(data_notas_altas, select = -Exam_Score)
data_notas_altas
```

Podemos observar en el siguiente gr√°fico de tarta la distribuci√≥n de "altas calificaciones" respecto a la variable `Previous_Scores`.

```{r}
data$calificacion_categoria <- ifelse(data$Previous_Scores > 80, "Alta calificaci√≥n", "Resto de calificaciones")


categoria_counts <- as.data.frame(table(data$calificacion_categoria))
categoria_counts$percentage <- round(100 * categoria_counts$Freq / sum(categoria_counts$Freq), 1)

ggplot(categoria_counts, aes(x = "", y = Freq, fill = Var1)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Distribuci√≥n de Calificaciones en Previous Exams", 
       x = NULL, y = NULL) +
  theme_minimal() +
  theme(axis.text = element_blank(), 
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  geom_text(aes(label = paste(percentage, "%")), position = position_stack(vjust = 0.5))

```

Para nuestro estudio debemos crear una nueva m√©trica que refleje de forma general las **horas semanales de trabajo del estudiante**. Para ello, vamos a combinar varias de las variables disponibles para obtener una estimaci√≥n m√°s completa de las horas de dedicaci√≥n del estudiante. Algunas de las variables que podr√≠an influir directamente en las horas de trabajo semanales incluyen:

-   `Hours_Studied`: El n√∫mero de horas que el estudiante estudia.
-   `Tutoring_Sessions`: El n√∫mero de sesiones de tutor√≠a.

La f√≥rmula para las horas semanales de trabajo es

\$Horas_Semanales_Work = Hours_Studied + Tutoring_Sessions \$.

Donde:

-   `Hours_Studied`: N√∫mero de horas estudiadas.

-   `Tutoring_Sessions`: N√∫mero de sesiones de tutor√≠a ( 1 hora por sesi√≥n).

```{r}
if ("Hours_Studied" %in% names(data_notas_altas) & 
    "Tutoring_Sessions" %in% names(data_notas_altas) & 
    "Physical_Activity" %in% names(data_notas_altas)){
  
  data_notas_altas$Horas_Semanales_Work <- data_notas_altas$Hours_Studied +               data_notas_altas$Tutoring_Sessions

  data_notas_altas <- data_notas_altas[, !(names(data_notas_altas) %in% c("Hours_Studied", "Tutoring_Sessions", "Physical_Activity"))]
} else {
  print("Las columnas necesarias ya han sido eliminadas.")
}
  
summary(data_notas_altas$Horas_Semanales_Work)
```

```{r}
data_numeric <- data_notas_altas[, sapply(data_notas_altas, is.numeric)]
data_scaled <- as.data.frame(scale(data_numeric))
data_notas_altas[, sapply(data_notas_altas, is.numeric)] <- data_scaled
data_notas_altas
```

Una vez identificados los estudiantes con altas calificaciones, el siguiente paso es identificar cuales son aquellos factores que influyen m√°s en las altas calificaciones del alumno. Para ello, generamos una **matriz de correlaci√≥n** junto con un **mapa de calor**, lo que nos permitir√° visualizar de manera clara c√≥mo se relacionan las variables num√©ricas dentro del conjunto de datos.

Con este an√°lisis podremos detectar si existe una asociaci√≥n significativa entre las horas de estudio personal y las calificaciones obtenidas. Adem√°s, nos permitir√° observar la influencia de otros factores, como las horas de sue√±o, la asistencia a tutor√≠as o la participaci√≥n en actividades extracurriculares, en el rendimiento acad√©mico de los estudiantes con mejores notas.

```{r}
matriz_correlacion <- cor(data_notas_altas)
matriz_melt <- melt(matriz_correlacion)

ggplot(data = matriz_melt, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name = "Correlaci√≥n") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "Variables", y = "Variables", title = "Mapa de Calor de Correlaci√≥n")
```

El resultado de la matriz de correlaci√≥n nos arroja que no existe gran correlaci√≥n entre variables.

```{r}
model1 = lm(Horas_Semanales_Work ~ ., data = data_notas_altas)
summary(model1)
```

```{r}
data_notas_alta_simplificado <- data_notas_altas %>% dplyr::select(-School_Type_Public, -Gender_Female)
data_notas_alta_simplificado
```

```{r}
vif_values <- vif(lm(Horas_Semanales_Work ~ ., data = data_notas_alta_simplificado))
print(vif_values)
```

```{r}
indices <- sample(1:nrow(data_notas_alta_simplificado), size = 0.7 * nrow(data_notas_alta_simplificado))
train_data <- data_notas_alta_simplificado[indices, ]
test_data <- data_notas_alta_simplificado[-indices, ]
```

```{r}
#library(MASS)
#model_reduced <- stepAIC(lm(Horas_Semanales_Work ~ .^2, data = train_data), direction = "both")
#summary(model_reduced)
```

```{r}
predicciones <- predict(model_reduced, newdata = test_data)
```

```{r}
comparacion <- data.frame(Real = test_data$Horas_Semanales_Work, Predicha = predicciones)
comparacion
```

```{r}
residuos <- comparacion$Real - comparacion$Predicha
rmse <- sqrt(mean(residuos^2))
print(paste("RMSE: ", rmse))
```


### An√°lisis del Desempe√±o Acad√©mico y Factores que Influyen en la Mejora del Estudiante 

#### Introducci√≥n

¬øCu√°les son los factores clave que determinan si un estudiante mejorar√° su rendimiento acad√©mico?

El objetivo de este estudio es identificar los factores que influyen en la mejora del rendimiento acad√©mico de los estudiantes.
Para lograrlo, se han utilizado t√©cnicas de aprendizaje autom√°tico que permiten analizar grandes vol√∫menes de datos y extraer patrones que pueden ser utilizados para la toma de decisiones en el √°mbito educativo.

Dado que las variables del conjunto de datos no presentaban una correlaci√≥n lineal significativa entre s√≠, se descartaron m√©todos estad√≠sticos tradicionales y se opt√≥ por modelos basados en √°rboles de decisi√≥n, que permiten capturar relaciones complejas entre las variables y generar reglas interpretables.


#### Preparaci√≥n y Exploraci√≥n de Datos

Se parte de un conjunto de datos estructurado con m√∫ltiples variables relacionadas con el desempe√±o acad√©mico de los estudiantes, incluyendo horas de estudio, asistencia, nivel de motivaci√≥n, acceso a recursos, entre otros. Concretamente para responder a esta pregunta se usar√° el conjunto de datos ya preprocesado "df_cleaned".

Para entender mejor la distribuci√≥n de las calificaciones, se generaron histogramas de Exam_Score y Previous_Scores:

```{r}
# Distribuci√≥n de Exam_Score
ggplot(df_cleaned, aes(x = Exam_Score)) +
  geom_histogram(bins = 20, fill = "blue", alpha = 0.7) +
  labs(title = "Distribuci√≥n de Exam_Score", x = "Exam Score", y = "Frecuencia")

# Distribuci√≥n de Previous_Scores
ggplot(df_cleaned, aes(x = Previous_Scores)) +
  geom_histogram(bins = 20, fill = "red", alpha = 0.7) +
  labs(title = "Distribuci√≥n de Previous_Scores", x = "Previous Scores", y = "Frecuencia")

```
'Exam_Score' tiene poca variabilidad, con la mayor√≠a de los estudiantes en el rango de 60 a 75 puntos.
'Previous_Scores' tiene una distribuci√≥n m√°s uniforme, lo que sugiere que podr√≠a ser una mejor variable predictora.


Debido a la baja variabilidad en Exam_Score, decidimos intentar predecir High_Score en lugar de Exam_Score directamente.

El conjunto de datos no conten√≠a una variable expl√≠cita para clasificar el rendimiento de los estudiantes.
Para abordar este problema, se cre√≥ la variable High_Score, que clasifica a los estudiantes en alto rendimiento y bajo rendimiento con base en su calificaci√≥n final (Exam_Score).

```{r}
# Crear la variable High_Score (1 si el Exam_Score >= 80, 0 si es menor)
df_cleaned$High_Score <- ifelse(df_cleaned$Previous_Scores >= 80, 1, 0)

# Ver distribuci√≥n
table(df_cleaned$High_Score)

```

Se seleccion√≥ un umbral de 80 puntos para definir un "alto rendimiento" porque permite diferenciar a los estudiantes con desempe√±o notable del resto.
Esta clasificaci√≥n se utilizar√° en los modelos para predecir qu√© factores influyen en que un estudiante alcance un alto rendimiento.


### Modelos Utilizados

Para identificar los factores que m√°s influyen en el rendimiento de los estudiantes, se probaron distintos modelos:

1. Regresi√≥n Log√≠stica
2. Random Forest
3. XGBoost
4. √Årbol de Decisi√≥n (Mejor Modelo)

##### 1. Regresi√≥n Log√≠stica
La regresi√≥n log√≠stica se utiliz√≥ inicialmente para predecir High_Score en funci√≥n de las dem√°s variables.

```{r}
# Entrenar modelo de Regresi√≥n Log√≠stica
model <- glm(High_Score ~ ., data = df_cleaned %>% select(-Exam_Score), family = binomial)

# Hacer predicciones
y_prob <- predict(model, newdata = df_cleaned, type = "response")
y_pred <- ifelse(y_prob >= 0.5, 1, 0)

# Evaluaci√≥n
accuracy <- mean(y_pred == df_cleaned$High_Score)
print(paste("Accuracy:", accuracy))

```
Precisi√≥n = 99.9%, lo cual es demasiado alto para ser realista.
Se detect√≥ sobreajuste, ya que Previous_Scores predec√≠a High_Score casi perfectamente.
Conclusi√≥n: No es un modelo √∫til para este an√°lisis

##### 2. Random Forest
Se prob√≥ Random Forest para capturar relaciones no lineales entre variables.

```{r}
# Cargar librer√≠as necesarias
library(randomForest)
library(caret)

# Dividir datos en entrenamiento (70%) y prueba (30%)
set.seed(42)
trainIndex <- createDataPartition(df_cleaned$High_Score, p = 0.7, list = FALSE)
trainData <- df_cleaned[trainIndex, ]
testData  <- df_cleaned[-trainIndex, ]

# Entrenar el modelo Random Forest (corrigiendo par√°metros)
rf_model <- randomForest(factor(High_Score) ~ ., 
                         data = trainData %>% select(-Exam_Score), 
                         ntree = 200,  # Reducimos el n√∫mero de √°rboles
                         mtry = floor(sqrt(ncol(trainData) - 1)),  # Ajustamos n√∫mero de variables por √°rbol
                         importance = TRUE)

# Hacer predicciones en el conjunto de prueba
rf_pred <- predict(rf_model, newdata = testData, type = "class")

# Evaluar precisi√≥n del modelo
rf_accuracy <- mean(rf_pred == testData$High_Score)
print(paste("Random Forest Accuracy:", rf_accuracy))

# Matriz de confusi√≥n
rf_conf_matrix <- table(Predicted = rf_pred, Actual = testData$High_Score)
print("Random Forest Confusion Matrix:")
print(rf_conf_matrix)

# Importancia de las variables
importance_df <- as.data.frame(importance(rf_model))
importance_df$Variable <- rownames(importance_df)
importance_df <- importance_df[order(-importance_df$MeanDecreaseGini), ]

# Visualizar importancia de variables
print("Variable Importance in Random Forest:")
print(importance_df)

# Visualizaci√≥n gr√°fica de importancia de variables
library(ggplot2)
ggplot(importance_df, aes(x = reorder(Variable, -MeanDecreaseGini), y = MeanDecreaseGini)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Importancia de Variables en Random Forest", x = "Variables", y = "Importancia Gini")



```
#### 3. XGBoost

```{r}
# Cargar librer√≠a
library(xgboost)

# Preparar datos en formato de matriz para XGBoost
train_matrix <- model.matrix(High_Score ~ . -1, data = trainData %>% select(-Exam_Score))
test_matrix  <- model.matrix(High_Score ~ . -1, data = testData %>% select(-Exam_Score))

# Convertir a formato DMatrix de XGBoost
dtrain <- xgb.DMatrix(data = train_matrix, label = trainData$High_Score)
dtest  <- xgb.DMatrix(data = test_matrix, label = testData$High_Score)

# Definir hiperpar√°metros del modelo
params <- list(
  objective = "binary:logistic",  # Clasificaci√≥n binaria
  eval_metric = "error",  # Evaluar por tasa de error
  eta = 0.1,  # Tasa de aprendizaje
  max_depth = 6,  # Profundidad m√°xima del √°rbol
  subsample = 0.8,  # Porcentaje de muestras usadas en cada iteraci√≥n
  colsample_bytree = 0.8  # Proporci√≥n de variables usadas en cada √°rbol
)

# Entrenar el modelo XGBoost
set.seed(42)
xgb_model <- xgb.train(params, dtrain, nrounds = 100, watchlist = list(train = dtrain, test = dtest), verbose = 0)

# Hacer predicciones
xgb_pred_prob <- predict(xgb_model, dtest)
xgb_pred <- ifelse(xgb_pred_prob > 0.5, 1, 0)

# Evaluar precisi√≥n del modelo
xgb_accuracy <- mean(xgb_pred == testData$High_Score)
print(paste("XGBoost Accuracy:", xgb_accuracy))

# Matriz de confusi√≥n
xgb_conf_matrix <- table(Predicted = xgb_pred, Actual = testData$High_Score)
print("XGBoost Confusion Matrix:")
print(xgb_conf_matrix)

# Importancia de variables en XGBoost
importance_matrix <- xgb.importance(model = xgb_model)
print("Feature Importance in XGBoost:")
print(importance_matrix)

```



#### 4. √Årbol de Decisi√≥n




```{r}
# Cargar librer√≠as necesarias
library(rpart)
library(rpart.plot)
library(ggplot2)

# Dividir datos en entrenamiento y prueba
set.seed(42)
trainIndex <- createDataPartition(df_cleaned$Improved, p = 0.7, list = FALSE)
trainData <- df_cleaned[trainIndex, ]
testData  <- df_cleaned[-trainIndex, ]

# Entrenar el √Årbol de Decisi√≥n Optimizado
tree_model <- rpart(Improved ~ ., 
                    data = trainData %>% select(-Exam_Score, -Previous_Scores, -Score_Improvement), 
                    method = "class", 
                    control = rpart.control(cp = 0.005, minsplit = 10, maxdepth = 7))

# Mejora de la visualizaci√≥n con rpart.plot()
rpart.plot(tree_model, 
           type = 2,  # √Årbol detallado con nodos rectangulares
           extra = 104,  # Mostrar porcentaje de datos en cada nodo
           box.palette = "BuGn",  # Paleta de colores para los nodos
           tweak = 1.2,  # Ajuste del tama√±o del √°rbol
           main = "√Årbol de Decisi√≥n Mejorado")

# Guardar imagen en alta resoluci√≥n
png("Decision_Tree_Optimized.png", width = 1200, height = 800)
rpart.plot(tree_model, type = 2, extra = 104, box.palette = "BuGn", tweak = 1.2, main = "√Årbol de Decisi√≥n Mejorado")
dev.off()

# Hacer predicciones con el modelo optimizado
tree_pred <- predict(tree_model, newdata = testData, type = "class")

# Evaluar el modelo optimizado
tree_accuracy <- mean(tree_pred == testData$Improved)
tree_conf_matrix <- table(Predicted = tree_pred, Actual = testData$Improved)

# Mostrar resultados
print(paste("Optimized Decision Tree Accuracy:", tree_accuracy))
print("Optimized Decision Tree Confusion Matrix:")
print(tree_conf_matrix)

```

* Si un estudiante ya tiene una calificaci√≥n alta (High_Score = 1), no se espera una mejora significativa. Es decir, los estudiantes con alto rendimiento tienen menos margen de mejora.

* La asistencia a clases es un factor fundamental para mejorar el rendimiento acad√©mico. Si la asistencia (Attendance) es menor a 84%, la probabilidad de mejora es baja (35% de mejora).
Si la asistencia es mayor o igual a 84%, se consideran otros factores adicionales que pueden influir en la mejora.

* Si Attendance >= 84%, la distancia al colegio (Distance_from_Home) afecta la mejora:

    * Si un estudiante vive a m√°s de 3 km, la probabilidad de mejora es 33%.
    * Si un estudiante vive a menos de 3 km, se eval√∫an otros factores como las horas de estudio.
En conclusi√≥n, los estudiantes que viven m√°s lejos tienen menos probabilidad de mejorar, posiblemente debido a tiempos de traslado prolongados y fatiga.
Si un estudiante estudia menos de 20 horas semanales, la tutor√≠a (Tutoring_Sessions) se convierte en un factor relevante:

* Si Tutoring_Sessions < 0.38, la probabilidad de mejorar es 41%.
Si Tutoring_Sessions >= 0.38, la probabilidad de mejora aumenta a 54%.

*Si un estudiante estudia m√°s de 20 horas semanales, la probabilidad de mejorar es 57%. Sin embargo, en este caso, el nivel de involucramiento parental (Parental_Involvement) comienza a ser un factor clave:

* Si Parental_Involvement < 3, la asistencia del estudiante se vuelve un elemento determinante:
    * Si Attendance < 97%, la probabilidad de mejora es 13%.
    * Si Attendance >= 97%, la probabilidad de mejora aumenta a 33%.
* Si Parental_Involvement >= 3, la probabilidad de mejora es 67%.
En conclusi√≥n, estudiar m√°s de 20 horas a la semana aumenta significativamente la probabilidad de mejora. Para los estudiantes con menos horas de estudio, recibir tutor√≠as ayuda a mejorar su rendimiento. Adem√°s, un alto nivel de involucramiento parental y una asistencia superior al 97% pueden compensar la falta de apoyo familiar.




```{r}
# Cargar librer√≠as necesarias
library(ggplot2)
library(gganimate)
library(gifski)
library(rpart)
library(dplyr)

# Dividir datos en entrenamiento y prueba
set.seed(42)
trainIndex <- createDataPartition(df_cleaned$Improved, p = 0.7, list = FALSE)
trainData <- df_cleaned[trainIndex, ]
testData  <- df_cleaned[-trainIndex, ]

# Entrenar el √Årbol de Decisi√≥n
tree_model <- rpart(Improved ~ Attendance + Hours_Studied + Tutoring_Sessions, 
                    data = trainData, 
                    method = "class", 
                    control = rpart.control(cp = 0.005, minsplit = 10, maxdepth = 4))

# Definir los pasos del √°rbol con etiquetas mejoradas
testData <- testData %>%
  mutate(
    step = case_when(
      Attendance < 84 ~ "Paso 1: Asistencia < 84% (Rojo)", 
      Hours_Studied < 20 ~ "Paso 2: Horas de Estudio < 20 (Azul)", 
      Tutoring_Sessions < 0.38 ~ "Paso 3: Tutor√≠as < 0.38 (Verde)", 
      TRUE ~ "Paso 4: Segmentaci√≥n Final (Morado)"
    ),
    classification = as.factor(Improved) # Guardamos la clasificaci√≥n
  )

# Asignar colores a las fases del √°rbol
color_mapping <- c("Paso 1: Asistencia < 84% (Rojo)" = "red", 
                   "Paso 2: Horas de Estudio < 20 (Azul)" = "blue", 
                   "Paso 3: Tutor√≠as < 0.38 (Verde)" = "green",
                   "Paso 4: Segmentaci√≥n Final (Morado)" = "purple")

# Asignar colores espec√≠ficos a la clasificaci√≥n
classification_colors <- c("0" = "black", "1" = "yellow") # Mayor contraste

# Crear una tabla con las reglas del √°rbol
tree_rules <- data.frame(
  step = c(1, 2, 3, 4), 
  rule = c(
    "Inicio: Todos los datos",
    "Divisi√≥n: Asistencia < 84%",
    "Divisi√≥n: Horas de Estudio < 20",
    "Divisi√≥n: Tutor√≠as < 0.38"
  )
)

# Crear la animaci√≥n con colores mejorados y movimiento m√°s fluido
animated_plot <- ggplot(testData, aes(x = Attendance, y = Hours_Studied, 
                                      color = classification)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_vline(xintercept = 84, linetype = "dashed", color = "red", size = 1) +  # Regla de asistencia
  geom_hline(yintercept = 20, linetype = "dashed", color = "blue", size = 1) + # Regla de horas de estudio
  labs(title = "Proceso de Decisi√≥n en el √Årbol de Decisi√≥n", 
       subtitle = "{tree_rules$rule[as.integer(frame_time)]}", 
       x = "Asistencia (%)", 
       y = "Horas de Estudio por Semana") +
  scale_color_manual(values = classification_colors, name = "Clasificaci√≥n Final") +  # Ahora los colores representan 0 o 1
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        plot.subtitle = element_text(size = 12)) +
  transition_states(as.integer(as.factor(step)), 
                    transition_length = 4, # Hace la transici√≥n m√°s larga y fluida
                    state_length = 2) + # Tiempo de pausa entre pasos reducido para continuidad
  ease_aes('linear')  # Movimiento m√°s continuo

# Guardar y mostrar animaci√≥n con duraci√≥n m√°s lenta y fluida
animate(animated_plot, duration = 12, fps = 8, renderer = gifski_renderer()) # 12s de duraci√≥n
anim_save("decision_tree_animation_smooth.gif")


```
```{r}
# Cargar librer√≠as necesarias
library(plotly)
library(rpart)
library(dplyr)

# Dividir datos en entrenamiento y prueba
set.seed(42)
trainIndex <- createDataPartition(df_cleaned$Improved, p = 0.7, list = FALSE)
trainData <- df_cleaned[trainIndex, ]
testData  <- df_cleaned[-trainIndex, ]

# Entrenar el √Årbol de Decisi√≥n
tree_model <- rpart(Improved ~ Attendance + Hours_Studied + Tutoring_Sessions, 
                    data = trainData, 
                    method = "class", 
                    control = rpart.control(cp = 0.005, minsplit = 10, maxdepth = 4))

# Definir los pasos del √°rbol
testData <- testData %>%
  mutate(
    step = case_when(
      Attendance < 84 ~ "Paso 1: Asistencia < 84%",
      Hours_Studied < 20 ~ "Paso 2: Horas de Estudio < 20",
      Tutoring_Sessions < 0.38 ~ "Paso 3: Tutor√≠as < 0.38",
      TRUE ~ "Paso 4: Segmentaci√≥n Final"
    )
  )

# Crear la visualizaci√≥n interactiva
interactive_plot <- plot_ly(testData, x = ~Attendance, y = ~Hours_Studied, color = ~step, 
                            colors = c("red", "blue", "green", "purple"),
                            type = 'scatter', mode = 'markers',
                            text = ~paste("Tutor√≠as:", Tutoring_Sessions, "<br>Mejora:", Improved)) %>%
  layout(title = "Evoluci√≥n de las Decisiones en el √Årbol de Decisi√≥n",
         xaxis = list(title = "Asistencia (%)"),
         yaxis = list(title = "Horas de Estudio por Semana"),
         legend = list(title = list(text = "Etapa de Segmentaci√≥n")))

# Mostrar el gr√°fico interactivo
interactive_plot

```

