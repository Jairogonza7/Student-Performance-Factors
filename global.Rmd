---
title: "Students Performance Factors"
author: 
  - "Jairo González Hernández"
  - "Mathis Goujon"
  - "Claudia Teresa Heredia Ceballos"
  - "Pedro López Ruz"
  - "José Antonio Medina García"
---

# Students Performance Factors

**Trabajo Final Data Science**

*Master en Ingeniería del Software: Cloud, Datos y Gestión de TI*

## Descripción del dominio

El rendimiento académico es un tema clave en la educación, ya que influye directamente en las oportunidades que tendrán los jovenes en el día de mañana y en el desarrollo de nuestra sociedad. Comprender qué factores afectan al desempeño de los estudiantes permitirá a las instituciones educativas a mejorar los métodos de enseñanza, diseñar políticas educativas más efectivas y proporcionar un mayor apoyo a aquellos estudiantes que lo necesiten.

### Enfoque del Trabajo

Este estudio analiza los factores que influyen en el rendimiento académico de los estudiantes. Para ello, se hace uso de datos relacionados con aspectos personales, sociales y académicos para identificar patrones y determinar qué variables tienen mayor impacto en el desempeño escolar.

En particular, el estudio se enfoca en responder dos preguntas fundamentales:

1.  **¿Se pueden agrupar a los estudiantes en una clase según sus características?**\

    La organización de los estudiantes dentro del aula puede influir significativamente en su aprendizaje y rendimiento. Por esta razón, se explorará la posibilidad de segmentar a los alumnos con base en características clave como sus calificaciones previas, el tiempo dedicado al estudio, su nivel de motivación, la presencia de discapacidades de aprendizaje y su participación en actividades extracurriculares.

    Este enfoque permitirá una distribución estratégica que potencie el aprendizaje al ubicar a los estudiantes en entornos que favorezcan su desarrollo académico y personal.

2.  **¿Cuántas horas de trabajo personal necesita un estudiante para obtener una alta calificación?**

    Otro objetivo del estudio es determinar cuántas horas diarias de estudio autónomo son necesarias para que un estudiante alcance una alta calificación. Para ello, se identificarán aquellos factores que tengan mayor influencia con la calificación del estudiante, ya que estos aspectos pueden influir en el rendimiento académico. A través de un modelo de regresión, se buscará cuantificar la relación entre estas variables y el desempeño estudiantil, proporcionando una guía para optimizar los hábitos de estudio.

    A través de este análisis, se pretende aportar información valiosa para mejorar las estrategias educativas, optimizar la distribución de los estudiantes en el aula y ofrecer recomendaciones que permitan a los alumnos maximizar su rendimiento académico.

### Interés y motivación del estudio

Vivimos en un mundo en constante transformación, donde los sistemas educativos deben evolucionar para responder a nuevos desafíos. En este contexto, **comprender los factores que influyen en el rendimiento académico es fundamental** para optimizar los procesos de enseñanza y garantizar un aprendizaje más inclusivo y eficaz. Este estudio busca **identificar patrones y relaciones** clave entre diversas variables que impactan la forma en que los estudiantes aprenden y se desarrollan, proporcionando información valiosa para la mejora de estrategias pedagógicas.

#### Impacto del Rendimiento Académico en la Sociedad y la Economía

El rendimiento académico es un tema de gran relevancia tanto a nivel local como global, ya que influye directamente en el desarrollo profesional y económico de una sociedad. Un bajo rendimiento estudiantil puede **repercutir en altas tasas de deserción escolar**, desempleo y desigualdad social, lo que genera impactos negativos en la economía y el bienestar de la población. En muchos países, los sistemas educativos han implementado programas de intervención basados en el análisis de datos para mejorar el desempeño estudiantil, reducir brechas de aprendizaje y fomentar la equidad educativa.

Desde una perspectiva económica, diversos estudios han demostrado que la inversión en educación tiene un **impacto directo en el crecimiento del PIB** y en la **movilidad social** de los individuos. Por ejemplo, la UNESCO destaca que **la desescolarización y las carencias educativas cuestan 10 billones de dólares al año a la economía mundial**, subrayando la importancia de invertir en educación para el crecimiento económico y la cohesión social. Además, la misma organización señala que una mejor educación contribuye directamente al crecimiento económico al mejorar la productividad laboral y aumentar los ingresos potenciales de las personas.

Tomemos como ejemplo España, donde los datos de la **Fundación BBVA** muestran que una mejora del rendimiento académico podría **contribuir de manera significativa al Producto Interno Bruto (PIB) nacional**. Según un estudio realizado por la fundación, si se redujera la tasa de abandono escolar temprano y se mejorara el rendimiento en matemáticas y lectura, el PIB podría aumentar en un **2,1% anual**.

Por otro lado, el rendimiento académico no depende únicamente de la capacidad intelectual del estudiante. Factores como el **apoyo familiar, los hábitos de estudio, la motivación personal y la presencia de dificultades de aprendizaje** desempeñan un papel crucial en su desempeño. Adoptar un enfoque basado en estos elementos permite \*\*diseñar estrategias educativas \*personalizadas\*\*, favoreciendo un aprendizaje adaptado a las necesidades individuales de cada estudiante.

#### Análisis de Estudios Previos sobre el Rendimiento Académico

Este estudio se basa en investigaciones previas que hemos encontrado donde se ha analizado el impacto de factores externos al estudiante en el rendimiento académico. Algunos de estos factores incluyen:

-   **Entorno Socioeconómico**: Un estudio realizado por *Redalyc (2005)* señala que, en sociedades más industrializadas, el rendimiento escolar se ve más afectado por el ambiente socioeconómico del alumno y otras variables no escolares (*Redondo, 2005*).

-   **Apoyo Familiar y Escolar**: La investigación de *Domínguez & Pérez (2021)* destaca la importancia de un ambiente de confianza en las instituciones educativas, donde los docentes fomenten la creatividad y el pensamiento crítico, factores que influyen positivamente en el aprendizaje de los estudiantes (*Domínguez & Pérez, 2021*).

-   **Salud y Bienestar**: Factores como una alimentación adecuada y un sueño reparador son fundamentales para el rendimiento escolar. Un informe de *Aventura Amazonia (2023)* subraya que estos elementos garantizan que las necesidades básicas del estudiante estén cubiertas, permitiendo una mejor capacidad de respuesta y aprendizaje (*Aventura Amazonia, 2023*).

Estos estudios nos han servido como punto de partida para nuestro análisis, permitiéndonos identificar los factores clave que influyen en el rendimiento académico. A partir de estas investigaciones, hemos diseñado un enfoque que combina diferentes variables externas y su impacto en el aprendizaje, con el objetivo de aportar nuevas perspectivas y profundizar en la relación entre estos elementos dentro de nuestro propio estudio.

#### Enfoque del equipo

Nuestro equipo de trabajo está compuesto por estudiantes de **Ingeniería Informática e Ingeniería de la Salud**, lo que nos permite abordar el estudio desde una perspectiva multidisciplinaria. Mientras que desde la informática podemos aplicar análisis de datos avanzados para extraer conclusiones relevantes, desde la salud entendemos la importancia del bienestar en el proceso de aprendizaje. Como estudiantes, también conocemos de primera mano la diversidad en las aulas y la necesidad de adaptar el entorno educativo para mejorar el rendimiento y la experiencia de aprendizaje de cada alumno.

### Referencias

-   Fundación BBVA. (2020). El impacto de la mejora del rendimiento académico en el crecimiento económico. Disponible en: <https://www.fbbva.org/es/publicaciones/el-impacto-de-la-mejora-del-rendimiento-academico-en-el-crecimiento-economico/>

-   Hanushek, E. A., & Woessmann, L. (2012). The Economic Benefits of Educational Reform. National Bureau of Economic Research. Disponible en: <https://www.nber.org/papers/w18247>

-   Organización de las Naciones Unidas para la Educación, la Ciencia y la Cultura (UNESCO). (2022). La desescolarización y las carencias educativas cuestan 10 billones de dólares al año a la economía mundial. Disponible en: <https://www.unesco.org/es/articles/la-desescolarizacion-y-las-carencias-educativas-cuestan-10-billones-de-dolares-al-ano-la-economia>

-   Organización de las Naciones Unidas para la Educación, la Ciencia y la Cultura (UNESCO). (2022). Lo que debemos saber sobre el precio de la inacción en el ámbito de la educación. Disponible en: <https://www.unesco.org/es/articles/lo-que-debemos-saber-sobre-el-precio-de-la-inaccion-en-el-ambito-de-la-educacion>

-   Redondo, J. (2005). Factores socioeconómicos que influyen en el rendimiento académico en sociedades industrializadas. Revista de Educación Comparada, 32(1), 45-67. Disponible en: <https://www.redalyc.org/pdf/270/27029103.pdf>

-   Domínguez, M., & Pérez, L. (2021). La importancia del entorno educativo en el rendimiento académico. Revista Dominio de las Ciencias, 7(4), 23-45. Disponible en: <https://www.dominiodelasciencias.com/ojs/index.php/es/article/view/2718/html>

-   Aventura Amazonia. (2023). Factores externos que afectan al rendimiento escolar. Disponible en: <https://aventura-amazonia.com/nos-gusta-el-cole/factores-externos-que-afectan-al-rendimiento-escolar>

## Librerías

La función ipak está diseñada para facilitar la instalación y carga de paquetes en R. Es útil cuando desea asegurarse de que todos los paquetes necesarios para un script o proyecto se instalan y cargan automáticamente. <https://gist.github.com/stevenworthington/3178163>

```{r}
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if(length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("tidyverse","ggplot2", "dplyr","grid", "gridExtra", "reshape2", "car", "ggridges", "factoextra", "cluster", "NbClust", "RColorBrewer","viridis", "reshape2", "xgboost","randomForest","caret","rpart","rpart","gganimate","gifski","rpart","plotly")


ipak(packages)
```

## Descripción del dataset

El dataset ha sido extraído de la plataforma *Kaggle* y proporcionado por el usuario *lainguyn123*. Se puede acceder al conjunto de datos a través del siguiente enlace: [Student Performance Factors Dataset](https://www.kaggle.com/datasets/lainguyn123/student-performance-factors/data).

El archivo que contiene el conjunto de datos se denomina **StudentPerformanceFactors** y está en formato **CSV**, con un tamaño aproximado de **641 kB**.

Este conjunto de datos proviene de una investigación que analiza los factores que afectan el rendimiento académico de los estudiantes. Incluye diversas variables relacionadas con características personales, académicas y sociales, tales como hábitos de estudio, asistencia, participación de los padres, y otros aspectos clave que influyen en el éxito académico de los estudiantes.

En cuanto a sus dimensiones, el dataset consta de un total de:

-   **6,607 Filas**

-   **20 Columnas**

## Exploración de datos

Antes de realizar cualquier análisis, es fundamental explorar el conjunto de datos para comprender la estructura de los mismos, identificar posibles inconsistencias y verificar la presencia de valores faltantes. En esta sección, realizamos una inspección inicial del dataset.

### Lectura de los datos

Cargamos el dataset desde el archivo CSV y verificamos su correcta importación:

```{r}
data <- read.csv("data/StudentPerformanceFactors.csv", header=TRUE)
```

A continuación, se presentan las primeras seis filas del conjunto de datos para obtener una vista preliminar de su estructura y los valores de las variables.

```{r}
head(data)
```

Vamos a examinar la estructura del conjunto de datos para obtener un resumen de las variables presentes, su tipo de dato y una visión general de cómo están organizados los datos.

```{r}
str(data)
```

El dataset está compuesto por **6,607 filas** y **20 columnas**, las cuales incluyen atributos de distintos tipos: *numéricos*, *categóricos* y *booleanos*.

A continuación, se describen algunos de estos atributos:

-   **Hours_Studied**: Número de horas de estudio semanales.

-   **Attendance**: Porcentaje de clases a las que ha asistido.

-   **Parental_Involvement**: Nivel de implicación de los padres en la educación del alumno *(Low, Medium, High)*.

-   **Access_to_Resources**: Disponibilidad de recursos educativos *(Low, Medium, High)*.

-   **Extracurricular_Activities**: Participación en actividades extraescolares *(Yes, No)*.

-   **Sleep_Hours**: Número medio de horas de sueño por noche.

-   **Previous_Scores**: Puntuaciones de exámenes anteriores.

-   **Motivation_Level**: Nivel de motivación del estudiante *(Low, Medium, High)*.

-   **Internet_Access**: Disponibilidad de acceso a Internet *(Yes, No)*.

-   **Tutoring_Sessions**: Número de sesiones de tutoría a las que asiste al mes.

-   **Family_Income**: Nivel de ingresos familiares *(Low, Medium, High)*.

-   **Teacher_Quality**: Calidad de los profesores *(Low, Medium, High)*.

-   **School_Type**: Tipo de escuela a la que asistió *(Public, Private)*.

-   **Peer_Influence**: Influencia de los compañeros en el rendimiento académico *(Positive, Neutral, Negative)*.

-   **Physical_Activity**: Número medio de horas de actividad física a la semana.

-   **Learning_Disabilities**: Presencia de dificultades de aprendizaje *(Yes, No)*.

-   **Parental_Education_Level**: Nivel educativo más alto de los padres *(High School, College, Postgraduate)*.

-   **Distance_from_Home**: Distancia de casa a la escuela *(Near, Moderate, Far)*.

-   **Gender**: Género del estudiante *(Male, Female)*.

-   **Exam_Score**: Calificación del examen final.

### Identificación de Valores nulos, faltantes o duplicados

A continuación, vamos a observar si existen valores faltantes, erróneos o inconsistentes en el conjunto de datos. Utilizaremos una función que identifica las filas con **valores NA o vacíos ("")** en cada columna, proporcionando un resumen de los valores faltantes por columna, y calcula el número total de filas que contienen al menos un valor faltante o vacío.

```{r}
detect_and_count_missing_data <- function(df) {
  na_count <- colSums(is.na(df))
  
  # Contar los valores vacíos en cada columna
  empty_count <- colSums(sapply(df, function(x) x == ""))
  
  missing_data <- data.frame(NA_Count = na_count, Empty_Count = empty_count)
  
  missing_data <- missing_data[missing_data$NA_Count > 0 | missing_data$Empty_Count > 0, ]
  
  rows_with_missing <- apply(df, 1, function(row) any(is.na(row) | row == ""))
  num_rows_with_missing <- sum(rows_with_missing)
  
  # Porcentaje de filas con algún valor NA o ("")
  porc_num_row_with_missing <- (num_rows_with_missing / nrow(df)) * 100

  result <- list(
    missing_data_by_column = missing_data,
    porc_num_row_with_missing = porc_num_row_with_missing,
    num_rows_with_missing = num_rows_with_missing
  )
  
  return(result)
}

missing_data_result <- detect_and_count_missing_data(data)


print(missing_data_result$missing_data_by_column)
cat("Número de filas con al menos un valor faltante o vacío:", missing_data_result$num_rows_with_missing, "\n")
cat("Porcentaje de filas con valores faltantes o vacíos:", round(missing_data_result$porc_num_row_with_missing, 2), "%\n")


total_values <- ncol(data) * nrow(data)
missing_values <- sum(missing_data_result$missing_data_by_column$NA_Count, na.rm = TRUE) +
                  sum(missing_data_result$missing_data_by_column$Empty_Count, na.rm = TRUE)
missing_proportion <- missing_values / total_values

cat("Proporción de valores faltantes en el conjunto de datos:", round(missing_proportion, 4), "\n")

```

En el resultado arrojado por la función podemos observar que no existen valores **NA** en las columnas de nuestro dataframe, lo que significa que no hay datos explícitamente faltantes o nulos. Sin embargo, también notamos que hay filas con **valores vacíos** en ciertas variables categóricas.

Al sumar el total de valores faltantes podemos observar que hay **229 filas** con algún valor faltante. Esto supone un **3.47%** del total de instacias que tiene el dataframe.

La proporción de valores faltantes en tu conjunto de datos es de **0.00178**, lo que significa que aproximadamente el **0.18% de los datos están faltantes**.

También realizaremos un análisis para verificar si existen filas con valores duplicados dentro del conjunto de datos.

```{r}
detect_complete_duplicates <- function(df) {
  
  duplicated_rows <- df[duplicated(df) | duplicated(df, fromLast = TRUE), ]
  return(duplicated_rows)
}


complete_duplicates_result <- detect_complete_duplicates(data)
if (nrow(complete_duplicates_result) > 0) {
  print("Filas completamente duplicadas:")
  print(complete_duplicates_result)
} else {
  print("No se encontraron filas completamente duplicadas.")
}
```

Podemos ver que no existen filas idénticas dentro del conjunto de datos, lo que indica que cada estudiante es único y no hay duplicados completos de registros.

### Análisis descriptivo

#### Variables numéricas

En esta sección, vamos a calcular las **medidas estadísticas básicas** para las variables numéricas, tales como la *media*, *mediana*, *desviación estándar*, y otros estadísticos relevantes. También calcularemos las frecuencias de las variables categóricas para entender mejor la distribución de los datos.

```{r}
# Resumen estadístico de las variables numéricas
numeric_vars <- sapply(data, is.numeric)  
data_numeric <- data[, numeric_vars]
summary(data_numeric)
```

**Observaciones**

-   La mayoría de los estudiantes estudian entre **16 y 24 horas a la semana**, con una distribución bastante centrada en la media y la mediana. Sin embargo, se observa que el *máximo de 44 horas* indica la presencia de algunos estudiantes que estudian significativamente más.

-   La **asistencia (Attendance)** tiende a ser **alta**, con el 50% de los estudiantes asistiendo al menos 80% de las clases. Sin embargo, **hay alumnos con asistencia más baja (60%)**. Algo destacable es que ningún alumno tiene una porcentaje de asistencia menor al 60% lo que se puede deber a que se requiere de ese porcentaje de asistencia como mínimo para presentarse al exámen.

-   La mayoría de los estudiantes duermen entre **6 y 8 horas**, aunque hay algunos casos que duermen solo 4 horas, lo que podría afectar su rendimiento académico.

-   La **distribución de calificaciones previas está equilibrada**, con la mediana y la media relativamente cercanas. Sin embargo, hay estudiantes con puntajes significativamente más bajos (50), lo que podría indicar dificultades académicas previas.

-   La mayoría de los estudiantes asisten a **1 o 2 sesiones de tutoría al mes**, pero también hay quienes no reciben ninguna tutoría. Respecto a la actividad física, la mayoría de los estudiantes realizan entre 2 y 4 horas, aunque algunos no hacen ninguna actividad, lo que podría impactar su salud y concentración.

-   Respecto a **la calificación final del exámen**, la media y la mediana están alineadas, lo que indica una **distribución simétrica**. La mayoría de los estudiantes obtienen calificaciones **entre 65 y 69**; sin embargo, algunos alcanzan hasta 101, lo que podría deberse a un posible error en los datos o a un estudiante destacado que, gracias a una bonificación adicional, supera la calificación máxima establecida.

Estas conclusiones nos van a orientar sobre los próximos pasos en el preprocesamiento de datos, como identificar grupos de estudiantes con distintos patrones de estudio, asistencia y tutorías. Además, va a ser clave analizar posibles outliers, como la calificación de 101 en el examen final, para determinar si se trata de un error o una excepción justificable.

A continuación calculamos la *desviación estándar* y la *varianza*, lo cual nos da una idea de la dispersión de los datos con los que vamos a trabajar.

```{r}
# Desviación estándar
desviacion_estandar <- sapply(data_numeric, sd)
desviacion_estandar
```

```{r}
# varianza
varianza <- sapply(data_numeric, var)
varianza
```

**Conclusiones**

-   **Variables con alta variabilidad**: `Attendance` y `Previous_Scores` tienen las varianzas más altas, lo que sugiere que hay *grandes diferencias* entre los estudiantes en términos de asistencia y calificaciones previas. Con esta información, podríamos analizar si la variabilidad en Attendance y Previous_Scores impacta directamente en el Exam_Score.

-   **Variables con baja variabilidad**: `Sleep_Hours`, `Tutoring_Sessions`, `Physical_Activity` muestran desviaciones estándar más bajas, lo que indica que la mayoría de los estudiantes tienen *comportamientos similares en estos aspectos*. Es decir, suelen dormir las mismas horas, realizar rutinas de ejercicio similares y sesiones de tutoría parecidas. Por lo que se puede llegar a la conclusión de que estos factores pueden no diferenciar mucho a los estudiantes en términos de rendimiento.

-   **Exam_Score vs Previous_Scores**: *Previous Scores tiene una variabilidad significativamente mayor a Exam_Score* (14.40 vs. 3.89 en desviación estándar), lo que sugiere que las calificaciones en el examen final están más concentradas alrededor de un valor central en comparación con las calificaciones anteriores.

-   Respecto a **Hours_Studied**, su varianza de *35.89* indica una alta dispersión, lo que puede significar que los estudiantes tienen *hábitos de estudio muy variados*. Algunos dedican muchas horas a estudiar, mientras que otros apenas lo hacen. Por ello, puede que el tiempo de estudio sea un factor muy variable y determinante en el rendimiento académico.

#### Variables categóricas

Para las variables categóricas, vamos a calcular las *frecuencias y proporciones de cada categoría* de modo que podamos observar la distribución de las diferentes categorías dentro de cada variable. Para ello, primero seleccionamos las variables categóricas y luego hacemos uso de la función `table()` y `prop.table()` para obtener la distribución de cada una.

```{r}
data <- data %>%
  mutate(across(where(is.character), as.factor))

categorical_vars <- sapply(data, is.factor) 
data_categoric <- data[, categorical_vars] # Filtrar solo variables categóricas
```

```{r}
# Obtener frecuencias absolutas
frecuencias <- lapply(data_categoric, table)
frecuencias
```

NOTA: Al observar las frecuencias, en el caso de `Parental_Education_Level`, `Distance_from_Home` y `Teacher_Quality`se ve una frecuencia sin valor debido a que hemos detectado anteriormente que en esas variables existen valores faltantes.

Algunas de las observaciones obtenidas son las siguientes:

-   **Parental Involvement**, **Teacher Quality** y **Motivation Level**: La mayoría de los estudiantes tienen un nivel medio (seguido de nivel bajo) de involucramiento familiar, motivación, y calidad docente, lo cual podría indicar áreas clave para intervenir en el proceso educativo.

-   **Internet_Access**, **Extracurricular_Activities**, y **Access_To_Recourses**: Las variables relacionadas con el acceso a recursos muestran una distribución relativamente equilibrada, lo que podría ser positivo para el acceso equitativo a la educación.

-   La distribución de **Family_Income** (ingresos familiares) muestra una ligera mayoría de estudiantes provenientes de familias con ingresos bajos (2672), seguida de familias con ingresos medios (2666), y una menor representación de familias con ingresos altos (1269). Además, la mayoría de los estudiantes asiste a escuelas públicas (4598), con un número considerable en escuelas privadas (2009). Estas diferencias de las variables sugieren que el contexto socioeconómico podría influir en la experiencia educativa de los estudiantes.

-   **Learning disabilities**: La mayoría de los estudiantes no tiene discapacidades de aprendizaje (5912), mientras que una fracción pequeña sí las tiene (695).

-   **Peer Influence**: La influencia neutral de los compañeros parece ser la más común (2592), seguida de positiva (2638) y negativa (1377). La influencia de los compañeros es *predominantemente positiva o neutral*, lo que puede indicar que los estudiantes se ven generalmente influenciados de manera favorable.

De forma complementaria, se muestran las proporciones de cada categoría dentro de las variables categóricas del conjunto de datos.

```{r}
# Obtener proporciones relativas
proporciones <- lapply(data_categoric, function(x) prop.table(table(x)))
proporciones
```

En el apartado de *visualización de datos* se explorarán más a fondo estas distribuciones y relaciones, lo que permitirá tener una comprensión más clara y detallada de los patrones en el conjunto de datos.

#### Análisis de correlación entre variables

**Análisis de la Correlación de Variables categóricas**

Tras analizar las distribuciones de las variables categóricas y las medidas estadísticas de las numéricas, el siguiente paso es estudiar la **correlación entre variables**. Este análisis nos permitirá identificar relaciones entre las variables, detectar posibles asociaciones y evaluar la redundancia de información. De este modo, nos facilitará la interpretación de los datos y la selección de variables en etapas posteriores del estudio.

Para ello, vamos a usar **tablas de contingencia**, las cuales muestran la distribución conjunta de dos variables categóricas. La tabla se llena con las frecuencias marginales de todos los pares de valores entre dos variables categoricas, permitiéndonos identificar posibles patrones o asociaciones.

Para ello, primero obtenemos los nombres de todas las variables categóricas de nuestro dataframe.

```{r}
# Obtener nombres de las variables categóricas
categorical_vars_names <- names(data_categoric)
print(categorical_vars_names)
```

A continuación, definimos una función que genera la tabla de contingencia entre dos variables categóricas específicas, las cuales se pasan como parámetros.

```{r}
create_contingency_table <- function(df, var1, var2) {
  df_clean <- df[!is.na(df[[var1]]) & df[[var1]] != "" & !is.na(df[[var2]]) & df[[var2]] != "", ]
  
  # Crear tabla de contingencia
  table_result <- table(df_clean[[var1]], df_clean[[var2]])
  
  # Agregar título descriptivo
  title <- paste("Tabla de contingencia entre", var1, "y", var2)
  
  # Devolver título y tabla
  return(list(title = title, table = table_result))
}
```

Para profundizar en el estudio de las relaciones entre variables y así posteriormente facilitar la segmentación de los estudiantes en grupos con características comunes, **agruparemos las variables categóricas en conjuntos temáticos**. De esta manera, podremos analizar cómo factores relacionados entre sí pueden influir en la organización dentro del aula y el rendimiento académico.

A continuación, definimos los siguientes grupos de variables categóricas:

-   **Factores familiares y socioeconómicos**: Parental_Involvement, Family_Income, Parental_Education_Level, Distance_from_Home.

-   **Recursos y apoyo educativo**: Access_to_Resources, Teacher_Quality, School_Type, Internet_Access.

-   **Características individuales y académicas**: Motivation_Level, Learning_Disabilities, Extracurricular_Activities, Peer_Influence, Gender.

Para cada uno de estos grupos, generaremos tablas de contingencia que permitan identificar patrones dentro de cada categoría y evaluar la posible segmentación de los estudiantes.

```{r}
create_grouped_contingency_tables <- function(df, categorical_vars, group_name) {
  
  variable_groups <- list(
    "Factores familiares y socioeconómicos" = c("Parental_Involvement", "Family_Income", "Parental_Education_Level", "Distance_from_Home"),
    
    "Recursos y apoyo educativo" = c("Access_to_Resources", "Teacher_Quality", "School_Type", "Internet_Access"),
    
    "Características individuales y académicas" = c("Motivation_Level", "Learning_Disabilities", "Extracurricular_Activities", "Peer_Influence", "Gender")
  )
  
  if (!(group_name %in% names(variable_groups))) {
    stop("El grupo especificado no es válido.")
  }
  
  group_vars <- intersect(categorical_vars, variable_groups[[group_name]])
  if (length(group_vars) < 2) {
    stop("El grupo tiene menos de dos variables categóricas disponibles.")
  }
  
  cat("\nAnálisis de:", group_name, "\n")
  
  combinations <- combn(group_vars, 2, simplify = FALSE)
  
  group_tables <- lapply(combinations, function(vars) {
    df_clean <- df[!is.na(df[[vars[1]]]) & df[[vars[1]]] != "" & 
                   !is.na(df[[vars[2]]]) & df[[vars[2]]] != "", ]
    
    table_result <- table(df_clean[[vars[1]]], df_clean[[vars[2]]])
    title <- paste("Tabla de contingencia entre", vars[1], "y", vars[2])
    
    cat("\n", title, "\n")
    print(table_result)
    
    return(list(title = title, table = table_result))
  })
  
  return(group_tables)
}
```

```{r}
table_factores_familiares <- create_grouped_contingency_tables(data_categoric, categorical_vars_names, "Factores familiares y socioeconómicos")
```

**Análisis de las Relaciones Más Relevantes en Factores Familiares y Socioeconómicos**

De las relaciones analizadas en las tablas de contingencia, nos hemos quedado con aquellos patrones que ofrecen información curiosa y relevante sobre cómo los factores familiares y socioeconómicos pueden influir en la educación de los estudiantes.

**1. Los padres con mayores ingresos participan menos en la educación de sus hijos.** Respecto a la relación entre `Parental_Involvement` y `Family_Income`, se observa que las familias con ingresos altos no muestran un nivel de involucramiento parental significativamente mayor en comparación con familias de ingresos medios o bajos. Esto sugiere que estos padres pueden delegar la educación de sus hijos en tutores privados o confiar en que las escuelas gestionen su aprendizaje sin su intervención directa.

**2. A mayor nivel educativo de los padres, mayor es su involucramiento**. Existe una relación clara entre el nivel educativo de los padres y su nivel de participación en la educación de sus hijos. Sin embargo, los padres con estudios de posgrado están menos involucrados que aquellos con estudios universitarios o de secundaria, lo que podría indicar que tienen menos tiempo disponible debido a sus responsabilidades laborales.

**3.Los estudiantes de familias con ingresos bajos suelen vivir más lejos de la escuela**. Los datos muestran que los estudiantes de familias con menores ingresos tienden a residir en zonas más alejadas de la escuela. Esto puede deberse a limitaciones económicas que dificultan el acceso a viviendas cercanas a instituciones educativas.

**4.Los padres que viven más cerca de la escuela están más involucrados**. Existe una diferencia significativa en la participación parental según la distancia entre la casa y la escuela. Puede deberse a que los padres que viven cerca tienen más oportunidades de asistir a reuniones, supervisar tareas y participar activamente en el proceso educativo de sus hijos.

**5.Ingresos familiares altos corresponde con el menor nivel educativo**. la mayoría de las familias con ingresos altos (High) tienen padres cuyo nivel educativo más frecuente es High School. Esto puede ser debido a que, en determinadas generaciones o contextos, no era necesario un título universitario para alcanzar buenos ingresos, mientras que en la actualidad la educación superior puede ser un requisito más común para acceder a salarios altos.

```{r}
table_recursos_educativos <- create_grouped_contingency_tables(data_categoric, categorical_vars_names, "Recursos y apoyo educativo")
```

**Análisis de las relaciones mas relevantes en factores de Recursos y apoyo educativo**

**1. Acceso a recursos y acceso a internet están fuertemente relacionados**. En todas las categorías de Access_to_Resources (High, Medium, Low), la mayoría de los estudiantes tienen acceso a internet. Aunque los estudiantes con Low Access to Resources son los que tienen menos acceso a internet, lo que sugiere que las carencias en recursos también se reflejan en la conectividad.

**2.La calidad docente parece mejorar con mejores recursos**. La categoría High Access to Resources tiene la mayor proporción de profesores calificados como High Quality (581), en comparación con Low (207) o Medium (1161). En cambio, los estudiantes con Low Access to Resources tienen menos profesores High (408) y proporcionalmente más en categorías Low y Medium. Esto nos podría decir que los recursos disponibles en la escuela podrían influir en la calidad percibida del profesorado.

**3. Las escuelas privadas tienen mejor acceso a recursos**. 642 estudiantes en escuelas privadas reportan tener High Access to Resources, mientras que solo 1333 en escuelas públicas tienen esta misma categoría. En cambio, los estudiantes con Low Access to Resources se encuentran mayoritariamente en escuelas públicas (916 frente a 397 en privadas).

```{r}
table_caracteristicas_individuales <- create_grouped_contingency_tables(data_categoric, categorical_vars_names, "Características individuales y académicas")
```

**Análisis de las relaciones mas relevantes en características individuales y académicas**

**1. Los estudiantes que participan en actividades extracurriculares tienden a tener un mayor nivel de motivación**. La mayoría de los estudiantes con un nivel de motivación "alto" (1998) participan en actividades extracurriculares, mientras que la cantidad de estudiantes con motivación "baja" (801) es menor entre los que no participan. Esto sugiere un ciclo positivo entre la motivación y la participación.

**2. Actividades extracurriculares y la influencia de los compañeros**. En los estudiantes con `Extracurricular_activities` con valor Yes, una gran mayoría reporta un valor de `Peer_Influence` "positive" (1610), mientras que la proporción de estudiantes con `Peer_Influence` "negative" (541) es menor entre los no participantes. Esto podría sugerir que las actividades extracurriculares fomentan entornos de apoyo y tiene un impacto positivo en la relación con sus pares.

**3. Motivación y influencia de los compañeros**. En la tabla de contingencia, los estudiantes con un `Motivation_Level` más alto tienen una mayor proporción de influencia (`Peer_Influence`) "positiva" (533) en comparación con los estudiantes con motivación "baja" (417). Esto podría indicar que un mayor nivel de motivación está relacionado con una mayor integración social.

**4. Género y otros factores**. En cuanto a las relaciones de género con otras variables, se observa que los *hombres tienen una mayor prevalencia de discapacidades de aprendizaje en comparación con las mujeres*, con una mayor cantidad de varones diagnosticados con estas discapacidades. Además, aunque las *mujeres tienen una mayor frecuencia en los niveles de motivación alta en comparación con los hombres*, las diferencias no son demasiado marcadas en términos absolutos. En *relación con la influencia de los compañeros*, no se detectan diferencias significativas entre hombres y mujeres, ya que las proporciones de influencia negativa, neutral y positiva son bastante similares para ambos géneros. En general, las diferencias de género en estas variables no parecen ser muy pronunciadas, pero sí revelan tendencias interesantes en cuanto a la prevalencia de discapacidades de aprendizaje y la motivación.

**NOTA**: En este análisis de las tablas de contingencia, el desbalance en el número de estudiantes entre categorías, como en el caso de las escuelas públicas y privadas, puede afectar la interpretación de las relaciones entre variables, como la calidad docente o el acceso a recursos. Las frecuencias absolutas pueden dar una impresión errónea debido a la mayor cantidad de estudiantes en las escuelas públicas. Para corregir este sesgo, se analizarán las proporciones o porcentajes dentro de cada categoría, lo que permitirá obtener conclusiones más precisas. Este enfoque se aplicará en la siguiente fase del análisis.

**Análisis de la Correlación de Variables Numéricas**

En este apartado, se busca analizar la **correlación entre las variables numéricas** del conjunto de datos. Para ello, es necesario examinar la distribución de cada una de las variables numéricas y determinar si su relación es lineal o no lineal, lo que nos ayudará a decidir qué tipo de coeficiente de correlación aplicar: **Pearson** o **Spearman**.

Primero, se analizarán las distribuciones de las variables numéricas para entender su comportamiento. Esto es crucial porque el coeficiente de **Pearson** asume que las variables tienen distribuciones normales y una relación lineal. Si las variables no siguen una distribución normal, o si se observa que la relación es no lineal, optaremos por el coeficiente de **Spearman**, que no requiere normalidad en la distribución y evalúa la relación monótona entre las variables.

**Distribución de las Variables Numéricas**

Para empezar, se realiza un análisis de la distribución de las variables numéricas a través de histogramas. Cada variable se examina de manera individual para identificar su forma y si se ajusta o no a una distribución normal.

```{r}
create_histogram <- function(df, variable, binwidth = 1, fill = "cornflowerblue") {
  if (!(variable %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  ggplot(df, aes_string(x = variable)) +
    geom_histogram(binwidth = binwidth, 
                   fill = fill, color = "black", bins = 20) +
    labs(title = paste(variable, "analysis"), x = variable, y = "Count") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5))
}

create_histogram(data, "Sleep_Hours")
create_histogram(data, "Hours_Studied")
create_histogram(data, "Attendance")
create_histogram(data, "Tutoring_Sessions")
create_histogram(data, "Physical_Activity")
create_histogram(data, "Previous_Scores")
create_histogram(data, "Exam_Score")
```

Tras analizar los histogramas, observamos que las variables `Sleep_Hours`, `Hours_Studied` y `Physical_Activity` siguen una **distribución normal**, con una forma simétrica y una concentración de valores en el centro. Por otro lado, `Tutoring_Sessions` y `Exam_Score` presentan un **sesgo negativo** (a la izquierda), ya que las barras en el extremo izquierdo son más altas. En cuanto a `Attendance` y `Previous_Score`, tienen una **distribución uniforme**, con barras de altura similar a lo largo de casi toda la distribución, mostrando solo una leve disminución en los extremos.

**Análisis de Normalidad con Gráficos Q-Q**

Después de analizar los histogramas, utilizamos los **gráficos Q-Q (Quantile-Quantile plots)** para evaluar con mayor precisión si las variables numéricas siguen una distribución normal.

Estos gráficos comparan los cuantiles de los datos con los cuantiles de una distribución normal teórica de modo que si los puntos siguen aproximadamente una línea recta, la variable se ajusta bien a una distribución normal.

A continuación, se presentan los gráficos Q-Q para cada variable numérica del conjunto de datos:

```{r}
create_qq_plot <- function(df, variable) {
  if (!(variable %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  # Crear el gráfico Q-Q
  ggplot(df, aes(sample = .data[[variable]])) + 
    stat_qq() +
    stat_qq_line(color = "red") + 
    labs(title = paste("Q-Q Plot para", variable), x = "Cuantiles teóricos", y = "Cuantiles muestrales") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5))
}

create_qq_plot(data, "Sleep_Hours")
create_qq_plot(data, "Hours_Studied")
create_qq_plot(data, "Attendance")
create_qq_plot(data, "Tutoring_Sessions")
create_qq_plot(data, "Physical_Activity")
create_qq_plot(data, "Previous_Scores")
create_qq_plot(data, "Exam_Score")
```

Al analizar los gráficos Q-Q, observamos que las conclusiones coinciden con las obtenidas a partir de los histogramas. En particular, en las gráficas de `Tutoring_Sessions` y `Exam_Score`, los puntos en el extremo derecho se desvían notablemente por encima de la línea, mientras que en el extremo izquierdo están ligeramente por debajo. Esto indica un sesgo a la derecha, lo que significa que hay valores más altos que se alejan de la distribución normal esperada.

Por otro lado, las gráficas de `Attendance` y `Previous_Score` muestran una distribución bastante uniforme, ya que los puntos se distribuyen de manera relativamente constante en torno a la línea de referencia. Esta observación refuerza la conclusión previa de los histogramas, confirmando que ambas variables siguen una distribución uniforme.

**Análisis de Correlación entre Variables**

En este apartado, vamos a evaluar la relación entre las variables numéricas del conjunto de datos, aplicando el coeficiente de correlación adecuado según si las variables siguen una distribución normal o no.

```{r}
normal_vars <- c("Sleep_Hours", "Hours_Studied", "Physical_Activity")
non_normal_vars <- c("Attendance", "Tutoring_Sessions", "Previous_Scores", "Exam_Score")
```

Luego, calculamos la matriz de correlación utilizando el coeficiente de Pearson para las variables normales. Para las variables no normales, reemplazamos el cálculo con el coeficiente de Spearman. La matriz resultante nos muestra cómo se correlacionan todas las variables entre sí, asignando un valor entre -1 y 1, donde:

-   1 indica una correlación positiva perfecta.

-   -1 indica una correlación negativa perfecta.

-   0 indica que no existe correlación lineal.

```{r}
# Crear una matriz de correlación combinando Pearson y Spearman
cor_matrix <- cor(data_numeric, method = "pearson")  
cor_matrix[non_normal_vars, non_normal_vars] <- cor(data_numeric[, non_normal_vars], method = "spearman")

print(cor_matrix)
```

Para interpretar mejor la matriz creada anteriormente vamos a crear un **HeatMap**. Este gráfico visualiza las correlaciones entre las variables con un esquema de colores que ayuda a identificar las relaciones fuertes o débiles.

```{r}
cor_data <- melt(cor_matrix)

# Crear el heatmap
ggplot(cor_data, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(label = round(value, 2)), color = "white", size = 4) +  # Muestra valores en celdas
  scale_fill_gradient2(low = "blue", high = "red", midpoint = 0) +
  labs(title = "Heatmap de Correlación", x = "Variable", y = "Variable") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Al analizar el heatmap de correlación, observamos que la mayoría de las variables presentan coeficientes de correlación cercanos a 0, es decir, existe una **baja o nula relación lineal** entre ellas. Esto sugiere que, en general, los factores analizados en el dataset no muestran una dependencia fuerte entre sí.

Sin embargo, al centrarnos en la variable `Exam_Score`, notamos que las variables `Attendance` y `Hours_Studied` son las que presentan la **mayor correlación positiva con el desempeño académico**. Esto implica que los estudiantes que asisten con mayor frecuencia a clases y dedican más tiempo al estudio tienden a obtener mejores resultados en los exámenes.

**NOTA**:A pesar de esta relación, es importante destacar que **la correlación no implica causalidad**. Aunque existe una asociación entre estas variables, otros factores no considerados en el análisis podrían influir en el rendimiento de los estudiantes, como la calidad de la enseñanza o incluso el estado emocional del estudiante.

**Gráficos de dispersión**

Por último, vamos a crear diagramas de dispersión (scatter plots) para explorar más a fondo la relación entre las dos variables que tengan mayor correlación. En este caso, mostramos el scatter plot entre las variables `Hours_Studied`, `Previous_Scores` y `Exam_Score`, lo cual nos ayuda a observar si existe una tendencia o relación lineal entre estas dos.

```{r}
create_scatter_plot <- function(df, var_x, var_y) {
  ggplot(df, aes_string(x = var_x, y = var_y, color = var_y)) +  
    geom_point(alpha = 0.7, size = 3) +  
    geom_smooth(method = "lm", color = "black", se = FALSE) +  
    scale_color_viridis_c(option = "magma") +  
    labs(title = paste("Relación entre", var_x, "y", var_y),
         x = var_x, y = var_y, color = var_y) +
    theme_minimal()
}
```

```{r}
create_scatter_plot(data_numeric, "Hours_Studied", "Exam_Score")
```

Al observar el gráficos de dispersión se identifican dos comportamientos distintos en la relación entre **Hours_Studied** y **Exam_Score**. Para notas entre **60 y 75**, se aprecia un crecimiento que parece ser exponencial o lineal, lo que sugiere que a medida que los estudiantes dedican más tiempo al estudio, su rendimiento en el examen mejora de manera consistente, lo cuál indica una relación clara entre el número de horas estudiadas y el puntaje obtenido.

Sin embargo, cuando el **Exam_Score** supera los **75 puntos**, la cantidad de horas estudiadas presenta una mayor variabilidad, oscilando entre **5 y 30 horas**. A pesar de esta dispersión, se observa que la mayoría de los estudiantes con puntajes altos han estudiado entre **20 y 30 horas**. Esto sugiere que, a partir de cierto punto, estudiar más horas no siempre se traduce en un mejor desempeño, y otros factores podrían estar influyendo en el rendimiento académico.

Una posible explicación es que algunos estudiantes logran notas altos con menos horas de estudio debido a estrategias más eficientes o conocimientos previos.

También se observa una pequeña fracción de estudiantes con **calificaciones superiores a 90 pese a haber estudiado muy poco (menos de 3 horas)**. Estos casos podrían considerarse como valores atípicos en futuros análisis si afectan la interpretación de los datos, analizándolos por separado o excluyéndolos según el contexto.

```{r}
create_scatter_plot(data_numeric, "Attendance", "Exam_Score")
```

En cuanto a Attendance, la gráfica muestra un patrón similar al de `Hours_Studied`. Se observa un crecimiento exponencial en la relación con `Exam_Score` entre los **60 y 75 puntos**, lo que indica que una mayor asistencia a clases tiende a estar asociada con un mejor desempeño en este rango. Sin embargo, para **calificaciones** superiores a 75, la asistencia varía significativamente, desde niveles casi perfectos hasta valores mucho más bajos, lo que sugiere que, en estos casos, otros factores podrían estar influyendo en el rendimiento académico.

A continuación, mostramos el gráfico de dispersión entre `Previous_Scores` y `Exam_Score` el cuál tiene un comportamiento similar respecto a `attendance`.

```{r}
create_scatter_plot(data_numeric, "Previous_Scores", "Exam_Score")
```

Por último, vamos a crear un gráfico en 3D que nos permita visualizar la relación entre tres variables al mismo tiempo. En lugar de solo observar las variables en dos dimensiones (como hemos hecho anteriormente en un gráfico de dispersión tradicional), este gráfico nos ayudará a ver cómo interactúan las tres variables simultáneamente.

```{r}
create_scatter_plot_3d <- function(df, var_x, var_y, var_color) {
  ggplot(df, aes_string(x = var_x, y = var_y, color = var_color)) +
    geom_point(alpha = 0.7, size = 3) +  
    geom_smooth(method = "lm", color = "black", se = FALSE) +  
    scale_color_viridis_c(option = "plasma") +
    labs(title = paste("Relación entre", var_x, "y", var_y, "con", var_color),
         x = var_x, y = var_y, color = var_color) +
    theme_minimal()
}

create_scatter_plot_3d(data_numeric, "Attendance", "Exam_Score", "Hours_Studied")
```

Podemos observar que hay estudiantes con una asistencia similar que, sin embargo, presentan una gran variabilidad en sus horas de estudio, desde muy bajas hasta bastante altas. Un ejemplo claro de esto son aquellos estudiantes que asisten al 100% de las clases, pero sus horas de estudio fuera del aula son muy variadas Algunos de estos estudiantes dedican muy poco tiempo al estudio, mientras que otros, a pesar de su alta asistencia, invierten muchas horas de estudio. Esto sugiere que **la asistencia a clases no siempre está directamente relacionada con la cantidad de horas dedicadas al estudio fuera del aula**, y los hábitos de estudio varían considerablemente entre los estudiantes.

Por otro lado, cuando observamos los estudiantes con altos valores de `Exam_Score`, notamos que, aunque la asistencia puede variar, los estudiantes con una calificación alta en el examen suelen haber dedicado **más de 15 horas de estudio**. Esto sugiere que, aunque la asistencia a clases es importante, las horas de estudio fuera del aula juegan un papel fundamental en el rendimiento académico, especialmente para los estudiantes con calificaciones más altas.

Es importante destacar que esta gráfica también revela un patrón interesante: **un pequeño porcentaje de estudiantes, que en un principio sorprendió por obtener calificaciones superiores a 9 con pocas horas de estudio, tiene una asistencia superior al 85%**. Esto sugiere que, aunque estos estudiantes no dedicaron muchas horas adicionales al estudio, su alta asistencia a clases podría haberles proporcionado un nivel de comprensión que les permitió obtener buenos resultados.

**Conclusiones del análisis de correlación entre variables**

En conclusión, el análisis de correlación entre las variables muestra que las más fuertemente relacionadas son `Hours_Studied` y `Exam_Score`, con una **correlación positiva significativa**, lo que indica que a medida que los estudiantes dedican más horas al estudio, su desempeño en los exámenes tiende a mejorar. De manera similar, `Attendance` también muestra una correlación positiva con `Exam_Score`, lo que sugiere que **los estudiantes que asisten con mayor frecuencia a clases tienen un mejor rendimiento en los exámenes**. Sin embargo, la relación entre `Attendance` y `Hours_Studied` no es tan fuerte, ya que, aunque ambos factores tienden a aumentar juntos, existe una considerable **variabilidad en las horas de estudio entre los estudiantes con una asistencia similar**.

## Preprocesamiento de datos

### Decisiones sobre la Integridad del Conjunto de Datos

Después de realizar el análisis exploratorio de los datos, hemos decidido **no eliminar ninguna columna del conjunto de datos**, ya que se considera que todas son relevantes para el estudio del rendimiento académico. Las variables contenidas en el conjunto de datos, como `Teacher_Quality` (calidad del profesorado), `Parental_Education_Level` (nivel educativo de los padres) y `Distance_from_Home` (distancia desde el hogar), son factores clave que **impactan directamente en el desempeño académico y proporcionan contexto crucial para entender las diferencias entre los estudiantes**.

Cada una de estas columnas aporta información valiosa que contribuye a identificar patrones y relaciones importantes para nuestro análisis y La eliminación de alguna de estas variables podría reducir la precisión de los resultados, por lo que se ha optado por mantenerlas todas en el modelo.

### Manejo de valores nulos

Durante la exploración de los datos, hemos identificado que existen algunas filas con valores faltantes, específicamente en las variables **Teacher_Quality**, **Parental_Education_Level** y **Distance_from_Home**. Sin embargo, dado que la **proporción de registros con datos ausentes es baja** (un máximo de 235 filas con valores faltantes de un total de 6600), esto sugiere que la **calidad general de los datos es bastante razonable**.

En este caso, consideramos que la opción más adecuada es **eliminar las filas con valores faltantes**. Dado que representan una fracción pequeña del total (**3.47%**), su eliminación no debería afectar significativamente los resultados, y el impacto en la calidad del análisis sería mínimo. Además, al eliminar estas filas no corremos el riesgo de introducir sesgos en el modelo.

```{r}
clean_missing_data <- function(df) {
  original_row_count <- nrow(df)
  
  # Eliminar filas con valores NA o vacíos en cualquier columna
  df <- df[!apply(df, 1, function(x) any(is.na(x) | x == "")), ]
  
  # Eliminar niveles vacíos de las variables categóricas específicas
  df$Teacher_Quality <- droplevels(df$Teacher_Quality)
  df$Parental_Education_Level <- droplevels(df$Parental_Education_Level)
  df$Distance_from_Home <- droplevels(df$Distance_from_Home)
  
  cleaned_row_count <- nrow(df)
  rows_removed <- original_row_count - cleaned_row_count
  cat("Número de filas eliminadas:", rows_removed, "\n")
  
  return(df)
}

# Aplicar la función a los datos
data <- clean_missing_data(data)

```

Observamos que se han eliminado 229 filas por lo que el dataset sin ningún valor de faltante constaría de un total de **6378 filas**.

### Detección de outliers

Antes de desarrollar modelos predictivos, es crucial identificar los valores atípicos. Para ello, empleamos el **método del rango intercuartil (IQR)**, que nos permite detectar valores extremos en las variables numéricas, evaluar su impacto en el análisis y determinar posibles tratamientos.

```{r}
numeric_cols <- sapply(data, is.numeric)

count_outliers <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  sum(x < lower_bound | x > upper_bound, na.rm = TRUE)
}


for (col_name in names(data)[numeric_cols]) {
  num_outliers <- count_outliers(data[[col_name]])
  print(paste("Variable:", col_name, "- Outliers:", num_outliers))
}
```

Podemos observar que existen outliers en las variables `Hours_studies`, `Tutoring_Sessions` y `Exam_Score`. Para analizarlos mejor, utilizaremos gráficos de caja o boxplots que nos permitirán visualizar su distribución.

```{r}
plot_boxplots <- function(df) {
  plots <- list()
  numeric_cols <- c("Hours_Studied", "Tutoring_Sessions", "Exam_Score")
  numeric_cols <- numeric_cols[numeric_cols %in% names(df)]
  

  for (var in numeric_cols) {
    p <- ggplot(df, aes_string(y = var)) +
      geom_boxplot(fill = "orange", alpha = 0.7) +
      theme_minimal() +
      labs(title = paste("Outliers in", var), y = var)
    
    plots[[var]] <- p
  }

  for (p in plots) {
    print(p)
  }
}
```

```{r}
plot_boxplots(data)
```

Al observar los gráficos de caja, podemos identificar la presencia de valores atípicos. Sin embargo, no todos estos valores deberían considerarse como anomalías.

En el caso de la variable `tutoring_sessions`, los valores entre 4 y 8 se marcan como atípicos, aunque representan un rango perfectamente válido de horas de tutoría. De manera similar, en `Hours_Studied`, se detectan valores extremos por encima de las 35 horas y por debajo de las 5 horas de estudio. Si bien estos pueden parecer atípicos desde una perspectiva estadística, es posible que reflejen hábitos de estudio reales en algunos estudiantes.

En cambio, en el gráfico de `Exam_Scores`, se pueden notar calificaciones que superan el valor máximo permitido de 100. Para solucionar esto, filtraremos las filas en las que el valor de `Exam_Score` sea superior a 100 y lo estableceremos a la máxima nota posible, es decir, 100.

```{r}
data$Exam_Score[data$Exam_Score > 100] <- 100
max_Exam_score <- max(data$Exam_Score)
print(max_Exam_score)
```

### Codificación

Para preparar los datos de manera óptima para el análisis, aplicamos varias transformaciones a las variables categóricas y ordinales. Esto nos permite estructurar la información de manera que los modelos puedan interpretarla correctamente.

Con esta función convertimos las columnas del data frame en factores ordenados y les asignamos valores enteros, de acuerdo con un orden específico de niveles. Esto es util para las variables que tienen una relación de orden o tienen un nivel jerárquico o progresivo, es decir, que pueden compararse en términos de más o menos, mejor o peor, mayor o menor.

-   `Parental_Involvement`,`Access_to_Resources`,`Motivation_Level`,`Family_Income`,`Teacher_Quality`. Estas variables pueden ordenarse de menor a mayor o viceversa".

-   En `Peer_Influence`, **Positive \> Neutral \> Negative** en términos de impacto en el rendimiento. Por lo que tambien se pueden ordenar.

-   En `Distance_from_Home` ordenamos los valores en términos de **nivel de cercanía** de la escuela a la casa del estudiante.

-   En `Parental_Education_Level` ordenamos los valores en términos de **nivel de estudio de los padres**. Desde menos estudios (High School) hasta más estudios (Postgraduate).

```{r}
convert_to_ordered_int <- function(df, column_names, levels_order, ordered = TRUE) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      df[[col]] <- as.integer(factor(df[[col]], levels = levels_order, ordered = ordered))
    }
  }
  return(df)
}

```

Algunas variables categóricas contienen únicamente valores "Yes" o "No", por lo que es más eficiente transformarlas en valores 0 y 1, 'No' y 'Yes', respectivamente.

Las variables modificadas serán:

-   `Extracurricular_Activities`, `Internet_Access`, `Learning_Disabilities` → Yes = 1, No = 0

```{r}
convert_to_binary <- function(df, column_names) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      df[[col]] <- ifelse(df[[col]] == "Yes", 1, 0)
    }
  }
  return(df)
}

```

Algunas variables no tienen una jerarquía clara, por lo que en lugar de asignar valores ordinales, creamos columnas binarias (dummies) para cada categoría, es decir, aplicamos One-Hot Encoding.

-   `School_Type` pasará a dividirse en dos columnas: `School_Type_Public` y `School_Type_Private`
-   `Gender` se convierte en `Gender_Male` y `Gender_Female`.

```{r}
convert_to_one_hot <- function(df, column_names) {
  for (col in column_names) {
    if (col %in% colnames(df)) {
      unique_values <- unique(df[[col]])
      for (val in unique_values) {
        new_col_name <- paste(col, val, sep = "_")
        df[[new_col_name]] <- ifelse(df[[col]] == val, 1, 0)
      }
      df[[col]] <- NULL  # Eliminamos la columna original después de crear las dummy variables
    }
  }
  return(df)
}

```

En cuanto a las calificaciones de los estudiantes, vamos a añadir una columna que clasifique las `Previous_Scores` de los estudiantes en diferentes categorías, de acuerdo con los rangos de puntuación establecidos en el sistema español:

-   **Aprobado**: Para las calificaciones entre 5.0 y 6.9.

-   **Bien**: Para las calificaciones entre 7.0 y 7.9.

-   **Notable**: Para las calificaciones entre 8.0 y 8.9.

\-**Sobresaliente**: Para las calificaciones superiores a 9.0.

```{r}
categorize_previous_scores <- function(df) {
  df <- df %>%
    
    mutate(
      Previous_Scores_Category = case_when(
        Previous_Scores >= 50 & Previous_Scores <= 69 ~ "Aprobado",
        Previous_Scores >= 70 & Previous_Scores <= 79 ~ "Bien",
        Previous_Scores >= 80 & Previous_Scores <= 89 ~ "Notable",
        Previous_Scores >= 90 ~ "Sobresaliente"
      )
    ) %>%
    
    select(Previous_Scores, Previous_Scores_Category, everything()) 

  return(df)
}

data <- categorize_previous_scores(data)
```

Todo lo mencionado anteriormente se llevará a cabo ejecutando la siguiente función:

```{r}
clean_and_filter_data <- function(data) {
  data <- data %>%
    distinct() %>%
    
    convert_to_ordered_int("Previous_Scores_Category", 
                           c("Aprobado", "Bien", "Notable", "Sobresaliente")) %>%
    
    # Convertir a valores ordenados (Low < Medium < High)
    convert_to_ordered_int(c("Parental_Involvement", "Access_to_Resources", "Motivation_Level",
                              "Family_Income", "Teacher_Quality"),
                           c("Low", "Medium", "High")) %>%
    
    # Convertir Peer_Influence en valores ordenados (Negative < Neutral < Positive)
    convert_to_ordered_int("Peer_Influence", c("Negative", "Neutral", "Positive")) %>%
    
    # Convertir Parental Education Level en valores ordenados (High School < College < Postgraduate)
    convert_to_ordered_int("Parental_Education_Level", c("High School", "College", "Postgraduate")) %>%
    
    # Convertir Distance_from_Home en valores ordenados (Near < Moderate < Far)
    convert_to_ordered_int("Distance_from_Home", c("Near", "Moderate", "Far")) %>%
    
    # Convertir a valores binarios (No = 0, Yes = 1)
    mutate(
      Extracurricular_Activities = ifelse(Extracurricular_Activities == "Yes", 1, 0),
      Internet_Access = ifelse(Internet_Access == "Yes", 1, 0),
      Learning_Disabilities = ifelse(Learning_Disabilities == "Yes", 1, 0)
    ) %>%
    
    # Aplicar One-Hot Encoding a School_Type y Gender
    mutate(
      School_Type_Private = ifelse(School_Type == "Private", 1, 0),
      School_Type_Public = ifelse(School_Type == "Public", 1, 0),
      Gender_Male = ifelse(Gender == "Male", 1, 0),
      Gender_Female = ifelse(Gender == "Female", 1, 0)
    ) %>%
    
    # Eliminar las columnas originales después de One-Hot Encoding
    select(-School_Type, -Gender)

  return(data)
}

```

```{r}
df_cleaned <- clean_and_filter_data(data)
```

Vamos a guardar df_cleaned en la carpeta 'data' para poder hacer uso del dataset preprocesado en las preguntas individuales:

```{r}
df_cleaned
write.csv(df_cleaned, file = "data/df_cleaned.csv", row.names = FALSE)

```

Después de la codificación, nuestro dataset consta de estos tipos:

```{r}
str(df_cleaned)
```

### Escalarización

Para que el análisis sea óptimo, también es necesario escalar las variables.

-   `Sleep_Hours` toma como valor las horas de sueño por noche. Supondremos que el estudiante duerme esta cantidad de horas todos los días por lo que modificaremos el valor para que sean horas semanales (Multiplicamos por 7 las horas de sueño diarias).

-   `Tutoring_Sessions` toma como valor las sesiones de tutoria por mes. Para escalar esta variable, se tomará 1 sesión de tutoría = 1 hora y a su vez, se pasará a horas semanales. Por ejemplo, si un estudiante tiene `Tutoring_Sessions` = 4 en un mes, significa que tiene 1 por semana (`Tutoring_Sessions`/ 4 semanas).

```{r}
scale_time_variables <- function(df) {
  df <- df %>%
    mutate(
      Sleep_Hours = Sleep_Hours * 7,  # Convertir de horas por noche a horas por semana
      Tutoring_Sessions = Tutoring_Sessions / 4  # Convertir sesiones a horas/semana
    )
  return(df)
}

df_cleaned <- scale_time_variables(df_cleaned)

print("Sleep_Hours:") 
summary(df_cleaned$Sleep_Hours)  # Debería estar en un rango de 0-56 horas semanales
print("Tutoring_Sessions:")
summary(df_cleaned$Tutoring_Sessions)  # Ahora representará horas de tutoría por semana


```

Como puede observarse, para las horas de sueño semanales, el mínimo es 28, lo cual significa que hay estudiantes que duermen 4 horas por noche (4 \* 7 = 28). La mediana es 49, lo que indica que la mayoría de los estudiantes duermen aproximadamente 7 horas por noche (7 \* 7 = 49). El máximo es 70, lo que implica que algunos estudiantes duermen 10 horas por noche (10 \* 7 = 70).

Por otro lado, para las horas de tutoría por semana, el mínimo es 0, lo cual es correcto, ya que algunos estudiantes no tienen sesiones de tutoría. La mediana es 0.25, lo que significa que muchos estudiantes tienen 1 sesión por mes (1 hora / 4 = 0.25 horas/semana). El máximo es 2, lo que indica que algunos estudiantes tienen 8 sesiones de tutoría por mes, que equivale a 2 horas de tutoría por semana.

A continuación, exportamos el dataframe `df_cleaned` en un **archivo CSV** para su uso en proyectos individuales, evitando la necesidad de repetir todo el proceso de preprocesamiento.

```{r}
# Exportar el dataframe a un archivo CSV
# Verificar si el archivo ya existe antes de exportarlo
file_path <- "df_cleaned.csv"

if (!file.exists(file_path)) {
  write.csv(df_cleaned, file_path, row.names = FALSE)
  message("Archivo exportado exitosamente.")
} else {
  message("El archivo ya existe. No se ha vuelto a exportar.")
}
```

## Visualización de los datos

En este apartado, exploraremos la distribución y relaciones entre las variables del conjunto de datos mediante diferentes representaciones gráficas. A través de histogramas, gráficos de dispersión y diagramas de barras, podremos identificar patrones, tendencias y posibles valores atípicos que nos ayuden a comprender mejor la información disponible.

### Distribución de variables numéricas

Para analizar la distribución de las variables numéricas relacionadas con el tiempo, generaremos histogramas que nos permitirán visualizar cómo se distribuyen sus valores.

A continuación, se presentan los histogramas de las principales variables horarias para evaluar su comportamiento en el conjunto de datos.

```{r}
create_hour_histogram <- function(df, variable, fill = "cornflowerblue") {
  if (!(variable %in% colnames(df))) {
    stop("La variable no existe en el dataframe.")
  }
  
  ggplot(df, aes_string(x = variable)) +
    geom_bar(stat = "count", 
             fill = fill, color = "black", 
             position = position_dodge(width = 1)) +  # Asegura que las barras estén separadas
    scale_x_continuous(breaks = seq(min(df[[variable]], na.rm = TRUE), 
                                    max(df[[variable]], na.rm = TRUE), by = 1)) +  
    labs(title = paste("Distribución de", variable), 
         x = variable, y = "Frecuencia") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5))
}

create_hour_histogram(data, "Sleep_Hours")
create_hour_histogram(data, "Tutoring_Sessions")
create_hour_histogram(data, "Physical_Activity")
```

Respecto a las horas de sueño (`Sleep_Hours`), se observa que sigue una distribución aproximadamente normal, con la mayoría de los estudiantes durmiendo alrededor de 7 horas. En cuanto a las sesiones de tutoría, la mayoría de los estudiantes asiste a 1 o 2 sesiones, siendo poco común superar las 3 sesiones, y muchos estudiantes no asisten a ninguna. En relación con las horas de actividad física semanal, la mayoría dedica unas 3 horas a la semana al ejercicio, aunque también se observa una variabilidad en torno a las 2 y 4 horas. Es importante destacar que una pequeña proporción de estudiantes no realiza ninguna actividad física semanalmente

### Distribución de calificaciones

```{r}
# Supongamos que 'data' es el dataframe y 'Previous_Scores_Category' es la columna con las categorías
category_counts <- data %>%
  count(Previous_Scores_Category)

# Crear gráfico de pie con ggplot
ggplot(category_counts, aes(x = "", y = n, fill = Previous_Scores_Category)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Distribución de las Categorías de Calificación (Previous_Scores_Category)", 
       x = NULL, y = NULL) +
  theme_void() +
  theme(legend.title = element_blank()) +
  scale_fill_manual(values = c("#ff9999", "#66b3ff", "#99ff99", "#ffcc99")) +
  geom_text(aes(label = paste(n, "estudiantes")), 
            position = position_stack(vjust = 0.5), 
            size = 3,  # Reducimos el tamaño de la fuente
            check_overlap = TRUE)  # Asegura que no haya superposición de texto

```

### Distribución de variables categóricas

En este apartado, vamos a visualizar la distribución de las variables categóricas dentro del conjunto de datos. El objetivo principal es observar cómo se distribuyen las categorías dentro de cada variable. Para ello, se utilizan **gráficos de barras (bar plots)** y se agrupan las variables categóricas en **tres categorías principales**, lo que facilita la contextualización y organización del análisis:

-   **Contexto familiar y socioeconómico**: Variables que reflejan el entorno familiar y el nivel socioeconómico de los estudiantes.

-   **Acceso a recursos y actividades**: Variables que describen el acceso de los estudiantes a recursos educativos y su participación en actividades extracurriculares.

-   **Rendimiento y apoyo educativo**: Variables relacionadas con la motivación, el apoyo educativo y otros factores que pueden influir en el rendimiento de los estudiantes.

```{r}
barplot_chart_multiple <- function(df, var_names) {
  plots <- list()  # Lista para almacenar los gráficos
  
  for (var_name in var_names) {
    if (!(var_name %in% colnames(df))) {
      warning(paste("La variable", var_name, "no existe en el dataframe. Se omitirá."))
      next
    }
    
    dist_var <- as.data.frame(table(df[[var_name]]))
    colnames(dist_var) <- c(var_name, "Count")
    
    colors <- brewer.pal(n = min(nrow(dist_var), 9), name = "Pastel1")  
    
    p <- ggplot(dist_var, aes_string(x = var_name, y = "Count", fill = var_name)) +
      geom_bar(stat = "identity", color = "black") +
      scale_fill_manual(values = colors) +  
      theme_minimal() +
      labs(title = paste("Distribución de", var_name),
           x = var_name,
           y = "Frecuencia") +
      theme(legend.position = "none")  # Ocultar leyenda
    
    plots[[var_name]] <- p  # Guardamos el gráfico en la lista
  }
  
  if (length(plots) > 0) {
    grid.arrange(grobs = plots, ncol = min(length(plots), 2))  # Ajusta columnas dinámicamente
  } else {
    stop("No se generaron gráficos. Verifique los nombres de las variables.")
  }
}

```

```{r}
# Agrupación de variables relacionadas con el contexto familiar y socioeconómico
family_and_socioeconomic <- c("Parental_Involvement", "Family_Income", "Parental_Education_Level", "School_Type")

# Agrupación de variables relacionadas con el acceso a recursos y actividades
student_access <- c("Access_to_Resources", "Internet_Access", "Distance_from_Home")

# Agrupación de variables relacionadas con el rendimiento y el apoyo educativo
performance_and_support <- c("Motivation_Level", "Peer_Influence", "Learning_Disabilities", "Gender", "Extracurricular_Activities")
```

```{r}
barplot_chart_multiple(data,family_and_socioeconomic)
```

Respecto al **contexto familiar y socioeconómico**, la mayoría de los estudiantes reportan una **involucración media** de los padres en su educación, seguida de una involucración alta. Los *ingresos familiares* están equilibrados entre **niveles medios y bajos**. En cuanto al *nivel educativo de los padres*, la mayoría tiene estudios de **High School**, seguido de College, con una pequeña proporción alcanzando el Postgrado. Finalmente, predominan las **escuelas públicas**, que tienen más del doble de estudiantes que las privadas.

```{r}
barplot_chart_multiple(data,student_access)
```

En cuanto al acceso a recursos, la mayoría de los estudiantes tiene un **acceso medio-alto a los recursos** educativos. **Prácticamente todos los estudiantes cuentan con acceso a internet** y, en su mayoría, viven a una distancia **cercana o moderada** de su escuela.

```{r}
barplot_chart_multiple(data,performance_and_support)
```

Por último, observando las variables relacionadas con el **rendimiento y apoyo educativo**, se aprecia que los estudiantes presentan una *distribución variada* en cuanto a su motivación, influencia de los compañeros y posibles discapacidades de aprendizaje. La motivación, en su mayoría, se encuentra en niveles medios, lo que sugiere que los estudiantes tienen un interés moderado en sus estudios. En cuanto a la influencia de los compañeros, la mayoría de los estudiantes reporta una influencia positiva o neutral, lo que puede indicar un entorno social favorable para el aprendizaje. Además, una pequeña fracción de los estudiantes presenta discapacidades de aprendizaje, lo que podría influir en su rendimiento académico y requerir un análisis más profundo. Además, cabe recalcar que hay una mayor proporción de estudiantes masculinos en comparación con las femeninas, lo que podría generar sesgos en estudios posteriores sobre la influencia del género. Finalmente, más estudiantes participan en actividades extracurriculares que aquellos que no lo hacen.

### Análisis del Promedio de Calificaciones en Función de Variables Categóricas

Antes de analizar la relación entre las calificaciones de los estudiantes (`Previous_Scores`) y otras variables, es importante explorar cómo estas calificaciones varían según distintas características categóricas. A continuación, se presentan **gráficos de caja (boxplots)** que muestran el promedio de Previous_Scores en función de variables clave como la participación de los padres, el acceso a recursos, el nivel de motivación, el tipo de escuela.

```{r}
categoric_numeric_boxplot <- function(df, cat_var, num_var) {
  if (!(cat_var %in% colnames(df)) | !(num_var %in% colnames(df))) {
    stop("Una o ambas variables no existen en el dataframe.")
  }
  
  color_palette <- brewer.pal(min(length(unique(df[[cat_var]])), 9), "Pastel1")  

  p <- ggplot(df, aes_string(x = cat_var, y = num_var, fill = cat_var)) +
    geom_boxplot(outlier.colour = "red", outlier.shape = 16, outlier.size = 2) +  # Boxplot con outliers resaltados
    scale_fill_manual(values = color_palette) +  
    theme_minimal() +
    labs(title = paste("Distribución de", gsub("_", " ", num_var), "por", gsub("_", " ", cat_var)),
         x = gsub("_", " ", cat_var),
         y = gsub("_", " ", num_var)) +
    theme(plot.title = element_text(hjust = 0.5)) 
  
  print(p)
}

categoric_numeric_boxplot(data, "Parental_Involvement", "Previous_Scores")
categoric_numeric_boxplot(data, "Access_to_Resources", "Previous_Scores")
categoric_numeric_boxplot(data, "Motivation_Level", "Previous_Scores")
categoric_numeric_boxplot(data, "Extracurricular_Activities", "Previous_Scores")
categoric_numeric_boxplot(data, "School_Type", "Previous_Scores")
categoric_numeric_boxplot(data, "Gender", "Previous_Scores")
```

Los resultados obtenidos son las bastantes curiosos ya que los promedios de las calificaciones (`Previous_Scores`) son **prácticamente idénticos en todos los casos**, independientemente de las características categóricas como la participación de los padres, el acceso a recursos, el nivel de motivación, el tipo de escuela y el género. Esta uniformidad es sorprendente, ya que se esperaba que variables como la participación parental, el acceso a recursos o el tipo de escuela tuvieran algún tipo de impacto en las calificaciones.

A continuación, hacemos el mismo proceso pero para la calificación final de los estudiantes (`Exam_Score`):

```{r}
categoric_numeric_boxplot(data, "Parental_Involvement", "Exam_Score")
categoric_numeric_boxplot(data, "Access_to_Resources", "Exam_Score")
categoric_numeric_boxplot(data, "Motivation_Level", "Exam_Score")
categoric_numeric_boxplot(data, "Extracurricular_Activities", "Exam_Score")
categoric_numeric_boxplot(data, "School_Type", "Exam_Score")
categoric_numeric_boxplot(data, "Gender", "Exam_Score")
```

Existen varias explicaciones posibles para esta observación. Una posibilidad es que el conjunto de datos esté demasiado equilibrado (es decir es un **toy dataset**), de modo que las diferencias entre las categorías sean mínimas o se compensen entre sí. Otra explicación podría ser que el impacto de estas variables sobre las calificaciones **no sea tan directo o significativo como se pensaba inicialmente**. Tal vez factores más complejos o interactivos, como el tipo de estrategias de estudio, o incluso el contexto social del estudiante, tengan un papel más relevante en el rendimiento académico. Además, es posible que la variable Previous_Scores no esté capturando toda la variabilidad en el rendimiento académico, ya que hay otros factores que pueden influir en el desempeño de los estudiantes que no se están considerando en este análisis.

### Relación de variables respecto al Género

Respecto a la primera pregunta planteada en este estudio respecto a si se pueden agrupar a los estudiantes en una clase según sus características una de las primeras cosas que se nos pueden ocurrir ya que, en algunos colegios es una práctica común, es dividir las clases por género. Este enfoque plantea la pregunta de si las diferencias de género podrían influir en el desempeño académico o en otras características importantes de los estudiantes, lo que justificaría esta práctica.

Para estudiar esto más a fondo, vamos a observar las distribuciones de las variables clave como el tiempo dedicado al estudio, la participación en actividades extracurriculares, la motivación, y las calificaciones previas, agrupadas por el género del estudiante. Esto nos ayudará respecto a la primera pregunta de nuestro estudio, es decir, nos permitirá determinar si es posible segmentar a los estudiantes de manera más efectiva, tomando en cuenta el género como una variable que podría influir en su desempeño. Esto puede ser útil ya que se encuentran diferencias notables entre los géneros, podría ser útil dividir las clases por género para que se ajusten a las necesidades y características de cada grupo.

Antes que nada, recalcar que hemos observado anteriormente que los hombres representan un 57.8% del total de alumnos y las mujeres un 42.2% por lo que vamos a utilizar técnicas de ponderación para equilibrar las distribuciones de los géneros y asegurarnos de que el análisis no se vea sesgado por la mayor representación de un género sobre otro. Esto nos ayudará a identificar si, a pesar de las diferencias de representación entre hombres y mujeres, las tendencias de las variables clave, como las horas de estudio, la motivación y las calificaciones previas, se mantienen consistentes o si existen patrones diferenciados según el género.

Creamos una columna de ponderación llamada `weight_gender` que contiene los **pesos inversos** para los géneros. Como las mujeres representan el 42.2%, podemos asignarles un peso mayor, digamos 1.5 veces su valor real, y los hombres, con el 57.8%, tendrían un peso más bajo.

El peso para cada género lo calculamos de la siguiente manera:

-   **Peso para mujeres**: 57.8 / 42.2 ≈ 1.37
-   **Peso para hombres**: 42.2 / 57.8 ≈ 0.73

Una vez hecho esto, creamos gráficos de barras con las variables ponderadas por género.

```{r}
data$gender_weight <- ifelse(data$Gender == "Female", 1.37, 0.73)

create_Relation_With_Gender_Chart <- function(df, categorical_var) {
  if (!(categorical_var %in% colnames(df))) {
    stop("La variable principal no existe en el dataframe.")
  }
  if (!("Gender" %in% colnames(df))) {
    stop("La variable de agrupación no existe en el dataframe.")
  }
  
  ggplot(df, aes_string(x = categorical_var, fill = "Gender", weight = "gender_weight")) + 
    geom_bar(position = "dodge", color = "black") +  # Usar peso para ajustar las barras
    scale_fill_manual(values = c("pink", "cornflowerblue")) + 
    labs(title = paste("Distribución de", categorical_var, "agrupado por Gender"),
         x = categorical_var, 
         y = "Frecuencia ponderada",
         fill = "Gender") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))
}



create_Relation_With_Gender_Chart(data, "Sleep_Hours")
create_Relation_With_Gender_Chart(data, "Hours_Studied")
create_Relation_With_Gender_Chart(data, "Tutoring_Sessions")
create_Relation_With_Gender_Chart(data, "Previous_Scores")
create_Relation_With_Gender_Chart(data, "Exam_Score")
```

Si observamos las gráficas llegamos a que la conclusión que podemos obtener de este análisis, después de aplicar la ponderación para equilibrar la representación de hombres y mujeres, es que, a pesar de las diferencias en la proporción de género en el conjunto de datos, las mujeres tienden a tener un mayor rendimiento académico en varias áreas clave. Esto se refleja en su mayor número de horas de sueño, mayor dedicación al estudio y mayor participación en tutorías en comparación con los hombres. Además, las mujeres tienen calificaciones más altas, tanto en `Previous_Scores` como en `Exam_Score`.

Estos resultados nos plantean el debate de si es conveniente separar o agrupar a los estudiantes por género, ya que la evidencia sugiere que las mujeres pueden tener ciertas ventajas en cuanto a hábitos de estudio. Sin embargo, vamos a tener en cuenta otros factores que podrían influir en el rendimiento académico, como el entorno socioeconómico, la motivación, y el acceso a recursos educativos.

### Distribución Proporcional de Variables Categóricas por Tipo de Escuela

En este apartado, analizaremos la distribución de diversas variables categóricas, como la participación de los padres, el nivel socioeconómico y la calidad docente, entre otras, según el tipo de escuela (pública o privada). Para ello, utilizaremos **gráficos de barras apiladas (stacked bar charts)**, los cuales nos permitirán observar de manera clara la proporción de cada categoría dentro de estas variables para cada tipo de institución. Este enfoque nos ayudará a identificar posibles variaciones significativas entre los tipos de escuelas.

```{r}
stacked_barplot <- function(df, var_x, var_fill) {
  if (!(var_x %in% colnames(df)) | !(var_fill %in% colnames(df))) {
    stop("One or both variables do not exist in the dataframe.")
  }
  
  df[[var_x]] <- as.factor(df[[var_x]])
  df[[var_fill]] <- as.factor(df[[var_fill]])
  

  color_palette <- brewer.pal(3, "Pastel1")  
  
  p <- ggplot(df, aes_string(x = var_x, fill = var_fill)) +
    geom_bar(position = "fill") +
    scale_fill_manual(values = color_palette) + 
    theme_minimal() +
    labs(title = paste("Distribution of", var_fill, "by", var_x),
         x = var_x,
         y = "Proportion") +
    theme(plot.title = element_text(hjust = 0.5)) 
  
  print(p)
}

stacked_barplot(data, "School_Type", "Parental_Involvement")
stacked_barplot(data, "School_Type", "Family_Income")
stacked_barplot(data, "School_Type", "Teacher_Quality")
stacked_barplot(data, "School_Type", "Distance_from_Home")
stacked_barplot(data, "School_Type", "Peer_Influence")
stacked_barplot(data, "School_Type", "Motivation_Level")
```

Observamos que la proporción de todas las variables categóricas es **prácticamente idéntica** en ambos tipos de escuela, lo que sugiere que no existen diferencias sustanciales en la distribución de estas características entre las escuelas públicas y privadas. Esta falta de variación significativa podría indicar que factores como la participación de los padres, el nivel socioeconómico y la calidad docente **no están siendo influenciados de manera evidente por el tipo de institución educativa**.

### Análisis de la Asistencia en Función de Variables Categóricas

Después de analizar la relación entre distintas variables categóricas y las calificaciones de los estudiantes, observamos que no parecen influir significativamente en el rendimiento académico. Ahora, nos enfocaremos en estudiar si ciertos factores pueden estar relacionados con la **asistencia a clases**(`attendance`). Específicamente, analizaremos variables como la distancia desde el hogar a la escuela, el acceso a recursos, el nivel de ingresos familiares, la motivación y la influencia de los compañeros. Para ello, haremos uso de **boxplots** como hicimos anteriormente de modo que podremos visualizar si estas variables presentan variaciones significativas en la asistencia y detectar posibles tendencias o patrones.

```{r}
categoric_numeric_boxplot(data, "Distance_from_Home", "Attendance")
categoric_numeric_boxplot(data, "Access_to_Resources", "Attendance")
categoric_numeric_boxplot(data, "Family_Income", "Attendance")
categoric_numeric_boxplot(data, "Motivation_Level", "Attendance")
categoric_numeric_boxplot(data, "Peer_Influence", "Attendance")
```

Al igual que en el análisis de las calificaciones, observamos que las distintas variables categóricas no parecen tener un impacto significativo en el nivel de asistencia a clase. Sin embargo, si hay que destacar algún patrón, se percibe una ligera disminución en la asistencia entre los estudiantes que viven a una mayor distancia de la escuela (categoría "Far"), aunque la diferencia es mínima y no parece ser un factor determinante.

### Matriz de correlación

Por último, vamos a mostrar la matriz de correlación que nos permitirá visualizar la relación entre todas las variables del conjunto de datos. En este análisis, incluiremos tanto las variables numéricas como las categóricas (que previamente hemos convertido a valores numéricos o variables ordenadas).

```{r}
matriz_correlacion <- cor(df_cleaned)
matriz_melt <- melt(matriz_correlacion)

ggplot(data = matriz_melt, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name = "Correlación") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "Variables", y = "Variables", title = "Mapa de Calor de Correlación")
```

Al observar los resultados obtenidos de los modelos de análisis, vemos que `Hours_Studied` y `Attendance` resaltan como las características más importantes en la predicción del rendimiento de los estudiantes, de acuerdo con las puntuaciones de importancia normalizadas que se asignan a estas variables. Esto significa que:

-   **Hours_Studied**: Los modelos asignan una alta importancia a la cantidad de horas que un estudiante dedica al estudio, sugiriendo que, a medida que los estudiantes invierten más tiempo en estudiar, esto tiene una relación significativa con su rendimiento académico. Es decir, estudiar más suele estar vinculado a un mejor desempeño.

-   **Attendance**: Una mayor asistencia a las clases indica que el estudiante está más comprometido con su aprendizaje, lo cual suele reflejarse en mejores resultados académicos.

## Técnicas de resolución

En este apartado, comenzamos a aplicar técnicas de machine learning para abordar las dos preguntas planteadas inicialmente en el estudio. Después de realizar un exhaustivo proceso de preprocesamiento de datos, análisis exploratorio (EDA) y visualización, es momento de aplicar enfoques cuantitativos que nos permitan obtener respuestas más precisas y operativas a las siguientes cuestiones:

**1. ¿Se pueden agrupar a los estudiantes en una clase según sus características?**

Esta pregunta busca explorar la posibilidad de segmentar a los estudiantes en grupos homogéneos, basándonos en características clave como su rendimiento académico, participación, recursos disponibles, entre otros. Utilizaremos técnicas de agrupamiento (clustering) para identificar patrones y formar grupos significativos.

**2. ¿Cuántas horas de trabajo personal necesita un estudiante para obtener una alta calificación?**

Aquí nos enfocamos en determinar una relación predictiva entre el tiempo dedicado al estudio y las calificaciones obtenidas. Para ello, aplicaremos modelos de regresión que nos permitan estimar el número de horas de estudio necesarias para alcanzar un rendimiento académico sobresaliente.

Por tanto, con el empleo de esta técnicas vamos a generar modelos predictivos y descriptivos que aporten respuestas concretas y basadas en datos a las preguntas del estudio.

### Pregunta 1. ¿Se pueden agrupar a los estudiantes en una clase según sus características?

-   **Objetivo**: Intentar asignar a los alumnos a grupos de manera que se favorezca su aprendizaje.

En primer lugar, decidimos una estrategia a adoptar para agrupar a los alumnos. Nos enfocamos en diferentes variables según el objetivo a cumplir:

-   **Academic**: Nos interesamos en las variables que reflejan el éxito escolar en términos académicos, como la asistencia, el nivel de motivación en sus estudios, el número de horas de estudio o los resultados obtenidos. También tenemos en cuenta en este grupo las horas de sueño ya que consideramos que el sueño tiene una relación directa con el rendimiento académico (dormir lo suficiente está vinculado con una mejor concentración, memoria y desempeño en los exámenes)

-   **Support**: Aquí, el enfoque está en las necesidades de apoyo del alumno. ¿Necesita horas de tutoría? ¿Tiene dificultades para aprender? ¿Sus padres no se involucran lo suficiente en sus estudios?

-   **Resource**: ¿Dispone el alumno de los recursos necesarios para favorecer su aprendizaje?

-   **Social**: Variables relacionadas con el ocio y la vida social. ¿Tiene el alumno actividades extracurriculares? ¿Cuáles son sus relaciones de amistad?

-   **General**: Todas las variables. ¿Que grupos conforman estos datos?

**NOTA**: En relación con la variable `School_Type` (tipo de escuela, ya sea pública o privada), hemos observado en análisis previos que el tipo de colegio no muestra una relación significativa con el rendimiento académico de los estudiantes. Esto sugiere que, desde la perspectiva académica, la distinción entre escuelas públicas y privadas no influye de manera notable en las calificaciones o el desempeño escolar de los estudiantes. Además, desde el punto de vista de la pregunta central de este análisis, queremos agrupar a los estudiantes en clases según sus características para poder asignarlos a diferentes grupos que favorezcan su aprendizaje. Este proceso de agrupamiento se basa principalmente en características individuales de los estudiantes (como el número de horas de estudio, la asistencia a clases, la motivación, etc.), más que en el tipo de escuela al que asisten. Por lo tanto, no tiene sentido dividir a los estudiantes según su tipo de escuela (pública o privada) en este contexto, ya que el objetivo es organizar a los estudiantes en grupos que favorezcan su aprendizaje de manera independiente al tipo de colegio al que pertenecen.

```{r}
academic_columns <- c("Hours_Studied","Motivation_Level","Sleep_Hours", "Attendance", "Exam_Score", "Previous_Scores", "Previous_Scores_Category")
support_columns <- c("Learning_Disabilities", "Tutoring_Sessions", "Parental_Involvement")
resource_columns <- c("Family_Income", "Access_to_Resources", "Internet_Access", "Parental_Education_Level")
social_columns <- c("Extracurricular_Activities", "Physical_Activity", "Peer_Influence")
general_columns <- c(
  "Hours_Studied",
  "Attendance",
  "Parental_Involvement",
  "Access_to_Resources",
  "Extracurricular_Activities",
  "Sleep_Hours",
  "Previous_Scores",
  "Motivation_Level",
  "Internet_Access",
  "Tutoring_Sessions",
  "Family_Income",
  "Teacher_Quality",
  "Peer_Influence",
  "Physical_Activity",
  "Learning_Disabilities",
  "Parental_Education_Level",
  "Distance_from_Home",
  "Exam_Score"
)
```

```{r}
df_scaled = as_tibble(scale(df_cleaned))

data_for_cluster_academic <- select(df_scaled, all_of(academic_columns))
data_for_cluster_support <- select(df_scaled, all_of(support_columns))
data_for_cluster_resource <- select(df_scaled, all_of(resource_columns))
data_for_cluster_social <- select(df_scaled, all_of(social_columns))
data_for_cluster_general <- select(df_scaled, all_of(general_columns))
```

Para agrupar a los alumnos según estas categorías, utilizaremos el método de **clustering K-Means**.

Primero, definimos una función que nos permita seleccionar el mejor valor de **K**.

```{r}
compare_k <- function(df) {
  print(fviz_nbclust(df, kmeans, method = "wss") + 
    ggtitle("Elbow Method for Optimal K"))

  print(fviz_nbclust(df, kmeans, method = "silhouette") + 
    ggtitle("Silhouette Method for Optimal K"))
}
```

Luego, definimos una función que aplique el clustering y añada la variable **cluster** a nuestro conjunto de datos inicial.

```{r}
applying_kmeans <- function(data_for_clustering, k){
  set.seed(42)
  kmeans_model <- kmeans(data_for_clustering, centers = k, nstart = 25)
  df_with_cluster <- as_tibble(df_cleaned)
  df_with_cluster$Cluster <- as.factor(kmeans_model$cluster)
  return(df_with_cluster)
}
```

Finalmente, definimos una función que nos permita **comparar los grupos formados**:\
- ¿Cuántos alumnos hay en cada cluster?\
- Comparación de las variables utilizadas en el clustering mediante **ridgeline plots**.

```{r}
print_clustering_results <- function(df_with_clusters, data_for_cluster, columns_to_focus){
  cluster_summary <- df_with_clusters %>%
    group_by(Cluster) %>%
    summarise(
      Num_Students = n()
    )
  
  print(ggplot(cluster_summary, aes(x = as.factor(Cluster), y = Num_Students, fill = as.factor(Cluster))) +
          geom_bar(stat = "identity") +
          labs(title = "Number of Students in Each Cluster", x = "Cluster", y = "Student Count") +
          theme_minimal())
  
  for (column in columns_to_focus) {
    print(ggplot(df_with_clusters, aes(x = as.factor(Cluster), y = !!sym(column), fill = as.factor(Cluster))) +
            geom_boxplot() +
            labs(title = paste(column, "Distribution in Each Cluster"), x = "Cluster", y = column) +
            theme_minimal())
  }
  
  print(fviz_cluster(list(data = data_for_cluster, cluster = df_with_clusters$Cluster),
                     geom = "point",
                     ellipse.type = "convex",
                     ggtheme = theme_minimal(),
                     main = "Cluster Visualization (PCA Projection)"))
}

```

```{r}
find_optimal_clusters <- function(data) {
  set.seed(42)
  result <- NbClust(data, diss = NULL, distance = "euclidean", 
                    min.nc = 2, max.nc = 4, method = "kmeans")
  
  # Retorna el número óptimo de clusters sugerido
  return(result)
}
```

#### Academic

```{r}
compare_k(data_for_cluster_academic)
```

```{r}
optimal_clusters_academic <- find_optimal_clusters(data_for_cluster_academic)

```

Analizando las gráficas del método del Codo (Elbow Method) y del Coeficiente de Silhouette, llegamos a la conclusión de que el número óptimo de clústeres es 𝑘 = 2 k=2.

Esta conclusión se fundamenta en dos aspectos clave:

**Método del Codo (Elbow Method)**: En esta gráfica, observamos que la mayor reducción en la suma de cuadrados dentro del grupo ocurre hasta 𝑘 = 2 k=2, formando un punto de inflexión o "codo" en ese valor. A partir de 𝑘 = 2 k=2, la disminución en la varianza interna de los clústeres se vuelve menos pronunciada, lo que indica que agregar más clústeres no aporta una mejora significativa en la compactación de los datos.

**Coeficiente de Silhouette (Silhouette Method)**: Este método mide la calidad de la agrupación en función de la cohesión interna y la separación entre clústeres. En la gráfica correspondiente, el valor más alto del coeficiente de Silhouette se encuentra en 𝑘 = 2 k=2, lo que indica que, con este número de clústeres, los grupos están bien diferenciados y los puntos dentro de cada clúster son más homogéneos.

Basándonos en la evaluación de múltiples criterios de clustering mediante `NbClust`, el número óptimo de clusters en los datos es **2**, ya que recibió la mayor cantidad de votos. Esto sugiere que los datos tienen dos grupos bien diferenciados, lo que puede ser validado adicionalmente con métricas como el índice de silueta o gráficos de PCA

Dado que todos los métodos coinciden en que 𝑘 = 2 es el valor óptimo, podemos concluir que dividir los datos en dos grupos proporciona una segmentación adecuada, asegurando un equilibrio entre la reducción de la variabilidad interna y la claridad en la separación entre clústeres.

```{r}
df_cluster_academic <- applying_kmeans(data_for_cluster_academic, 2)
```

```{r}
print_clustering_results(df_cluster_academic, data_for_cluster_academic, academic_columns)
```

En los gráficos analizados se puede observar que la gran mayoría de las variables utilizadas presentan valores similares para ambos grupos o clústeres. Específicamente, variables como la cantidad de horas dedicadas al sueño y al estudio, la motivación, la asistencia a clases y la calificación en el examen final muestran distribuciones muy parecidas en ambos casos. Esto sugiere que estos factores no son determinantes a la hora de diferenciar los grupos de estudiantes.

Sin embargo, hay una variable que marca una diferencia clara entre los dos clústeres: las calificaciones previas. En este aspecto, se observa que en el clúster 1 se agrupan los estudiantes con mejores calificaciones previas, mientras que en el clúster 2 se encuentran aquellos con calificaciones más bajas.

Este resultado indica que el rendimiento académico previo es el factor más influyente en la segmentación de los estudiantes en estos grupos. Una posible interpretación es que las calificaciones previas pueden reflejar hábitos de estudio consolidados o diferencias en la comprensión de los contenidos a lo largo del tiempo, lo que termina impactando en la clasificación de los estudiantes.

En conclusión, aunque factores como el tiempo de estudio, la motivación y la asistencia son importantes en el desempeño académico, en este análisis en particular, la principal diferencia entre los grupos radica en las calificaciones previas. Esto refuerza la idea de que el rendimiento pasado es un buen predictor del rendimiento futuro y que los estudiantes con mejores antecedentes académicos tienden a mantenerse en un nivel más alto.

#### Support

```{r}
compare_k(data_for_cluster_support)
```

```{r}
optimal_clusters_support <- find_optimal_clusters(data_for_cluster_support)

```

La primera gráfica sigue el **método del codo**, el cual evalúa la suma de los cuadrados dentro de los clusters (WSS) en función del número de clusters. El punto óptimo se encuentra donde la disminución en WSS se vuelve menos pronunciada, formando un "codo" en la curva. En este caso, se observa un cambio notable en la pendiente alrededor de k=4 y k=8, lo que indica que estos valores podrían ser opciones razonables para segmentar los datos de manera eficiente.

Por otro lado, la segunda gráfica utiliza el **método del Silhouette** para determinar el número óptimo de clusters. En este método, se elige el valor de k que maximiza el índice de silhouette, el cual mide qué tan bien separados están los clusters y qué tan cohesivos son. En la gráfica, el valor más alto de silhouette se alcanza en k=8, lo que sugiere que este número de clusters permite una mejor separación entre los grupos y minimiza la superposición entre ellos.

Basándonos en la evaluación de múltiples criterios de clustering mediante `NbClust`, el número óptimo de clusters en los datos es **3**, ya que recibió la mayor cantidad de votos. Esto sugiere que los datos tienen cuatro grupos bien diferenciados, lo que puede ser validado adicionalmente con métricas como el índice de silueta o gráficos de PCA

En conclusión, aunque el método del codo sugiere que tanto k=4 como k=8 son buenas opciones, el método de Silhouette indica que k=8 ofrece la mejor separación entre clusters. Sin embargo, al aplicar el método de múltiples criterios, k=3 obtuvo la mayor cantidad de votos, superando a las demás opciones por 15 votos.

```{r}
df_cluster_support <- applying_kmeans(data_for_cluster_support, 3)
```

```{r}
print_clustering_results(df_cluster_support, data_for_cluster_support, support_columns)
```

En la siguiente visualización se pueden apreciar varios patrones interesantes en relación con la dificultad de aprendizaje, las sesiones de tutoría y el soporte parental.

En primer lugar, al analizar la variable de dificultad de aprendizaje, se observa que los clústeres 1 y 3 no presentan problemas significativos en este aspecto, mientras que el clúster 2 sí muestra dificultades. Esto indica que los estudiantes agrupados en el clúster 2 enfrentan mayores desafíos a la hora de comprender y asimilar los contenidos académicos en comparación con los otros dos grupos.

Si relacionamos este dato con la cantidad de horas dedicadas a sesiones de tutoría, encontramos que el clúster 3, a pesar de no presentar dificultades de aprendizaje, es el que más horas de tutoría registra. Esto sugiere que los estudiantes de este grupo utilizan la tutoría como una estrategia para mejorar aún más su rendimiento académico. Por otro lado, el clúster 2, que sí enfrenta problemas de aprendizaje, también recibe tutorías, pero en menor cantidad que el clúster 3. Este dato podría indicar que los estudiantes del clúster 2 deberían incrementar el tiempo dedicado a las sesiones de tutoría para poder superar sus dificultades y mejorar su desempeño académico.

Por último, al analizar el soporte parental, se obtiene un resultado homogéneo para los tres clústeres, ya que todos presentan un nivel de involucramiento familiar medio-alto. Esto significa que, independientemente de la dificultad de aprendizaje o el uso de tutorías, los estudiantes cuentan con un respaldo familiar relativamente favorable.

En conclusión, se observa que la dificultad de aprendizaje diferencia claramente al clúster 2, evidenciando la necesidad de estrategias de apoyo adicionales. Sin embargo, el uso de tutorías no siempre está ligado a dificultades académicas, ya que el clúster 3, sin problemas de aprendizaje, es el que más horas dedica a estas sesiones, posiblemente para mejorar su rendimiento. Por otro lado, el clúster 2, a pesar de enfrentar mayores dificultades, no es el que más tutorías recibe, lo que sugiere la importancia de fomentar su participación en estos espacios. Finalmente, el soporte parental es constante y estable en los tres clústeres, lo que indica que el respaldo familiar no varía significativamente según el desempeño académico o la necesidad de apoyo adicional.

#### Resources

```{r}
compare_k(data_for_cluster_resource)
```

```{r}
optimal_clusters_resources <- find_optimal_clusters(data_for_cluster_resource)
```

En la primera imagen, correspondiente al **método de Elbow**, se representa la suma de los cuadrados dentro del cluster (*Total Within Sum of Squares, WSS*) en función del número de clusters (*k*). Este método se basa en encontrar el punto donde la disminución de WSS empieza a desacelerarse de manera significativa, formando una especie de “codo” en la gráfica. En este caso, observamos que la curva muestra una reducción brusca hasta aproximadamente *k = 8*, después de lo cual la disminución de WSS se vuelve menos pronunciada. Esto sugiere que *k = 8* es un buen candidato para el número óptimo de clusters, ya que más allá de este punto la ganancia en términos de reducción de varianza dentro de los clusters es menor.

Por otro lado, en la segunda imagen se muestra el resultado del **método de Silhouette**, el cual mide la calidad de la agrupación en función de la cohesión interna y la separación entre los clusters. El objetivo es encontrar el valor de *k* que maximiza el ancho promedio del coeficiente de silueta, lo que indica que los puntos están bien agrupados dentro de sus respectivos clusters y bien separados de otros clusters. En esta gráfica, el valor más alto del coeficiente de silueta se observa en *k = 2*, lo que sugiere que dos clusters proporcionan la mejor separación según este criterio. Sin embargo, también se observa un valor elevado en *k = 8*, lo que indica que esta cantidad de clusters también es una opción viable.

Basándonos en la evaluación de múltiples criterios de clustering mediante `NbClust`, el número óptimo de clusters en los datos es **4**, ya que recibió la mayor cantidad de votos. Esto sugiere que los datos tienen cuatro grupos bien diferenciados, lo que puede ser validado adicionalmente con métricas como el índice de silueta o gráficos de PCA

El análisis de los diferentes métodos de clustering muestra resultados variados sobre la cantidad óptima de clusters. El método de **Elbow** sugiere que **k = 8** es una buena opción, ya que a partir de este punto la reducción de la varianza dentro de los clusters se desacelera significativamente. Por otro lado, el **método de Silhouette** indica que **k = 2** proporciona la mejor separación entre clusters, aunque también destaca **k = 8** como una alternativa viable. Sin embargo, el método de múltiples criterios de **NbClust** señala que **k = 4** es la mejor opción al haber recibido la mayor cantidad de votos, lo que sugiere la existencia de cuatro grupos bien diferenciados en los datos. Dado que NbClust integra varios enfoques de validación, se considera **k = 4** como el número óptimo de clusters, aunque los valores **k = 2 y k = 8** también pueden ser opciones a considerar dependiendo del criterio de segmentación que se priorice.

```{r}
df_cluster_resource <- applying_kmeans(data_for_cluster_resource, 4)
```

```{r}
print_clustering_results(df_cluster_resource, data_for_cluster_resource, resource_columns)
```

El análisis de la primera gráfica, correspondiente a los **ingresos familiares**, revela diversas diferencias entre los clústeres analizados. En términos generales, la mayoría de los grupos presentan ingresos de nivel medio, aunque existen algunas desviaciones significativas que reflejan desigualdades económicas dentro del conjunto de datos. En particular, los **clústeres 2 y 3** se sitúan dentro del rango de ingresos medios, pero con ciertas diferencias notables. El **clúster 2** muestra una mayor presencia de usuarios con ingresos **medios-bajos**, mientras que el **clúster 3** se inclina levemente hacia los **ingresos medios-altos**, aunque sin una diferencia muy pronunciada. En el caso del **clúster 1**, se observa una tendencia hacia ingresos **medios en su mayoría al alza**, sin presencia destacada de ingresos bajos. Sin embargo, el grupo con la situación económica más delicada es el **clúster 4**, que se distingue por presentar **ingresos íntegramente bajos** en comparación con los demás grupos.

Al relacionar estos hallazgos con la segunda gráfica, correspondiente al **acceso a recursos**, se observa que la mayoría de los clústeres tienen valores medios similares en cuanto a disponibilidad de recursos educativos. No obstante, existen algunas fluctuaciones, con ciertos casos que se inclinan hacia un acceso más limitado o, en otros, con mayores facilidades. Un hallazgo relevante es que, a pesar de que el **clúster 4** presenta los ingresos más bajos, su acceso a recursos no es significativamente menor, lo que sugiere la existencia de **programas de ayuda o becas** que compensan la falta de recursos económicos. Esto indica que, aunque las familias de este grupo tengan menos ingresos, han podido acceder a apoyos que mitigan las desigualdades.

En lo que respecta al **acceso a internet**, se evidencia que el **clúster 2** es el único grupo que presenta un valor negativo, es decir, una menor accesibilidad a la conectividad en comparación con el resto. Este dato plantea dos hipótesis posibles: una primera explicación sería que estas familias **no pueden permitirse el acceso a internet** debido a razones económicas; sin embargo, esta teoría resulta inconsistente si consideramos que el **clúster 4**, que cuenta con los ingresos más bajos, sí tiene acceso a internet. Por lo tanto, una hipótesis más plausible es que en el **clúster 2 las familias han restringido el uso de internet a sus hijos por decisión propia**, probablemente por razones educativas, de control parental o de valores familiares.

En cuanto al **nivel académico de los padres**, se observa que, en términos generales, la mayoría de los grupos presentan un nivel de educación secundaria. No obstante, existen diferencias entre los clústeres. El **clúster 1** se caracteriza por estar compuesto en su totalidad por padres con educación **secundaria**. El **clúster 2** también presenta una mayoría con educación secundaria, aunque con la particularidad de que algunos padres han alcanzado estudios **universitarios y de posgrado**. Por otro lado, el **clúster 4** cuenta principalmente con familias con formación en **educación secundaria y grados universitarios**, aunque sin un predominio de estudios avanzados. La situación más particular se encuentra en el **clúster 3**, donde los padres presentan un nivel de estudios **mínimo de grado universitario**, y en algunos casos, **estudios de posgrado**, lo que indica un nivel académico superior en comparación con el resto de los grupos.

El análisis realizado revela importantes diferencias socioeconómicas entre los clústeres analizados. Se ha identificado que el **clúster 4** es el grupo con menores ingresos, pero gracias a algún tipo de apoyo externo, ha podido mantener un acceso a recursos educativos similar al de los otros grupos. En cuanto a la **conectividad a internet**, el **clúster 2** es el único que presenta restricciones, lo que sugiere que la limitación se debe más a una decisión parental que a factores económicos. Respecto al **nivel educativo de los padres**, se observa que la mayoría han alcanzado la educación secundaria, aunque el **clúster 3 destaca por contar con padres con estudios universitarios y de posgrado en mayor proporción**. Estas diferencias pueden influir en el rendimiento académico y el acceso a oportunidades de aprendizaje, lo que subraya la importancia de analizar estos factores para diseñar estrategias de apoyo adecuadas para cada grupo.

#### Social

```{r}
compare_k(data_for_cluster_social)
```

```{r}
optimal_clusters_social <- find_optimal_clusters(data_for_cluster_social)
```

En el gráfico del **método del codo**, se observa que la "Suma de Cuadrados Dentro del Grupo" (**WSS**) disminuye considerablemente hasta aproximadamente k=3, k=4, momento en el cual la pendiente comienza a estabilizarse. Esto indica que a partir de estos valores, agregar más clusters genera una menor ganancia en la reducción de la variabilidad dentro de los grupos, sugiriendo que k=3 o k=4 son opciones razonables.

Por otro lado, el **método del silhouette** muestra que la mejor cohesión interna y separación entre los clusters se obtiene con k=2, lo que sugiere que dividir los datos en dos grupos maximiza la calidad de la segmentación.

Adicionalmente, el **análisis de múltiples criterios** también ha indicado que el número óptimo de clusters es k=2, ya que ha recibido la mayor cantidad de votos (**8 votos**), superando a k=3 y k=4, que han obtenido **5 votos** cada uno.

Los tres enfoques utilizados coinciden en que k=2 es la opción más sólida para la segmentación de los datos. Tanto el método del silhouette como el análisis de múltiples criterios refuerzan esta elección, indicando que dividir los datos en dos grupos proporciona la mejor cohesión y separación entre clusters. Aunque el método del codo sugería que k=3 o k=4 podrían ser alternativas razonables, la evidencia general respalda la elección de k=2 como el número óptimo de clusters en este caso.

```{r}
df_cluster_social <- applying_kmeans(data_for_cluster_social, 2)

```

```{r}
print_clustering_results(df_cluster_social, data_for_cluster_social, social_columns)
```

El análisis de los gráficos permite identificar distintos patrones en la relación entre la participación en **actividades extracurriculares**, la cantidad de **horas dedicadas a la actividad física** y la **influencia de los compañeros** en los alumnos. A través de la observación de estos datos, se pueden extraer conclusiones relevantes sobre cómo estas variables se relacionan entre sí y si tienen algún impacto en la vida social y académica de los estudiantes.

En el primer gráfico, correspondiente a la **realización de actividades extracurriculares**, se observa una diferencia clara entre los dos clústeres analizados. El **clúster 1** agrupa a aquellos alumnos que **no participan en actividades extraescolares**, mientras que el **clúster 2** representa a los estudiantes que sí realizan este tipo de actividades. Esta segmentación permite identificar una distinción clara en los hábitos de los alumnos con respecto a su tiempo fuera del entorno académico, lo que podría tener implicaciones en otros aspectos de su desarrollo personal y social.

En lo que respecta al **rango de horas dedicadas a la actividad física**, se observa que ambos clústeres presentan una distribución similar. Esto indica que la participación o no en actividades extracurriculares no tiene un impacto significativo en el tiempo que los estudiantes dedican a la práctica de ejercicio físico. Es decir, tanto los alumnos que realizan actividades extraescolares como los que no lo hacen mantienen hábitos de actividad física similares, lo que sugiere que otros factores, como la rutina diaria o el estilo de vida familiar, podrían ser más determinantes en este aspecto.

Por último, el análisis de la **influencia de los compañeros** muestra que ambos clústeres presentan una distribución equivalente en esta variable. Esto implica que la **realización de actividades extracurriculares no tiene un impacto significativo en el nivel de influencia que los compañeros ejercen sobre los estudiantes**. En otras palabras, la socialización y las dinámicas de grupo parecen mantenerse estables independientemente de si el alumno participa o no en actividades extracurriculares.

El análisis realizado revela que la participación en **actividades extracurriculares** es una característica diferenciadora entre los clústeres, pero no parece influir en otras variables como la **cantidad de horas dedicadas a la actividad física** ni en el **nivel de influencia de los compañeros**. La similitud en la distribución de estas últimas variables sugiere que la actividad extracurricular no es un factor determinante en los hábitos de ejercicio ni en la socialización de los alumnos. Por lo tanto, la decisión de realizar o no actividades extracurriculares podría estar más relacionada con factores personales o familiares que con un impacto significativo en la vida social o los hábitos de los estudiantes.

#### General

```{r}
compare_k(data_for_cluster_general)
```

```{r}
optimal_clusters_general <- find_optimal_clusters(data_for_cluster_general)
```

Por otro lado, el **método del silhouette** muestra que la mejor cohesión interna y separación entre los clusters se obtiene con k=2, lo que sugiere que dividir los datos en dos grupos maximiza la calidad de la segmentación.

Adicionalmente, el **análisis de múltiples criterios** también ha indicado que el número óptimo de clusters es k=2, ya que ha recibido la mayor cantidad de votos (**8 votos**), superando a k=3 y k=4, que han obtenido **5 votos** cada uno.

Los tres enfoques utilizados coinciden en que k=2 es la opción más sólida para la segmentación de los datos. Tanto el método del silhouette como el análisis de múltiples criterios refuerzan esta elección, indicando que dividir los datos en dos grupos proporciona la mejor cohesión y separación entre clusters. Aunque el método del codo sugería que k=3 o k=4 podrían ser alternativas razonables, la evidencia general respalda la elección de k=2 como el número óptimo de clusters en este caso.

```{r}
df_cluster_general <- applying_kmeans(data_for_cluster_general, 2)
```

```{r}
print_clustering_results(df_cluster_general, data_for_cluster_general, general_columns)
```

El `Cluster 2` se caracteriza por una mayor dedicación al estudio, con un rango de entre **19 y 26 horas semanales**, en contraste con el `Cluster 1`, que estudia entre **14 y 23 horas**. Además, los estudiantes del Cluster 2 presentan una **mayor asistencia a clases**, con un porcentaje de entre **83% y 95%**, mientras que en el Cluster 1 este valor es menor, oscilando entre **65% y 78%**. Este dato indica una mayor constancia y compromiso con la formación académica por parte del Cluster 2.

A pesar de estas diferencias en el tiempo dedicado al estudio y la asistencia, el rendimiento académico no sigue una correlación directa. Las **notas anteriores al examen son ligeramente superiores en el Cluster 2** (entre 6,5 y 8,9) en comparación con el Cluster 1 (entre 6,2 y 8,7), lo que sugiere que los estudiantes del segundo grupo han mostrado un desempeño más constante en las evaluaciones previas. Sin embargo, en la evaluación final, el resultado se invierte: el Cluster 1 obtiene una nota media de 7, mientras que el Cluster 2 alcanza una media inferior de 6,5.

En términos de **acceso a recursos**, ambos clústeres cuentan con **condiciones similares**. El acceso a materiales educativos es clasificado como Medio en el Cluster 1 y Medio Alto en el Cluster 2, lo que indica que, si bien el segundo grupo dispone de un ligero mejor acceso, las diferencias no son marcadas. Asimismo, en lo referente a las **sesiones de tutoría**, el `Cluster 1` recibe entre **0 y 2 horas semanales**, mientras que el `Cluster 2` recibe entre **1 y 2 horas**, lo que puede haber contribuido a su mejor desempeño en las notas previas, aunque sin un impacto claro en la evaluación final.

Desde el punto de vista socioeconómico, **ambos grupos provienen de familias con ingresos medio bajos**, lo que sugiere que **el rendimiento académico no está condicionado por la situación económica**. Además, el tipo de colegio al que asisten es tanto público como privado, y la **influencia de los compañeros** en el proceso de aprendizaje es catalogada como **media alta en ambos casos**, lo que indica que las diferencias en desempeño no pueden explicarse por estos factores.

Otros aspectos como **la actividad física, la presencia de problemas de aprendizaje y el nivel educativo de los padres** tampoco muestran variaciones significativas entre los clústeres. Ambos grupos realizan entre 2 y 4 horas de ejercicio a la semana, no presentan problemas de aprendizaje y tienen padres con estudios secundarios y algunos universitarios. Además, **todos los estudiantes cuentan con acceso a internet**, lo que elimina este factor como una posible barrera en su proceso educativo.

A partir de estos datos, se pueden extraer varias conclusiones importantes. A pesar de que el `Cluster 2` se muestra más comprometido con el estudio, dedica más horas a la preparación académica, tiene mayor asistencia y recibe más apoyo en tutorías, **su calificación final es inferior a la del** `Cluster 1`.

Esto podría indicar que **la cantidad de tiempo invertido en el estudio no siempre es el factor más determinante en el rendimiento, sino que la calidad del estudio y las estrategias utilizadas pueden desempeñar un papel más relevante**.

Asimismo, el hecho de que el `Cluster 1` obtenga mejores resultados finales sugiere que estos estudiantes pueden tener una **mayor eficiencia en el aprendizaje o en la aplicación de los conocimientos adquiridos en los exámenes**. También es posible que el desempeño del `Cluster 2` se vea afectado por otros factores no reflejados en la tabla, como el manejo del estrés en evaluaciones finales, la metodología de estudio o diferencias en la forma en que asimilan la información.

En general, el análisis sugiere que **el éxito académico no depende exclusivamente de la cantidad de horas dedicadas al estudio o la asistencia a clases**, sino que puede estar influenciado por la capacidad de los estudiantes para optimizar su aprendizaje y aplicar eficazmente sus conocimientos en situaciones evaluativas clave.

### Pregunta 2. ¿Cuáles son los factores clave que determinan si un estudiante mejorará su rendimiento académico?

#### Introducción

Análisis del Desempeño Académico y Factores que Influyen en la Mejora del Estudiante.

El rendimiento académico de los estudiantes es un aspecto crucial para el éxito educativo y profesional. Identificar qué factores influyen en la mejora de las calificaciones es fundamental para que las instituciones educativas puedan diseñar estrategias efectivas que optimicen el aprendizaje y reduzcan la brecha de rendimiento entre los estudiantes.

Diversos estudios han demostrado que factores como la asistencia a clase, la calidad del profesorado, el apoyo parental y las horas de estudio pueden impactar significativamente en el desempeño académico. Sin embargo, estas relaciones no siempre son lineales ni fáciles de modelar mediante métodos estadísticos tradicionales. Por ello, en este estudio aplicamos técnicas de aprendizaje automático para analizar el impacto de múltiples variables en la mejora del rendimiento académico, permitiendo descubrir patrones complejos que pueden no ser evidentes en análisis convencionales.

El objetivo de este trabajo es determinar qué factores son clave para predecir la mejora en el rendimiento académico de los estudiantes. Para ello, utilizamos modelos de clasificación basados en árboles de decisión, que ofrecen interpretabilidad y permiten extraer reglas claras para la toma de decisiones en entornos educativos. Dado que las variables del conjunto de datos no presentaban una correlación lineal significativa entre sí, descartamos métodos estadísticos tradicionales y optamos por enfoques de aprendizaje supervisado, los cuales son más adecuados para detectar relaciones no lineales y jerárquicas entre los factores analizados.

#### Preparación y Exploración de Datos

Se parte de un conjunto de datos estructurado con múltiples variables relacionadas con el desempeño académico de los estudiantes, incluyendo horas de estudio, asistencia, nivel de motivación, acceso a recursos, entre otros. Concretamente para responder a esta pregunta se usará el conjunto de datos ya preprocesado **"df_cleaned"**.

Para entender mejor la distribución de las calificaciones, se generaron histogramas de Exam_Score y Previous_Scores:

#### Visualización de la Distribución de Calificaciones

Objetivo: Entender la distribución de las calificaciones actuales (Exam_Score) y previas (Previous_Scores) para determinar si son adecuadas como variables objetivo.

```{r}
df <- read.csv("data/df_cleaned.csv")
# Distribución de Exam_Score
ggplot(df_cleaned, aes(x = Exam_Score)) +
  geom_histogram(bins = 20, fill = "blue", alpha = 0.7) +
  labs(title = "Distribución de Exam_Score", x = "Exam Score", y = "Frecuencia")

# Distribución de Previous_Scores
ggplot(df_cleaned, aes(x = Previous_Scores)) +
  geom_histogram(bins = 20, fill = "red", alpha = 0.7) +
  labs(title = "Distribución de Previous_Scores", x = "Previous Scores", y = "Frecuencia")

```

`Exam_Score` tiene **poca variabilidad**, con la mayoría de los estudiantes en el rango de **60 a 75 puntos**. `Previous_Scores` tiene una distribución más uniforme, lo que sugiere que podría ser una mejor variable predictora. Debido a la baja variabilidad en Exam_Score, utilizarlo directamente como variable objetivo podría no ser eficaz. Por ello, decidimos crear una variable categórica que represente mejor el rendimiento académico.

### Modelo Predictivo

El objetivo del modelo será predecir según distintos factores, si el alumno mejorará su rendimiento o no.

Para ello, se creará una nueva variable 'Improved', que tomará valor 1 si el alumno ha mejorado la calificación en 'Exam_Score' respecto a la 'Previous_Score'.

```{r}
# Crear la variable Improved (1 si Exam_Score > Previous_Scores, 0 si no)
df_cleaned$Improved <- ifelse(df_cleaned$Exam_Score > df_cleaned$Previous_Scores, 1, 0)

# Ver distribución
table(df_cleaned$Improved)

prop.table(table(df_cleaned$Improved))
```


| Clase             | Frecuencia | Proporción |
|-------------------|------------|------------|
| **No Mejoró (0)** | 4305       | 67.50%     |
| **Mejoró (1)**    | 2073       | 32.50%     |

Aproximadamente el 32.5% de los estudiantes mejoraron su calificación, mientras que el 67.5% no lo hicieron.

Esta variable será nuestra variable objetivo para predecir la mejora en el rendimiento académico.

#### Preparación del Conjunto de Datos para el Modelo

En este apartado se limpia el conjunto de datos eliminando variables redundantes y preparando los datos para el modelado.

```{r}
# Eliminar una de las variables dummies para evitar multicolinealidad
# Eliminar variables dummies redundantes
df_model <- df_cleaned %>%
  select(-School_Type_Public, -Gender_Female, -Exam_Score, -Previous_Scores, -Previous_Scores_Category)

# Convertir 'Improved' a factor
df_model$Improved <- as.factor(df_model$Improved)

```

Eliminamos variables dummies redundantes para evitar multicolinealidad.

Eliminamos Exam_Score y Previous_Scores porque Improved es una variable derivada de ellas. Incluir estas variables en el modelo podría causar problemas de fugas de datos, ya que el modelo estaría aprendiendo directamente de la respuesta en lugar de los factores explicativos

Convertimos 'Improved' a factor para su uso en modelos de clasificación.

#### División del Conjunto de Datos

Con 'createDataPartition' mantenemos la proporcion de las clases en 'trainData' y 'testData', evitando que alguna clase quede sobre o subrepresentada en el conjunto de prueba.

```{r}
set.seed(42)
trainIndex <- createDataPartition(df_model$Improved, p = 0.7, list = FALSE)
trainData <- df_model[trainIndex, ]
testData <- df_model[-trainIndex, ]

# Verificar distribución de clases
prop.table(table(trainData$Improved))
prop.table(table(testData$Improved))

```

| Clase             | Entrenamiento | Proporción | Prueba | Proporción |
|-------------------|---------------|------------|--------|------------|
| **No Mejoró (0)** | 4303          | 67.49%     | 2002   | 67.52%     |
| **Mejoró (1)**    | 2073          | 32.51%     | 965    | 32.48%     |

Como puede observarse la distribución de clases se mantiene consistente en ambos conjuntos, lo cual es importante para obtener un modelo representativo.

Con ello aseguramos que 'testData' represente fielmente la realidad y así evaluar el modelo en datos reales y desbalanceados.

El conjunto de datos estaba desbalanceado, con solo el 32.5% de los estudiantes mejorando su calificación. Esto podría hacer que el modelo se incline a predecir siempre ‘No mejoró’. Para evitar este problema, aplicamos submuestreo (downSample()) para equilibrar las clases y mejorar la capacidad del modelo para detectar patrones en ambas clases.

```{r}
# Submuestreo de la clase mayoritaria
set.seed(42)
trainData_balanced <- downSample(x = trainData %>% select(-Improved), y = trainData$Improved)

# Verificar nueva distribución
table(trainData_balanced$Class)

```

| Clase             | Frecuencia después del Submuestreo |
|-------------------|------------------------------------|
| **No Mejoró (0)** | 1452                               |
| **Mejoró (1)**    | 1452                               |

Al aplicar submuestreo de la clase mayoritaria (0 - no mejoró), se equilibran las clases en el conjunto de entrenamiento. Esto permitirá que el modelo aprenda de ambas clases por igual.

#### Entrenamiento de Random Forest

Configuramos el control de entrenamiento con validacion cruzada repetida:

```{r}
# Configurar control de entrenamiento
control <- trainControl(method = "repeatedcv", number = 5, repeats = 3)

```

Utilizamos 5 particiones (folds) repetidas 3 veces para obtener una estimación más estable del rendimiento del modelo.

Además de entrenar el modelo n = 500, calcularemos la importancia de variables.

```{r}
# Entrenar el modelo Random Forest
set.seed(42)
rf_model <- train(
  Class ~ ., 
  data = trainData_balanced,
  method = "rf",
  trControl = control,
  importance = TRUE,
  ntree = 500
)

```

#### Evaluación

```{r}
# Realizar predicciones
predictions <- predict(rf_model, newdata = testData)

# Ver matriz de confusión
conf_mat <- confusionMatrix(predictions, testData$Improved, positive = "1")

# Mostrar resultados
print(conf_mat)

```

-   Accuracy (Precisión): El modelo tiene una precisión del 53,92%.

-   Sensitivity (Sensibilidad): El 52.33% de los estudiantes que mejoraron fueron correctamente identificados.

-   Specificity (Especificidad): El 54,69% de los estudiantes que no mejoraron fueron correctamente identificados.

-   Kappa: Valor de 0.0626, sugiere un bajo nivel de acuerdo entre la predicción del modelo y la realidad, indicando que el modelo no está logrando una clasificación efectiva más allá del azar.

La sensibilidad y especificidad son bajas, lo que significa que el modelo no diferencia bien entre los estudiantes que mejoraron y los que no. El modelo tiene un bajo rendimiento, con una precisión cercana al azar (\~54%), lo que indica que no está capturando bien los patrones en los datos.

#### Evaluación con xgboost

```{r}
set.seed(42)
xgb_model <- train(
  Class ~ ., 
  data = trainData_balanced,
  method = "xgbTree",
  trControl = control,
  tuneGrid = expand.grid(
    nrounds = 100,  # Número de iteraciones, en lugar de usar ntree_limit
    max_depth = 6,
    eta = 0.3,
    gamma = 0,
    colsample_bytree = 1,
    min_child_weight = 1,
    subsample = 1
  )
)

# Evaluar desempeño sin warnings
suppressWarnings({
  xgb_pred <- predict(xgb_model, newdata = testData)
  conf_mat_xgb <- confusionMatrix(xgb_pred, testData$Improved, positive = "1")
})

# Comparar métricas
print(conf_mat_xgb)

```

-   Accuracy (Precisión): El modelo tiene una precisión del 51,31%.

-   Sensitivity (Sensibilidad): El 49.11% de los estudiantes que mejoraron fueron correctamente identificados.

-   Specificity (Especificidad): El 52,36% de los estudiantes que no mejoraron fueron correctamente identificados.

-   Kappa: Valor de 0.0131, sugiere un bajo nivel de acuerdo entre la predicción del modelo y la realidad, indicando que el modelo no está logrando una clasificación efectiva más allá del azar.

La sensibilidad y especificidad son bajas, lo que significa que el modelo no diferencia bien entre los estudiantes que mejoraron y los que no. El modelo tiene un bajo rendimiento, con una precisión cercana al azar (\~51%), lo que indica que no está capturando bien los patrones en los datos.

#### Comparación de Modelos

| Métrica               | Random Forest | XGBoost |
|-----------------------|---------------|---------|
| **Accuracy**          | 53.92%        | 51.31%  |
| **Sensitivity**       | 52.33%        | 49.11%  |
| **Specificity**       | 54.69%        | 52.36%  |
| **Kappa**             | 0.0626        | 0.0131  |
| **Balanced Accuracy** | 53.51%        | 50.74%  |

-   Random Forest obtiene una mejor precisión global (53.92%) en comparación con XGBoost (51.31%). Aunque la diferencia no es grande, XGBoost tiene un rendimiento más cercano al azar.

-   XGBoost muestra peores resultados en la detección de estudiantes que mejoran (sensibilidad 49.11% vs. 52.33% en RF), lo que significa que tiene más dificultad para identificar correctamente a los estudiantes que efectivamente mejoraron su rendimiento.

-   El coeficiente Kappa de XGBoost es muy bajo (0.0131), indicando que su capacidad de clasificación es prácticamente aleatoria. Esto sugiere que el modelo no está logrando captar patrones significativos en los datos.

-   Ambos modelos presentan dificultades para diferenciar correctamente a los estudiantes que mejoran y los que no.

#### Calcular AUC y curva ROC

```{r}
# Calcular probabilidades de predicción
prob_predictions <- predict(rf_model, newdata = testData, type = "prob")

# Calcular AUC
library(pROC)
roc_obj <- roc(testData$Improved, prob_predictions[, "1"])
auc_value <- auc(roc_obj)
print(paste("AUC:", auc_value))

# Graficar la curva ROC
plot.roc(roc_obj, main = "Curva ROC - Random Forest")

```

-   Eje X (1 - Especificidad): Representa la tasa de falsos positivos (cuando el modelo predice erróneamente que un estudiante mejoró).
-   Eje Y (Sensibilidad): Representa la tasa de verdaderos positivos (cuando el modelo predice correctamente que un estudiante mejoró).
-   Línea diagonal (gris): Representa una predicción aleatoria (AUC = 0.5).
-   La curva negra: Está muy cerca de la diagonal, lo que indica que el modelo no está realizando predicciones significativamente mejores que el azar.

Conclusión: - Un modelo bueno debería tener una curva más inclinada hacia la esquina superior izquierda, indicando una alta tasa de verdaderos positivos y una baja tasa de falsos positivos. - En este caso, la curva sigue muy de cerca la diagonal, lo que sugiere que el modelo no tiene una buena capacidad predictiva.

#### Importancia de Variables

Usando el mejor (Random Forest) y una vez validado el modelo, vamos a determinar cuales son las variables mas importantes que influyen en la predicción de la mejora del estudiante. 

```{r}
# Importancia de variables
var_imp <- varImp(rf_model)
plot(var_imp, top = 11, main = "Importancia de Variables")


```

-   Attendance (Asistencia): Es la variable más importante, lo que sugiere que los estudiantes con mayor asistencia tienen más probabilidades de mejorar su rendimiento.
-   Teacher_Quality (Calidad del Profesorado): Indica que la calidad del docente impacta significativamente en el aprendizaje y en la mejora del estudiante.
-   Hours_Studied (Horas de Estudio): Aunque es importante, su impacto es menor que la asistencia y la calidad docente, lo que sugiere que ir a clases y recibir una buena enseñanza es más relevante que solo estudiar muchas horas.

#### Arbol de decision

Una vez vistas las variables mas importantes, a continuación se construirá un árbol de decisión usando dichas variables. 

```{r}
# Instalar paquetes si no están instalados
if (!require("rpart")) install.packages("rpart", dependencies=TRUE)
if (!require("rpart.plot")) install.packages("rpart.plot", dependencies=TRUE)
if (!require("caret")) install.packages("caret", dependencies=TRUE)

# Cargar las librerías necesarias para construir y visualizar un Árbol de decisión
library(rpart)
library(rpart.plot)
library(caret)

```

-   Se seleccionan las variables más importantes identificadas previamente en el análisis de importancia de variables.
-   Estas variables serán usadas para construir el Árbol de Decisión.

```{r}
# Definir las variables más importantes según análisis previo
important_vars <- c("Attendance", "Teacher_Quality", "Hours_Studied", 
                    "Parental_Involvement", "Peer_Influence", 
                    "Tutoring_Sessions", "Distance_from_Home", "Motivation_Level", 
                    "Internet_Access", "Parental_Education_Level", "Extracurricular_Activities")

```

-   Se define X (las variables predictoras) y y (la variable objetivo Improved).
-   Se divide el conjunto de datos en 70% entrenamiento y 30% prueba manteniendo la proporción original de clases.

```{r}
# Definir la variable objetivo y las variables predictoras
X <- df_cleaned[, important_vars]
y <- df_cleaned$Improved

# Dividir en conjunto de entrenamiento (70%) y prueba (30%)
set.seed(42)
trainIndex <- createDataPartition(y, p = 0.7, list = FALSE)
trainData <- df_cleaned[trainIndex, ]
testData  <- df_cleaned[-trainIndex, ]

```

-   Entrenamos el Árbol de decisión
-   minsplit = 5 - Un nodo necesita al menos 5 observaciones para dividirse.
-   maxdepth = 8 - Limita la profundidad del árbol para evitar que sea demasiado complejo.

```{r}
# Entrenar el Árbol de Decisión con hiperparámetros ajustados
tree_model <- rpart(Improved ~ ., 
                    data = trainData[, c(important_vars, "Improved")], 
                    method = "class", 
                    control = rpart.control(cp = 0.001, minsplit = 5, maxdepth = 8))

```

-   Genera predicciones en el conjunto de prueba usando el modelo entrenado.
-   type = "class" asegura que la salida sean clases binarias (0 o 1) y no probabilidades.

```{r}
# Hacer predicciones con los datos de prueba
tree_pred <- predict(tree_model, newdata = testData, type = "class")

```

```{r}
# Calcular precisión del modelo
tree_accuracy <- mean(tree_pred == testData$Improved)

# Crear matriz de confusión
tree_conf_matrix <- table(Predicho = tree_pred, Real = testData$Improved)

# Imprimir resultados
print(paste("Precisión del Árbol Mejorado:", round(tree_accuracy * 100, 2), "%"))
print("Matriz de Confusión:")
print(tree_conf_matrix)

```

| **Métrica**                   | **Valor** |
|-------------------------------|-----------|
| **Precisión (Accuracy)**      | 66.13%    |
| **Verdaderos Negativos (TN)** | 1227      |
| **Falsos Positivos (FP)**     | 78        |
| **Verdaderos Positivos (TP)** | 38        |
| **Falsos Negativos (FN)**     | 570       |

-   Tenemos un rendimiento moderado(66.13%).
-   Clase 0 (No mejoró):
    -   1227 casos fueron correctamente clasificados (verdaderos negativos).
        -   78 casos fueron mal clasificados como que sí mejoraron (falsos positivos).
-   Clase 1 (Mejoró):
    -   38 casos fueron correctamente identificados como que mejoraron (verdaderos positivos).
    -   570 casos fueron mal clasificados como que no mejoraron (falsos negativos).

## Visualización

```{r}
# Visualizar el Árbol de Decisión Optimizado con mejores ajustes
rpart.plot(tree_model, 
           type = 2,  # Mostrar etiquetas en nodos
           extra = 104,  # Mostrar porcentaje de datos en cada nodo
           box.palette = "RdYlGn",  # Mejores colores para diferenciar clases
           tweak = 0.5,  # Ajustar tamaño del árbol
           cex = 0.65,  # Reducir tamaño de fuente para evitar sobrecarga
           fallen.leaves = TRUE,  # Mejor alineación de nodos terminales
           main = "Árbol de Decisión Optimizado con Variables Clave")

```

El primer nodo del árbol indica que la asistencia (Attendance) es el factor más determinante en la mejora académica. Esto significa que la asistencia es el factor más relevante para predecir si un estudiante mejorará o no su rendimiento.

En los siguientes niveles del árbol, variables como calidad docente (Teacher_Quality), horas de estudio (Hours_Studied), y nivel educativo de los padres (Parental_Education_Level) aparecen como factores clave en la clasificación.

-   Patrones de Mejora y No Mejora
    -   Nodos en verde: Representan grupos de estudiantes con alta probabilidad de mejora.
    -   Nodos en rojo: Representan estudiantes con baja probabilidad de mejora, lo que indica que las condiciones previas en esas ramas no favorecen el rendimiento académico.
    -   Nodos en amarillo: Representan puntos de decisión en los que todavía existen condiciones mixtas que pueden influir en el resultado final.
-   Interpretación de los Resultados
    -   Si un estudiante tiene alta asistencia y cuenta con buen apoyo parental, su probabilidad de mejora es mayor.
    -   Sin embargo, si un estudiante tiene baja asistencia, pocas horas de estudio y menor acceso a recursos educativos, es menos probable que mejore.

```{r}
print(tree_model)
```
Para mejorar el entendimiento pueden observarse las siguientes reglas:


```{r}
# Función para extraer las reglas del árbol
extract_rules <- function(tree_model) {
  path <- path.rpart(tree_model, nodes = as.numeric(row.names(tree_model$frame)))
  return(path)
}

# Aplicar la función y mostrar reglas
rules <- extract_rules(tree_model)
rules

```

* Nodo: Identificador del nodo en el árbol.
* División: Variable utilizada para dividir los datos en cada nodo.
* n: Cantidad de observaciones en el nodo.
* Pérdida: Número de observaciones mal clasificadas en ese nodo.
* Clase Predicha: Clase dominante en el nodo (0 o 1).
* Probabilidad (0,1): Distribución de probabilidades de cada clase.
Los nodos marcados con * son terminales, es decir, ya no se dividen más en el árbol de decisión.


| Nodo | División | n | Pérdida | Clase Predicha | Probabilidad (0,1) |
|------|----------|----|---------|---------------|---------------------|
| 1    | Raíz    | 4465 | 1465 | 0 | (0.6719, 0.3281) |
| 2    | Attendance < 79.5 | 2144 | 578 | 0 | (0.7304, 0.2696) * |
| 3    | Attendance >= 79.5 | 2321 | 887 | 0 | (0.6178, 0.3822) |
| 6    | Parental_Involvement < 2.5 | 1627 | 579 | 0 | (0.6441, 0.3559) |
| 12   | Attendance < 86.5 | 529 | 165 | 0 | (0.6881, 0.3119) * |
| 13   | Attendance >= 86.5 | 1098 | 414 | 0 | (0.6230, 0.3770) |
| 26   | Teacher_Quality < 1.5 | 123 | 33 | 0 | (0.7317, 0.2683) |
| 52   | Parental_Education_Level < 1.5 | 61 | 10 | 0 | (0.8361, 0.1639) |
| 104  | Tutoring_Sessions >= 1.5 | 25 | 1 | 0 | (0.9600, 0.0400) * |
| 105  | Tutoring_Sessions < 1.5 | 36 | 9 | 0 | (0.7500, 0.2500) |
| 210  | Attendance < 96.5 | 31 | 5 | 0 | (0.8387, 0.1613) * |
| 211  | Attendance >= 96.5 | 5 | 1 | 1 | (0.2000, 0.8000) * |
| 53   | Parental_Education_Level >= 1.5 | 62 | 23 | 0 | (0.6290, 0.3710) |
| 214  | Hours_Studied < 26.5 | 35 | 13 | 0 | (0.6286, 0.3714) |
| 428  | Attendance < 95.5 | 20 | 4 | 0 | (0.8000, 0.2000) * |
| 429  | Attendance >= 95.5 | 15 | 6 | 1 | (0.4000, 0.6000) * |
| 215  | Hours_Studied >= 26.5 | 7 | 1 | 1 | (0.1429, 0.8571) * |
| 27   | Teacher_Quality >= 1.5 | 975 | 381 | 0 | (0.6092, 0.3908) |
| 54   | Motivation_Level < 1.5 | 278 | 94 | 0 | (0.6619, 0.3381) |
| 218  | Hours_Studied < 18.5 | 104 | 28 | 0 | (0.7308, 0.2692) * |
| 219  | Hours_Studied >= 18.5 | 150 | 65 | 0 | (0.5667, 0.4333) |
| 438  | Peer_Influence >= 2.5 | 67 | 20 | 0 | (0.7015, 0.2985) * |
| 439  | Peer_Influence < 2.5 | 83 | 38 | 1 | (0.4578, 0.5422) * |
| 7    | Parental_Involvement >= 2.5 | 694 | 308 | 0 | (0.5562, 0.4438) |
| 14   | Hours_Studied < 29.5 | 648 | 280 | 0 | (0.5679, 0.4321) |
| 28   | Distance_from_Home >= 2.5 | 62 | 19 | 0 | (0.6935, 0.3065) |
| 56   | Attendance >= 83.5 | 53 | 14 | 0 | (0.7358, 0.2642) * |
| 57   | Attendance < 83.5 | 9 | 4 | 1 | (0.4444, 0.5556) |
| 115  | Attendance >= 80.5 | 7 | 2 | 1 | (0.2857, 0.7143) * |
| 15   | Hours_Studied >= 29.5 | 46 | 18 | 1 | (0.3913, 0.6087) |
| 30   | Extracurricular_Activities < 0.5 | 13 | 5 | 0 | (0.6154, 0.3846) |
| 60   | Motivation_Level >= 1.5 | 11 | 3 | 0 | (0.7273, 0.2727) * |
| 31   | Extracurricular_Activities >= 0.5 | 33 | 10 | 1 | (0.3030, 0.6970) |
| 62   | Tutoring_Sessions < 2.5 | 25 | 10 | 1 | (0.4000, 0.6000) |
| 125  | Parental_Education_Level >= 1.5 | 12 | 2 | 1 | (0.1667, 0.8333) * |
| 63   | Tutoring_Sessions >= 2.5 | 8 | 0 | 1 | (0.0000, 1.0000) * |



-   La asistencia (Attendance) es el factor más determinante en la mejora académica.

    -   Si la asistencia es menor al 79.5%, la probabilidad de mejora es del 26.96% (578/2144).
    -   Si la asistencia es mayor o igual al 79.5%, la probabilidad de mejora aumenta al 38.22% (887/2321).

\*El nivel de involucramiento parental (Parental_Involvement) tiene un impacto clave en los estudiantes con alta asistencia.

```         
* Si el involucramiento parental es menor a 2.5, la probabilidad de mejora es del 35.59% (579/1627).
* Si el involucramiento parental es mayor o igual a 2.5, la probabilidad de mejora aumenta al 44.38% (308/694).
```

-   Los estudiantes con asistencia mayor a 86.5% y baja calidad docente (Teacher_Quality \< 1.5) dependen del nivel educativo de sus padres (Parental_Education_Level).

    -   Si Parental_Education_Level \< 1.5, la probabilidad de mejora es del 16.39% (10/61), pero aumenta al 40% (1/25) si el estudiante recibe al menos 1.5 sesiones de tutoría (Tutoring_Sessions ≥ 1.5).
    -   Si Parental_Education_Level ≥ 1.5, la probabilidad de mejora sube al 45.24% (19/42) cuando el estudiante estudia más de 26.5 horas semanales.

-   El impacto del nivel de motivación (Motivation_Level) y la influencia de compañeros (Peer_Influence).

    -   Si Motivation_Level \< 1.5 y el estudiante vive a más de 2.5 km, la probabilidad de mejora es baja (4.17%).
    -   Si Motivation_Level ≥ 1.5 y el estudiante tiene alta influencia de compañeros (Peer_Influence ≥ 1.5), la probabilidad de mejora sube al 42.11% (244/566).
    -   Si Motivation_Level ≥ 1.5 y el estudiante estudia más de 29.5 horas, la probabilidad de mejora sube al 62.96% (17/27).

-   Las tutorías (Tutoring_Sessions) tienen un efecto significativo en los estudiantes con alta carga académica.

    -   Si Hours_Studied ≥ 29.5 y el estudiante recibe al menos 2.5 sesiones de tutoría, la probabilidad de mejora es del 100% (8/8).
    -   Si Hours_Studied ≥ 29.5, pero el estudiante recibe menos de 2.5 tutorías, la probabilidad de mejora varía entre 60% y 83.33%, dependiendo del nivel educativo de los padres.

-   La influencia de la distancia desde casa (Distance_from_Home) en la mejora del rendimiento.

    -   Si un estudiante vive a más de 2.5 km y su asistencia es menor a 83.5%, la probabilidad de mejora baja al 55.56% (5/9).
    -   Si un estudiante vive a menos de 2.5 km y tiene un Teacher_Quality ≥ 1.5, la probabilidad de mejora es mayor a 44.86%.

-   Las actividades extracurriculares (Extracurricular_Activities) juegan un rol crucial.

    -   Si el estudiante participa en actividades extracurriculares y tiene asistencia ≥ 94.5%, la probabilidad de mejora es 63.79% (37/58).
    -   Si no participa en actividades extracurriculares y su asistencia es \< 94.5%, la probabilidad de mejora baja al 42.31%.

-   Los estudiantes con Attendance ≥ 99.5% y al menos 7.5 horas de estudio tienen una probabilidad de mejora del 100%.


### Animación

El objetivo principal es visualizar el proceso de clasificación de los estudiantes en el árbol de decisión, permitiendo ver cómo la asistencia, el involucramiento parental y las horas de estudio influyen en la predicción de si un estudiante mejorará o no.

```{r}
# Cargar librerías necesarias
library(rpart)
library(rpart.plot)
library(ggplot2)
library(gganimate)
library(dplyr)
library(gifski)
library(tibble)
library(forcats)

# Asumiendo que 'tree_model' y 'testData' están disponibles
# Y que 'testData' contiene la variable 'Improved' (1 si mejoró, 0 si no)

# 1️⃣ Añadir un identificador único para cada estudiante
testData <- testData %>% mutate(id = 1:nrow(testData))

# 2️⃣ Asegurarse de que 'Improved' es una variable categórica con etiquetas
testData <- testData %>%
  mutate(
    Improved = factor(Improved, levels = c(0, 1), labels = c("No mejoró", "Mejoró"))
  )

# 3️⃣ Asignar a cada fila del dataset su etapa en el árbol
assign_tree_steps <- function(data) {
  data %>%
    mutate(
      step = case_when(
        Attendance < 79.5 ~ "Paso 1: Attendance < 79.5%",
        Attendance >= 79.5 & Parental_Involvement < 2.5 ~ "Paso 2: Parental_Involvement < 2.5",
        Attendance >= 79.5 & Parental_Involvement >= 2.5 & Hours_Studied < 29.5 ~ "Paso 3: Hours_Studied < 29.5",
        Attendance >= 79.5 & Parental_Involvement >= 2.5 & Hours_Studied >= 29.5 ~ "Paso 4: Hours_Studied >= 29.5",
        TRUE ~ "Paso 5: Decisión Final"
      ),
      # Ordenar las etapas correctamente
      step = factor(step, levels = c(
        "Paso 1: Attendance < 79.5%",
        "Paso 2: Parental_Involvement < 2.5",
        "Paso 3: Hours_Studied < 29.5",
        "Paso 4: Hours_Studied >= 29.5",
        "Paso 5: Decisión Final"
      ))
    )
}

testData_animated <- assign_tree_steps(testData)

# 4️⃣ Definir colores para cada etapa y shapes para 'Improved'
color_mapping <- c(
  "Paso 1: Attendance < 79.5%" = "#E41A1C",     # Rojo
  "Paso 2: Parental_Involvement < 2.5" = "#377EB8", # Azul
  "Paso 3: Hours_Studied < 29.5" = "#4DAF4A",   # Verde
  "Paso 4: Hours_Studied >= 29.5" = "#984EA3",  # Morado
  "Paso 5: Decisión Final" = "#FF7F00"          # Naranja
)

shape_mapping <- c("No mejoró" = 21, "Mejoró" = 24)

# 5️⃣ Crear la animación
animated_plot <- ggplot(testData_animated, aes(x = Attendance, y = Hours_Studied, group = id)) +
  geom_point(aes(color = step, shape = Improved, fill = Improved), size = 3, alpha = 0.8) +
  scale_color_manual(values = color_mapping, name = "Etapa del Árbol") +
  scale_shape_manual(values = shape_mapping, name = "Mejora") +
  scale_fill_manual(values = c("No mejoró" = "white", "Mejoró" = "black"), name = "Mejora") +
  labs(
    title = "Evolución de las Decisiones en el Árbol de Decisión",
    subtitle = "Etapa: {closest_state}",
    x = "Asistencia (%)",
    y = "Horas de Estudio por Semana"
  ) +
  theme_minimal(base_size = 14) +
  transition_states(
    step,
    transition_length = 4,
    state_length = 1,
    wrap = FALSE
  ) +
  ease_aes('quadratic-in-out')

# 6️⃣ Guardar la animación como GIF
animate(
  animated_plot,
  width = 800,
  height = 600,
  duration = 20,
  fps = 20,
  renderer = gifski_renderer()
)
anim_save("arbol_decision_animado.gif")

```


• Cada punto representa un estudiante. 
• El eje X muestra el porcentaje de asistencia. 
• El eje Y representa las horas de estudio por semana. 
• El color indica la etapa del árbol en la que se encuentra cada estudiante. 
• El tipo de marcador (círculo o triángulo) indica si el estudiante mejoró o no.

• La animación recorre las diferentes etapas del árbol de decisión, mostrando cómo los estudiantes son clasificados progresivamente según sus características. 
• En cada etapa, el gráfico se enfoca en los estudiantes que cumplen con los criterios de división del árbol.


• La primera división del árbol ocurre en Attendance \< 79.5%, lo que indica que la asistencia es un factor clave en la mejora del rendimiento. • Los estudiantes con baja asistencia (rojo) parecen menos propensos a mejorar.

• La segunda y tercera división se basan en Parental_Involvement \< 2.5 y Hours_Studied \< 29.5, lo que sugiere que la combinación de apoyo familiar y tiempo de estudio es crucial.

• Se observa una concentración de estudiantes que no mejoraron (círculos) en ciertas etapas tempranas del árbol, mientras que en otras se encuentran más estudiantes que sí mejoraron (triángulos). 

• En etapas finales, se pueden identificar subconjuntos donde la mejora es más probable, lo que sugiere estrategias de intervención.


### Árbol Interactivo

Para ir más allá se ha generado una visualización interactiva: 

Esta visualización es igual que la animación anterior, pero con la diferencia de poder elegir la etapa y la condición que queramos visualizar en el árbol de decisión.

```{r}
# Cargar librerías necesarias
library(ggplot2)
library(plotly)
library(dplyr)
library(tibble)
library(forcats)


testData_interactive <- assign_tree_steps(testData)

# Crear el gráfico interactivo con ggplot2
plot <- ggplot(testData_interactive, aes(
  x = Attendance, y = Hours_Studied, 
  color = step, 
  text = paste(
    "ID:", id, "<br>",
    "Asistencia:", round(Attendance, 1), "%<br>",
    "Horas de Estudio:", round(Hours_Studied, 1), "<br>",
    "Etapa:", step, "<br>",
    "Mejoró:", Improved
  ))) +
  geom_point(aes(shape = Improved, fill = Improved), size = 3, alpha = 0.8) +
  scale_color_manual(values = color_mapping, name = "Etapa del Árbol") +
  scale_shape_manual(values = shape_mapping, name = "Mejora") +
  scale_fill_manual(values = c("No mejoró" = "white", "Mejoró" = "black"), name = "Mejora") +
  labs(
    title = "Clasificación en el Árbol de Decisión",
    x = "Asistencia (%)",
    y = "Horas de Estudio"
  ) +
  theme_minimal(base_size = 14)

# 6️⃣ Convertir el gráfico a una versión interactiva con ggplotly
interactive_plot <- ggplotly(plot, tooltip = "text") %>%
  layout(
    title = list(text = "Clasificación en el Árbol de Decisión", font = list(size = 16)),
    xaxis = list(title = "Asistencia (%)"),
    yaxis = list(title = "Horas de Estudio")
  )

# 7️⃣ Mostrar el gráfico interactivo
interactive_plot
```

## Coclusiones

A lo largo del análisis, hemos explorado distintos enfoques de modelado para predecir si un estudiante mejorará su rendimiento académico. Sin embargo, los resultados obtenidos han sido poco satisfactorios. A pesar de probar diferentes técnicas, como Random Forest, XGBoost y Árboles de Decisión (aunque este último ha sido usado con resultados de RF), ninguno de los modelos ha logrado capturar patrones significativos en los datos.

Desde el inicio, el conjunto de datos presentaba una fuerte desbalance en las clases, con solo 32.5% de los estudiantes mostrando una mejora. Para abordar este problema, aplicamos submuestreo para equilibrar las clases y evitar que el modelo se inclinara a predecir mayoritariamente "No Mejoró". Sin embargo, incluso tras este ajuste, los modelos no lograron generar predicciones precisa:

| Métrica               | Random Forest | XGBoost |
|-----------------------|---------------|---------|
| **Accuracy**          | 53.92%        | 51.31%  |
| **Sensitivity**       | 52.33%        | 49.11%  |
| **Specificity**       | 54.69%        | 52.36%  |
| **Kappa**             | 0.0626        | 0.0131  |
| **Balanced Accuracy** | 53.51%        | 50.74%  |

| **Métrica**                   | Árbol de Decisión |
|-------------------------------|-----------|
| **Precisión (Accuracy)**      | 66.13%    |
| **Verdaderos Negativos (TN)** | 1227      |
| **Falsos Positivos (FP)**     | 78        |
| **Verdaderos Positivos (TP)** | 38        |
| **Falsos Negativos (FN)**     | 570       |

Dado el desempeño decepcionante de los modelos, nos preguntamos si el problema radica en los datos en sí. Algunas hipótesis son:

Los datos pueden no reflejar relaciones reales entre las variables:

  La importancia de la asistencia y las horas de estudio parece lógica, pero los modelos no lograron aprovechar esta información para hacer buenas predicciones.
  Otras variables, como el nivel educativo de los padres o la motivación, podrían no estar bien medidas o no ser representativas del rendimiento real.

La calidad de los datos es incierta

  No hemos podido verificar si los datos provienen de una fuente confiable.
  Si los datos han sido generados sintéticamente o contienen errores de recolección, esto explicaría por qué los modelos no encuentran patrones claros.
  La alta correlación entre algunas variables puede haber introducido ruido en las predicciones.

Faltan características importantes para predecir el rendimiento académico

  Puede que haya factores más determinantes, como la salud mental de los estudiantes, acceso a recursos educativos, o métodos de enseñanza, que no fueron considerados en este conjunto de datos.
  El rendimiento académico puede estar influenciado por múltiples variables externas que no están reflejadas en este dataset.

Como reflexión final, dado que hemos probado múltiples enfoques sin éxito, podríamos cuestionarnos la validez de los datos utilizados.
No hemos podido verificar con certeza si los datos son reales o sintéticos, lo que deja abierta la posibilidad de que las relaciones esperadas en un contexto educativo real no estén correctamente reflejadas en esta información.

En escenarios reales, antes de seguir optimizando modelos con datos de baja calidad, sería recomendable evaluar la fuente de los datos y la manera en que fueron recolectados.
Si los datos fueran correctos, pero incompletos, se necesitaría recopilar información adicional para mejorar la capacidad predictiva de los modelos.