---
title: "Students Performance Factors"
author: "Claudia Teresa Heredia Ceballos"
---

# Students Performance Factors

**Trabajo Final Data Science**

*Master en Ingenier√≠a del Software: Cloud, Datos y Gesti√≥n de TI*

## Introducci√≥n

El rendimiento acad√©mico es un factor clave en la educaci√≥n, ya que afecta tanto el futuro de los estudiantes como el desarrollo de la sociedad. Comprender qu√© influye en el desempe√±o escolar permite dise√±ar estrategias para mejorar los resultados. Este estudio explora el uso de machine learning para predecir la calificaci√≥n de los estudiantes, identificando variables clave y desarrollando una herramienta interactiva para su aplicaci√≥n en entornos educativos.

### Descripci√≥n del dominio

Factores como la asistencia a clase, la motivaci√≥n, la calidad del profesorado y el entorno social influyen en el rendimiento acad√©mico. Aplicar modelos predictivos permite anticipar dificultades y tomar decisiones informadas. Sin embargo, uno de los principales retos de este estudio ha sido abordar la baja variabilidad en los datos, lo que dificultaba la capacidad de los modelos para hacer predicciones precisas. Para ello, se exploraron estrategias como feature engineering y data augmentation con el fin de mejorar la representaci√≥n de los datos sin introducir ruido artificial.

### Enfoque del Trabajo

Se han utilizado t√©cnicas de machine learning para predecir el rendimiento acad√©mico, probando distintos modelos y optimizando su precisi√≥n. Adem√°s, se ha desarrollado un dashboard interactivo que permite a docentes y orientadores ingresar datos y obtener predicciones, haciendo que el modelo sea una herramienta pr√°ctica para mejorar la educaci√≥n.

### Inter√©s y motivaci√≥n del estudio

El objetivo es demostrar que la inteligencia artificial puede ser una aliada en la educaci√≥n, ayudando a identificar estudiantes en riesgo y facilitando estrategias personalizadas. Convertir modelos predictivos en herramientas accesibles brinda soluciones reales a los desaf√≠os actuales del sistema educativo.



### Importancia local/nacional y en el contexto actual

La educaci√≥n enfrenta desaf√≠os como la desigualdad en el acceso a recursos y la necesidad de personalizaci√≥n del aprendizaje. La aplicaci√≥n de machine learning puede ayudar a optimizar la ense√±anza, permitiendo a las instituciones anticiparse a problemas y mejorar la toma de decisiones. Implementar estos modelos a gran escala podr√≠a transformar la educaci√≥n, ofreciendo nuevas oportunidades para mejorar el desempe√±o estudiantil.

## Librer√≠as necesarias durante este an√°lisis.

```{r}
library(magrittr)
library(dplyr)
library(tidyverse)
library(caret)
library(randomForest)
library(e1071)
library(ggplot2)
library(shiny)
library(plotly)

```





## Descripci√≥n del dataset

Para la resoluci√≥n de esta pregunta se partir√° de los datos preprocesados en 'global.rmd'.

```{r}

df_cleaned <- read.csv("data/df_cleaned.csv")
df_cleaned_c <-  df_cleaned %>%
  select(-Previous_Scores_Category)
df_cleaned_c
```



#### An√°lisis exploratorio de 'exam_score'

```{r}

# Histograma de exam_score
ggplot(df_cleaned_c, aes(x = Exam_Score)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Distribuci√≥n de 'Exam_Score'", x = "Exam Score", y = "Frecuencia")

```

Como puede observarse existe una muy baja variabilidad de nuestra variable objetivo. 

```{r}
# Calcular estad√≠sticas descriptivas
summary(df_cleaned_c$Exam_Score)

# Calcular desviaci√≥n est√°ndar
sd_exam <- sd(df_cleaned_c$Exam_Score)
cat("Desviaci√≥n est√°ndar de exam_score:", sd_exam)

```

El objetivo es abordar el problema de la variabilidad para ir m√°s all√° y no solo predecir si el rendimiento del estudiante mejora o empeora, si no, predecir, exactamente, la calificaci√≥n que obtendr√° el estudiante.

## ¬øQu√© modelo funcionar√° mejor en la predicci√≥n de exam Score?

## Primera prueba. Random Forest, SVR y Regresi√≥n Lineal

###  Definir Variables Predictoras

Primero, se define la variable objetivo Exam_Score, que es la que se intenta predecir. Luego, se obtiene la lista de todas las variables en el DataFrame df_cleaned_c. Posteriormente, se excluyen Exam_Score, ya que es la variable objetivo, y student_id, puesto que es un identificador y no aporta informaci√≥n predictiva. Finalmente, se imprime la lista de variables predictoras. 

```{r}
target_variable <- "Exam_Score"
all_variables <- names(df_cleaned_c)
predictor_variables <- setdiff(all_variables, c(target_variable, "student_id"))
print(predictor_variables)
```


###  Divisi√≥n en Train/Test

Para la divisi√≥n del conjutno primero, se usa set.seed(123) para asegurar la reproducibilidad del muestreo. Luego, createDataPartition() divide los datos en 80% de entrenamiento (train_data) y 20% de prueba (test_data), manteniendo la distribuci√≥n de Exam_Score en ambas muestras.

```{r}
set.seed(123)
trainIndex <- createDataPartition(df_cleaned_c$Exam_Score, p = 0.8, list = FALSE)
train_data <- df_cleaned_c[trainIndex, ]
test_data <- df_cleaned_c[-trainIndex, ]

```



### Modelos de Machine Learning

Durante el estudio se comparar√°n 3 modelos distintos de machine learning para establecer cu√°l de ellos funciona mejor con el conjunto de datos que tenemos. 

#### Random Forest

Random Forest es √∫til porque combina m√∫ltiples √°rboles de decisi√≥n, lo que mejora la precisi√≥n y la capacidad de generalizaci√≥n del modelo al reducir la varianza de las predicciones.

Este bloque entrena y eval√∫a un modelo de Random Forest utilizando la librer√≠a caret. 

* Se usa train() para entrenar el modelo y se emplea validaci√≥n cruzada con 5 folds para evitar el sobreajuste y mejorar la generalizaci√≥n. 

* Se habilita importance = TRUE para obtener la importancia de las variables predictoras. 

* El modelo se eval√∫a haciendo predicciones en el conjunto de datos de prueba usando predict() y calculando el coeficiente de determinaci√≥n ùëÖ2, el cual mide qu√© tan bien el modelo explica la variabilidad de la variable objetivo (Exam_Score). 

```{r}
set.seed(123)

rf_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "rf",
  trControl = trainControl(method = "cv", number = 5),
  importance = TRUE
)
rf_pred <- predict(rf_model, newdata = test_data)
r2_rf <- R2(rf_pred, test_data$Exam_Score)
```



##### Importancia de Variables en RF

```{r}
importance_df <- data.frame(
  Variable = rownames(importance(rf_model$finalModel)),
  Importance = importance(rf_model$finalModel)[, 1]
)
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]

# Gr√°fico
ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Importancia de las Variables en Random Forest", x = "Variable", y = "Incremento en MSE") +
  theme_minimal()
```

Como puede observarse en la gr√°fica de importancia de variables, "Attendance" y "Hours_Studied" son las m√°s influyentes con gran diferencia. 

#### Regresi√≥n Lineal

La regresi√≥n lineal se utiliza para modelar la relaci√≥n entre una variable dependiente y una o m√°s variables independientes.


```{r}
lm_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)
lm_pred <- predict(lm_model, newdata = test_data)
r2_lm <- R2(lm_pred, test_data$Exam_Score)
```


#### SVR

Por √∫ltimo, en este apartado se entrana un modelo de Support Vector Regression. El modelo de SVR utiliza una funci√≥n de n√∫cleo radial (Radial Basis Function, RBF) para capturar relaciones no lineales en los datos.

En este caso tambi√©n se emplea validaci√≥n cruzada con 5 folds (method = "cv", number = 5) para evitar el sobreajuste y mejorar la generalizaci√≥n. Adem√°s, se preprocesan los datos centrando y escalando las variables predictoras (preProcess = c("center", "scale")) y se exploran diferentes configuraciones de hiperpar√°metros (tuneLength = 5).


```{r}

svr_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale"),
  tuneLength = 5
)
svr_pred <- predict(svr_model, newdata = test_data)
r2_svr <- R2(svr_pred, test_data$Exam_Score)
```


### Comparaci√≥n de Modelos

```{r}
results_no_cluster_no_fe <- data.frame(Modelo = c("Random Forest", "Regresi√≥n Lineal", "SVR"),
                              R2 = c(r2_rf, r2_lm, r2_svr))
print(results_no_cluster_no_fe)

```
La Regresi√≥n Lineal obtuvo el mejor desempe√±o con unùëÖ2 de 0.7299, superando a SVR y Random Forest.
SVR tambi√©n mostr√≥ un rendimiento similar a la regresi√≥n lineal, con un ùëÖ2 de 0.7256.
Random Forest tuvo el peor desempe√±o (0.6523), lo que sugiere que el modelo no pudo captar bien la estructura de los datos en su forma actual.



Durante todo el an√°lisis (tanto grupal como individual), se ha demostrado que los la estructura de los datos dificultan en gran medida el funcionamiento de los modelos predictivos. Por ello, sirge la siguiente pregunta:


## ¬øPodr√≠an mejorar los modelos si se alteran los datos?

## Primera prueba. Comparaci√≥n de Modelos aplicando Feature Engineering.:

```{r}

df_cleaned <- read.csv("data/df_cleaned.csv")

df_cleaned_c <- df_cleaned %>%
  select(-Previous_Scores_Category)  # Eliminamos una variable no utilizada
```


### Feature Engineering

Se crean nuevas variables derivadas de combinaciones l√≥gicas de las existentes para mejorar la capacidad predictiva de los modelos.

* 'study_sleep_ratio': Relaci√≥n entre horas de estudio y horas de sue√±o. Se introduce para medir el equilibrio entre descanso y preparaci√≥n acad√©mica.

* 'motivated_study': Producto de horas de estudio y nivel de motivaci√≥n. Representa el impacto de la motivaci√≥n en el esfuerzo acad√©mico.

* 'parent_peer_influence': Combinaci√≥n del involucramiento parental y la influencia de los pares. Se usa para medir el impacto del entorno social.

* 'distance_category': Agrupa la distancia a la escuela en tres categor√≠as: Cerca, Media y Lejos.

* 'study_group': Clasifica las horas de estudio en tres categor√≠as: Bajo, Medio y Alto.

* 'high_access_to_resources': Variable binaria que indica si el estudiante tiene acceso a recursos por encima de la media.

* 'social_influence': Suma de la influencia de pares, el involucramiento parental y la calidad del maestro, escalada para facilitar la comparaci√≥n.

```{r}

df_cleaned_c <- df_cleaned_c %>% mutate(
  study_sleep_ratio = scale(Hours_Studied / (Sleep_Hours + 1)),
  motivated_study = scale(Hours_Studied * Motivation_Level),
  parent_peer_influence = scale(Parental_Involvement * Peer_Influence),
  distance_category = case_when(
    Distance_from_Home < quantile(Distance_from_Home, 0.33) ~ "Cerca",
    Distance_from_Home < quantile(Distance_from_Home, 0.66) ~ "Media",
    TRUE ~ "Lejos"
  ),
  study_group = case_when(
    Hours_Studied < quantile(Hours_Studied, 0.33) ~ "Bajo",
    Hours_Studied < quantile(Hours_Studied, 0.66) ~ "Medio",
    TRUE ~ "Alto"
  ),
  high_access_to_resources = ifelse(Access_to_Resources > mean(Access_to_Resources, na.rm = TRUE), 1, 0),
  social_influence = scale(Peer_Influence + Parental_Involvement + Teacher_Quality)
)

# Convertir variables categ√≥ricas a factores
df_cleaned_c$distance_category <- as.factor(df_cleaned_c$distance_category)
df_cleaned_c$study_group <- as.factor(df_cleaned_c$study_group)


```


### Divisi√≥n en Train Test

```{r}

set.seed(123)
trainIndex <- createDataPartition(df_cleaned_c$Exam_Score, p = 0.8, list = FALSE)
train_data <- df_cleaned_c[trainIndex, ]
test_data <- df_cleaned_c[-trainIndex, ]
```


### Entrenamiento de Modelos: Randon Forest vs SVR vs Regresi√≥n Lineal:

```{r}

set.seed(123)

# üìå Random Forest
rf_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "rf",
  trControl = trainControl(method = "cv", number = 5),
  importance = TRUE
)
rf_pred <- predict(rf_model, newdata = test_data)
r2_rf <- R2(rf_pred, test_data$Exam_Score)


# Importancia de Variables en RF

importance_df <- data.frame(
  Variable = rownames(importance(rf_model$finalModel)),
  Importance = importance(rf_model$finalModel)[, 1]
)
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]

# Gr√°fico
ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Importancia de las Variables en Random Forest", x = "Variable", y = "Incremento en MSE") +
  theme_minimal()
# üìå Regresi√≥n Lineal
lm_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)
lm_pred <- predict(lm_model, newdata = test_data)
r2_lm <- R2(lm_pred, test_data$Exam_Score)

# üìå SVR
svr_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale"),
  tuneLength = 5
)
svr_pred <- predict(svr_model, newdata = test_data)
r2_svr <- R2(svr_pred, test_data$Exam_Score)
```
La importancia de variables se mantiene similar, pero ahora aparecen algunas nuevas transformaciones de variables como "motivated_study" y "social_influence, que ya no se muestran tan alejadas de la importandia de Hours_Studied, aunque s√≠ de la asistencia a clase. 

### Comparaci√≥n de Modelos: 

```{r}

results_no_cluster <- data.frame(Modelo = c("Random Forest", "Regresi√≥n Lineal", "SVR"),
                                 R2 = c(r2_rf, r2_lm, r2_svr))
print(results_no_cluster)



```
Los resultados son muy similares a la prueba anterior, lo que indica que el Feature Engineering no tuvo un impacto significativo en el rendimiento de los modelos.

Random Forest sigue con el peor desempe√±o (0.6473), e incluso mostr√≥ una leve disminuci√≥n en comparaci√≥n con la prueba anterior.

La Regresi√≥n Lineal y SVR no experimentaron cambios significativos.



## Segunda prueba. Comparaci√≥n de Modelos con Data Augmentation y Feature Engineering.


En esta secci√≥n, se eval√∫a cu√°l modelo de machine learning predice mejor el 'Exam_Score' tras aplicar t√©cnicas de 'data augmentation' con ruido controlado y 'feature engineering'. El objetivo es verificar si estas mejoras incrementan la capacidad predictiva de los modelos previamente utilizados: Random Forest, Regresi√≥n Lineal y Support Vector Regression (SVR).

Cargamos nuevamente los datos (eliminando la variable que no nos sirve):

```{r}
df_cleaned <- read.csv("data/df_cleaned.csv")

df_cleaned_c <- df_cleaned %>%
  select(-Previous_Scores_Category)  # Eliminamos una variable no utilizada
```


### Data Augmentation con Ruido Controlado

Para mejorar la variabilidad de los datos sin alterar significativamente la informaci√≥n original, se introduce ruido controlado en la variable objetivo Exam_Score. Se genera una perturbaci√≥n normal con media 0 y desviaci√≥n est√°ndar del 10% de la desviaci√≥n est√°ndar original. Adem√°s, los valores se limitan al rango [50, 100] para mantener la coherencia de los datos.

```{r}

set.seed(123)
df_augmented <- df_cleaned_c %>% mutate(
  Exam_Score = Exam_Score + rnorm(n(), mean = 0, sd = sd(df_cleaned_c$Exam_Score) * 0.1)  # Ruido moderado
)

# Limitar valores a 50-100
df_augmented$Exam_Score <- pmax(pmin(df_augmented$Exam_Score, 100), 50)

# Imprimir desviaci√≥n est√°ndar despu√©s de Data Augmentation
cat("Desviaci√≥n est√°ndar de Exam_Score despu√©s de Data Augmentation:", sd(df_augmented$Exam_Score), "\n")
```


### Feauture Engineering

En este apartado se mantienen las nuevas variables que se crearon durante la primera prueba. 

```{r}

df_augmented <- df_augmented %>% mutate(
  study_sleep_ratio = scale(Hours_Studied / (Sleep_Hours + 1)),
  motivated_study = scale(Hours_Studied * Motivation_Level),
  parent_peer_influence = scale(Parental_Involvement * Peer_Influence),
  distance_category = case_when(
    Distance_from_Home < quantile(Distance_from_Home, 0.33) ~ "Cerca",
    Distance_from_Home < quantile(Distance_from_Home, 0.66) ~ "Media",
    TRUE ~ "Lejos"
  ),
  study_group = case_when(
    Hours_Studied < quantile(Hours_Studied, 0.33) ~ "Bajo",
    Hours_Studied < quantile(Hours_Studied, 0.66) ~ "Medio",
    TRUE ~ "Alto"
  ),
  high_access_to_resources = ifelse(Access_to_Resources > mean(Access_to_Resources, na.rm = TRUE), 1, 0),
  social_influence = scale(Peer_Influence + Parental_Involvement + Teacher_Quality)
)

# Convertir variables categ√≥ricas a factores
df_augmented$distance_category <- as.factor(df_augmented$distance_category)
df_augmented$study_group <- as.factor(df_augmented$study_group)
```


### Definici√≥n de Variables Predictoras

```{r}

target_variable <- "Exam_Score"
all_variables <- names(df_augmented)
predictor_variables <- setdiff(all_variables, c(target_variable, "student_id"))
print(predictor_variables)
```

###  Divisi√≥n en Train/Test

```{r}

set.seed(123)
trainIndex <- createDataPartition(df_augmented$Exam_Score, p = 0.8, list = FALSE)
train_data <- df_augmented[trainIndex, ]
test_data <- df_augmented[-trainIndex, ]
```


### Entrenamiento y Validaci√≥n de los modelos:

```{r}

set.seed(123)

# Random Forest
rf_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "rf",
  trControl = trainControl(method = "cv", number = 5),
  importance = TRUE
)
rf_pred <- predict(rf_model, newdata = test_data)
r2_rf <- R2(rf_pred, test_data$Exam_Score)


importance_df <- data.frame(
  Variable = rownames(importance(rf_model$finalModel)),
  Importance = importance(rf_model$finalModel)[, 1]
)
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]

# Gr√°fico
ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Importancia de las Variables en Random Forest", x = "Variable", y = "Incremento en MSE") +
  theme_minimal()


# Regresi√≥n Lineal
lm_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)
lm_pred <- predict(lm_model, newdata = test_data)
r2_lm <- R2(lm_pred, test_data$Exam_Score)

# SVR
svr_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale"),
  tuneLength = 5
)
svr_pred <- predict(svr_model, newdata = test_data)
r2_svr <- R2(svr_pred, test_data$Exam_Score)

```


### Comparaci√≥n de los Modelos:

```{r}

results_data_augmentation <- data.frame(Modelo = c("Random Forest", "Regresi√≥n Lineal", "SVR"),
                                        R2 = c(r2_rf, r2_lm, r2_svr))
print(results_data_augmentation)
```
Aqu√≠ se observ√≥ una mejora en todos los modelos despu√©s de aplicar Data Augmentation.

Regresi√≥n Lineal sigue siendo el mejor modelo, alcanzando un ùëÖ2 de 0.7504.

SVR tambi√©n mejor√≥, con un ùëÖ2 de 0.7452.

Random Forest experiment√≥ la mayor mejora, aumentando suùëÖ2 de 0.6473 a 0.6853, lo que sugiere que el Data Augmentation ayud√≥ a reducir la variabilidad y mejorar el aprendizaje del modelo.

Agregar datos sint√©ticos con ruido moderado ayud√≥ a mejorar la generalizaci√≥n de los modelos.



## Tercera prueba. Comparaci√≥n de Modelos con Interpolaci√≥n y Feature Engineering.

En esta secci√≥n, se eval√∫a cu√°l modelo de machine learning predice mejor el Exam_Score tras aplicar interpolaci√≥n en lugar de data augmentation con ruido controlado y manteniendo el feature engineering. La interpolaci√≥n permite generar datos intermedios basados en los valores existentes, lo que puede reducir el sesgo en los modelos y mejorar la calidad del entrenamiento.


```{r}
df_cleaned <- read.csv("data/df_cleaned.csv")

df_cleaned_c <- df_cleaned %>%
  select(-Previous_Scores_Category)  # Eliminamos una variable no utilizada
```


###  Interpolaci√≥n y generaci√≥n de nuevos datos.

En lugar de a√±adir ruido aleatorio, utilizamos interpolaci√≥n para generar valores intermedios a partir de la distribuci√≥n existente de Exam_Score. La interpolaci√≥n ayuda a mejorar la representatividad de los datos sin distorsionar demasiado la informaci√≥n original.

En lugar de a√±adir ruido aleatorio, utilizamos interpolaci√≥n para generar valores intermedios a partir de la distribuci√≥n existente de Exam_Score. La interpolaci√≥n consiste en estimar valores dentro del rango de los datos originales para simular una distribuci√≥n m√°s continua y mejorar la representatividad de los datos.

Para lograrlo, se han realizado los siguientes pasos:

1. Generaci√≥n de puntos intermedios: Se crean valores dentro del rango m√≠nimo y m√°ximo de Exam_Score, asegurando una mayor densidad de datos en la distribuci√≥n original.

2. Aleatorizaci√≥n: Se seleccionan valores interpolados de forma aleatoria para evitar patrones artificiales.

3. Ajuste de la distribuci√≥n: Se introduce un peque√±o ruido proporcional para reflejar la variabilidad natural de los datos.

4. Limitaci√≥n de valores: Se restringen los valores interpolados al rango v√°lido de Exam_Score [55, 100].

```{r}

expandir_datos <- function(df) {
  n <- nrow(df)
  
  if (n < 2) return(df)  # Evitar problemas en conjuntos peque√±os
  
  # Generar nuevos valores interpolados
  nuevos_puntos <- seq(min(df$Exam_Score), max(df$Exam_Score), length.out = n * 2)
  nuevos_puntos <- sample(nuevos_puntos, size = n, replace = TRUE)  # Aleatorizar selecci√≥n
  df$Exam_Score <- nuevos_puntos
  return(df)
}

# Aplicar interpolaci√≥n
df_interpolado <- expandir_datos(df_cleaned_c)

# A√±adir ruido proporcional a la dispersi√≥n
df_interpolado <- df_interpolado %>% mutate(
  Exam_Score = Exam_Score + rnorm(n(), mean = 0, sd = sd(df_interpolado$Exam_Score) * 0.5)
)

# Limitar valores a 50-100
df_interpolado$Exam_Score <- pmax(pmin(df_interpolado$Exam_Score, 100), 50)

# Imprimir desviaci√≥n est√°ndar despu√©s de Interpolaci√≥n
cat("Desviaci√≥n est√°ndar de Exam_Score despu√©s de Interpolaci√≥n:", sd(df_interpolado$Exam_Score), "\n")

```


###  Feature Engineering

Durante esta prueba se mantienen las transformaciones anteriores para mejorar la capacidad predictiva de los modelos.

```{r}

df_interpolado <- df_interpolado %>% mutate(
  study_sleep_ratio = scale(Hours_Studied / (Sleep_Hours + 1)),
  motivated_study = scale(Hours_Studied * Motivation_Level),
  parent_peer_influence = scale(Parental_Involvement * Peer_Influence),
  distance_category = case_when(
    Distance_from_Home < quantile(Distance_from_Home, 0.33) ~ "Cerca",
    Distance_from_Home < quantile(Distance_from_Home, 0.66) ~ "Media",
    TRUE ~ "Lejos"
  ),
  study_group = case_when(
    Hours_Studied < quantile(Hours_Studied, 0.33) ~ "Bajo",
    Hours_Studied < quantile(Hours_Studied, 0.66) ~ "Medio",
    TRUE ~ "Alto"
  ),
  high_access_to_resources = ifelse(Access_to_Resources > mean(Access_to_Resources, na.rm = TRUE), 1, 0),
  social_influence = scale(Peer_Influence + Parental_Involvement + Teacher_Quality)
)

# Convertir variables categ√≥ricas a factores
df_interpolado$distance_category <- as.factor(df_interpolado$distance_category)
df_interpolado$study_group <- as.factor(df_interpolado$study_group)

```


### Definici√≥n de Variables Predictoras y Divisi√≥n del conjunto:
```{r}

target_variable <- "Exam_Score"
all_variables <- names(df_interpolado)
predictor_variables <- setdiff(all_variables, c(target_variable, "student_id"))
print(predictor_variables)


# Train/Test

set.seed(123)
trainIndex <- createDataPartition(df_interpolado$Exam_Score, p = 0.8, list = FALSE)
train_data <- df_interpolado[trainIndex, ]
test_data <- df_interpolado[-trainIndex, ]
```


### Entrenamiento y Validaci√≥n de Modelos:

En este apartado se vuelven a entrenar los mismos modelos: Random Forest, SVR y Regresi√≥n Lineal.

```{r}

set.seed(123)

# Random Forest
rf_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "rf",
  trControl = trainControl(method = "cv", number = 5),
  importance = TRUE
)
rf_pred <- predict(rf_model, newdata = test_data)
r2_rf <- R2(rf_pred, test_data$Exam_Score)

#  Importancia de Variables en RF

importance_df <- data.frame(
  Variable = rownames(importance(rf_model$finalModel)),
  Importance = importance(rf_model$finalModel)[, 1]
)
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]

# Gr√°fico
ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Importancia de las Variables en Random Forest", x = "Variable", y = "Incremento en MSE") +
  theme_minimal()

# Regresi√≥n Lineal
lm_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)
lm_pred <- predict(lm_model, newdata = test_data)
r2_lm <- R2(lm_pred, test_data$Exam_Score)

#  SVR
svr_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale"),
  tuneLength = 5
)
svr_pred <- predict(svr_model, newdata = test_data)
r2_svr <- R2(svr_pred, test_data$Exam_Score)
```



### Comparaci√≥n de Modelos:
```{r}

results_interpolation <- data.frame(Modelo = c("Random Forest", "Regresi√≥n Lineal", "SVR"),
                                    R2 = c(r2_rf, r2_lm, r2_svr))
print(results_interpolation)

```

Los resultados se desplomaron dr√°sticamente.
Todos los modelos obtuvieron un ùëÖ2 cercano a 0, lo que indica que no lograron captar ninguna relaci√≥n entre las variables y el Exam_Score.

La interpolaci√≥n alter√≥ demasiado la estructura de los datos, haciendo que los modelos pierdan completamente su capacidad predictiva.

La desviaci√≥n est√°ndar de Exam_Score se dispar√≥ de 3.93 a 14.10, lo que sugiere que los valores interpolados introdujeron demasiada variabilidad artificial.
Con ello podemos concluir que la interpolaci√≥n no fue una buena estrategia para este conjunto de datos, de hecho, ha sido la prueba con peores resultados. 


### Tabla Comparativa y Conclusi√≥n Final:

# Comparaci√≥n Final de Modelos

| Prueba                                        | Random Forest | Regresi√≥n Lineal | SVR  |
|-----------------------------------------------|--------------|-----------------|------|
| Primera Prueba                                | 0.6523       | **0.7299**      | 0.7256 |
| Feature Engineering                           | 0.6473       | **0.7292**      | 0.7259 |
| Data Augmentation + Feature Engineering       | 0.6853       | **0.7504**      | 0.7452 |
| Interpolaci√≥n + Feature Engineering           | 0.0001       | **0.0005**      | 0.0002 |


Como puede observarse en la tabla y despu√©s de las distintas pruebas, la mejor estrategia fue aplicar Data Augmentation junto con Feature Engineering. La interpolaci√≥n, en cambio, fue una estrategia fallida. La Regresi√≥n Lineal fue el mejor modelo en general.


## Una vez elegido el mejor modelo, ¬øPodremos mejorarlo haciendo alg√∫n ajuste de hiperpar√°metros?



En este pounto se decide que la Regresi√≥n Lineal junto con Data Augmentation y Feauture Engineering es el modelo que mejor funciona con nuestro tipo de datos. Antes de terminar de resolver la pregunta, vamos a ajustar algunos par√°metros para intentar mejorar el modelo:



```{r}


df_cleaned <- read.csv("data/df_cleaned.csv")

df_cleaned_c <- df_cleaned %>%
  select(-Previous_Scores_Category)
```

El ruido para el Data Augmentation se disminuye a 0.005: 

```{r}

set.seed(123)
df_augmented <- df_cleaned_c %>% mutate(
  Exam_Score = Exam_Score + rnorm(n(), mean = 0, sd = sd(df_cleaned_c$Exam_Score) * 0.005)
)

# Limitar valores a 50-100
df_augmented$Exam_Score <- pmax(pmin(df_augmented$Exam_Score, 100), 50)

# Imprimir desviaci√≥n est√°ndar despu√©s de agregar ruido
cat("Desviaci√≥n est√°ndar despu√©s de agregar ruido:", sd(df_augmented$Exam_Score), "\n")
```

### El Feauture Engineering lo dejaremos tal y como estaba en el apartado anterior:

```{r}

df_augmented <- df_augmented %>% mutate(
  study_sleep_ratio = as.numeric(scale(Hours_Studied / (Sleep_Hours + 1))),
  motivated_study = as.numeric(scale(Hours_Studied * Motivation_Level)),
  parent_peer_influence = as.numeric(scale(Parental_Involvement * Peer_Influence)),
  distance_category = as.factor(case_when(
    Distance_from_Home < quantile(Distance_from_Home, 0.33) ~ "Cerca",
    Distance_from_Home < quantile(Distance_from_Home, 0.66) ~ "Media",
    TRUE ~ "Lejos"
  )),
  study_group = as.factor(case_when(
    Hours_Studied < quantile(Hours_Studied, 0.33) ~ "Bajo",
    Hours_Studied < quantile(Hours_Studied, 0.66) ~ "Medio",
    TRUE ~ "Alto"
  )),
  high_access_to_resources = as.factor(ifelse(Access_to_Resources > mean(Access_to_Resources, na.rm = TRUE), 1, 0)),
  social_influence = as.numeric(scale(Peer_Influence + Parental_Involvement + Teacher_Quality))
)
```


### Variables predictoras y divisi√≥n en Train Test.
```{r}

target_variable <- "Exam_Score"
all_variables <- names(df_augmented)
predictor_variables <- setdiff(all_variables, c(target_variable, "student_id"))
print(predictor_variables)


set.seed(123)
trainIndex <- createDataPartition(df_augmented$Exam_Score, p = 0.8, list = FALSE)
train_data <- df_augmented[trainIndex, ]
test_data <- df_augmented[-trainIndex, ]
```


### Regresi√≥n Lineal

En este caso, con caret, podemos probar a optimizar la regresi√≥n lineal con 'glmet', que permite la regularizaci√≥n con Lasso (L1) y Ridge (L2):

```{r}

set.seed(123)
lm_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "glmnet",
  trControl = trainControl(method = "cv", number = 5),
  tuneGrid = expand.grid(
    alpha = c(0, 0.5, 1),  # Ridge (0), Elastic Net (0.5), Lasso (1)
    lambda = seq(0, 0.1, length = 10) # Probar valores de lambda
  )
)

lm_pred <- predict(lm_model, newdata = test_data)
r2_lm <- R2(lm_pred, test_data$Exam_Score)

# Guardar el modelo de Regresi√≥n Lineal
save(lm_model, file = "best_model_lm.RData")

```


### Evaluaci√≥n del modelo

```{r}

# MSE y RMSE
mse_lm <- mean((lm_pred - test_data$Exam_Score)^2)
rmse_lm <- sqrt(mse_lm)
cat("MSE:", mse_lm, "\n")
cat("RMSE:", rmse_lm, "\n")

# MAE
mae_lm <- mean(abs(lm_pred - test_data$Exam_Score))
cat("MAE:", mae_lm, "\n")

# R2
cat("R2:", r2_lm, "\n")

# Comparaci√≥n de predicciones vs valores reales
library(ggplot2)

ggplot(data = data.frame(Real = test_data$Exam_Score, Predicho = lm_pred), aes(x = Real, y = Predicho)) +
  geom_point(color = "blue") +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") + 
  labs(title = "Comparaci√≥n: Valores Reales vs. Predicciones",
       x = "Valores Reales",
       y = "Predicciones") +
  theme_minimal()

# Distribuci√≥n de Errores
error <- lm_pred - test_data$Exam_Score

ggplot(data.frame(error = error), aes(x = error)) +
  geom_histogram(binwidth = 1, fill = "blue", alpha = 0.6) +
  labs(title = "Distribuci√≥n de los Errores",
       x = "Error (Predicci√≥n - Real)",
       y = "Frecuencia") +
  theme_minimal()


```


Finalmente, esta tabla muestra, despu√©s de muchas combinaciones, los cambios que mejor han funcionado en el modelo elegido en la pregunta anterior:


| Hiperpar√°metro                                        | Antes | Ahora | 
|-----------------------------------------------|--------------|-----------------|
| Ruido                                | 0.1       | 0.005      | 
| Regresi√≥n                           | Lineal Simple       | Ridge y Lasso      | 


Los gr√°ficos y las m√©tricas obtenidas muestran c√≥mo la ligera variaci√≥n en la desviaci√≥n est√°ndar del ruido en Data Augmentation ha impactado en el rendimiento del modelo de regresi√≥n lineal.


| Desviaci√≥n est√°ndar antes   |  Desviaci√≥n est√°ndar con Data Augmentation| 
|-----------------------------------------------|--------------|
| 3.912884                                | 3.913056       |  

A simple vista, la diferencia en la desviaci√≥n est√°ndar parece m√≠nima, pero ha generado una mejora en R¬≤ de 0.7504 ‚Üí 0.7580.

Si no se aplicara Data Augmentation, el resultado de R¬≤ disminuir√≠a significativamente, como ocurri√≥ en pruebas anteriores.


Respecto a los gr√°ficos, la mayor√≠a de los errores est√°n concentrados cerca de 0, lo cual indica que el modelo hace buenas predicciones.
La distribuci√≥n de errores es asim√©trica, lo que indica que a√∫n hay cierta subestimaci√≥n para valores altos de "Exam_Score".


En este punto del an√°lisis, se ha conseguido obtener un modelo cuyo r2 es de 0.7580, lo que ya se empieza a considerar un modelo fiable (con margen de mejora).

Pero, una vez que tenemos un modelo que funciona, nos surge la siguiente pregunta:

## ¬øComo podr√≠amos llevar al uso estos modelos en la vida real?¬øQu√© aplicaci√≥n realista podr√≠a tener este an√°lisis?

Solemos terminar los an√°lisis proporcionando los resultados que hemos obtenido en los modelos, pero durante este proyecto, se ha querido finalizar dando un enfoque realista.

Para entender mejor este resultado, el enfoque ser√≠a el siguiente:

En todos los colegios existe un departamento orientativo, en el que adem√°s de las calificaciones de los alumnos, de las que se preocupan los profesores, se tienen en cuenta otros aspectos importantes en la vida del alumno, por ejemplo, ¬øRealiza el alumno actividades extraescolares?¬øLos padres se involucran lo suficiente con el alumno? o incluso ¬øLa influencia social le beneficia o le perjudica?.

Para seguir con el supuesto, imaginando que nuestros alumnos son de segundo de bachillerato, a√±o en el que se realiza selectividad y la calificaci√≥n ha de ser la m√°s alta posible, ¬øAyudar√≠a al departamento orientativo tener un cuestionario que predijera la calificaci√≥n final que obtendr√° el alumno? 

EL objetivo es entonces, que el alumno, con supervisi√≥n orientativa, responda a un a especie de cuestionario, en el que el resultado de la calificaci√≥n final se mostrar√° al psic√≥logo del colegio. Junto con el estudio del √°rbol de decisi√≥n generado en 'global.rmd' podr√≠a llevarse a cabo un programa especial para ayudar a cada alumno en la "variable" que lo requiera. 

Para llevarlo a cabo, se ha creado un dashboard, con la idea de que el alumno lo complete (siempre con supervisi√≥n orientativa):



### Formulario 

```{r}
library(shiny)

# Se carga el modelo y los datos
load("best_model_lm.RData")

# Definici√≥n de etiquetas amigables y leyendas
friendly_labels <- list(
   Previous_Scores = list(
    label = "¬øQu√© Calificaci√≥n obtuvo en el anterior examen?",
    legend = "Debe contestar a esta pregunta en forma de porcentaje: 0% = un 0, 100% = un 10."
  ),
  Attendance = list(
    label = "¬øA qu√© porcentaje de clases asiste el alumno?",
    legend = "Debe contestar a esta pregunta en forma de porcentaje: 0% = no asiste a clase, 100% = asiste a todas las clases."
  ),
  Distance_from_Home = list(
    label = "¬øCu√°l es la distancia del alumno al centro educativo?",
    legend = "0 = Cerca, 3 = Lejos"
  ),
  Hours_Studied = list(
    label = "¬øCu√°ntas horas estudia el alumno a la semana?",
    legend = "Ingrese la cantidad de horas dedicadas al estudio semanalmente."
  ),
  Access_to_Resources = list(
    label = "Disponibilidad de recursos educativos",
    legend = "0 = No tengo acceso a recursos, 100 = Tengo acceso a todos los recursos."
  ),
  Extracurricular_Activities = list(
    label = "Participaci√≥n en Actividades extraescolares",
    legend = "0 = No participo, 100 = Si participo"
  ),
  School_Type_Private = list(
    label = "¬øAsiste a un colegio privado?",
    legend = "0 = No, 1 = Si"
  ),
  School_Type_Public = list(
    label = "¬øAsiste a un colegio p√∫blico?",
    legend = "0 = No, 1 = Si"
  ),
  Gender_Male = list(
    label = "¬øSe considera de g√©nero masculino?",
    legend = "0 = No, 1 = Si"
  ),
  Gender_Female = list(
    label = "¬øSe considera de g√©nero femenino?",
    legend = "0 = No, 1 = Si"
  ),
  Sleep_Hours = list(
    label = "¬øCu√°ntas horas suele dormir el alumno?",
    legend = "Responda entre 4 y 10 horas"
  ),
  Internet_Access = list(
    label = "¬øDispone de Acceso a Internet?",
    legend = "0 = no, 1 = si"
  ),
  Tutoring_Sessions = list(
    label = "¬øA cu√°ntas tutor√≠as asiste al mes?",
    legend = "Responda entre 0 y 8"
  ),
  study_sleep_ratio = list(
    label = "¬øConsideras que las horas de sue√±o y las horas de estudio est√°n relacionadas?",
    legend = "Valores mayores a 0 indican m√°s estudio en relaci√≥n con el sue√±o"
  ),
  motivated_study = list(
    label = "¬øConsideras que las horas de estudio est√°n relacionadas con tu nivel de motivaci√≥n?",
    legend = "A m√°s valor, m√°s relaci√≥n entre motivaci√≥n y estudio"
  ),
  parent_peer_influence = list(
    label = "¬øConsideras que la influencia de tus padres y amigos influye en tu rendimiento?",
    legend = "A m√°s valor, m√°s relaci√≥n entre ambos factores"
  ),
  distance_category = list(
    label = "Clasifica la distancia desde la casa a la escuela en grupos seg√∫n percentiles",
    legend = "Escoja una opci√≥n."
  ),
  study_group = list(
    label = "¬øA qu√© grupo pertenecer√≠a en relaci√≥n a su estudio?",
    legend = "Bajo = estudia poco, Medio = normal, Alto = estudia mucho"
  ),
  high_access_to_resources = list(
    label = "Indica si un estudiante tiene acceso a recursos educativos por encima del promedio",
    legend = "1 = si, por encima de la media,0 = no, por debajo de la media"
  ),
  social_influence = list(
    label = "Combinaci√≥n del impacto de los compa√±eros, la participaci√≥n de los padres y la calidad docente",
    legend = "Valores m√°s altos indican mayor influencia social en el aprendizaje"
  ),
  Learning_Disabilities = list(
    label = "¬øPresenta dificultades de aprendizaje?",
    legend = "0 = No presenta, 1 = Presenta alguna Dificultad"
  ),
  Parental_Education_Level = list(
    label = "Nivel educativo mas alto de los padres",
    legend = "1 = High School, 2 = College, 3 = Postgraduate"
  ),
  Family_Income = list(
    label = "Nivel de Ingresos Familiares",
    legend = "0 = Ingresos Bajos, 3 = Ingresos altos"
  ),
  Teacher_Quality = list(
    label = "¬øComo puntuar√≠a la calidad del profesorado?",
    legend = "0 = Baja Calidad, 3 = Calidad Alta"
  ),
  Peer_Influence = list(
    label = "Influencia de los compa√±eros",
    legend = "1 = Negativa, 3 = Positiva "
  ),
  Physical_Activity = list(
    label = "N√∫mero medio de horas de actividad f√≠sica a la semana",
    legend = "Responda entre 0 y 6 horas"
  ),
  Motivation_Level = list(
    label = "¬øCu√°l es el nivel de motivaci√≥n del alumno?",
    legend = "Debe ingresar un valor entre 1 (baja motivaci√≥n) y 10 (alta motivaci√≥n)."
  ),
  Parental_Involvement = list(
    label = "¬øCu√°nto se involucran los padres en la educaci√≥n del alumno?",
    legend = "Ingrese un valor entre 1 (bajo) y 10 (alto)."
  ),
  Gender = list(
    label = "¬øCu√°l es el g√©nero del alumno?",
    legend = "Seleccione Female para femenino o Male para masculino."
  ),
  School_Type = list(
    label = "¬øA qu√© tipo de escuela asiste el alumno?",
    legend = "Seleccione Public para escuela p√∫blica o Private para escuela privada."
  )
)

# Variables que se tratar√°n como factores
factor_vars <- c("distance_category", "study_group", "high_access_to_resources", "Gender", "School_Type")

# UI - Interfaz de Usuario
ui <- fluidPage(
  titlePanel("Predicci√≥n de Nota en el Examen"),
  sidebarLayout(
    sidebarPanel(
      h4("Ingrese sus datos en formato formulario"),
      uiOutput("questionUI"),
      uiOutput("actionButtonUI")
    ),
    mainPanel(
      h3("Predicci√≥n de su Nota"),
      verbatimTextOutput("predicted_score")
    )
  )
)

# Server - L√≥gica del Dashboard
server <- function(input, output, session) {
  current_question <- reactiveVal(1)
  responses <- reactiveValues()
  final_result <- reactiveVal(NULL)

  output$questionUI <- renderUI({
    idx <- current_question()
    if (idx <= length(predictor_variables)) {
      var <- predictor_variables[idx]
      label_text <- if (!is.null(friendly_labels[[var]])) friendly_labels[[var]]$label else var
      legend_text <- if (!is.null(friendly_labels[[var]])) friendly_labels[[var]]$legend else ""
      
      input_ui <- if (var %in% factor_vars) {
        selectInput(inputId = var, label = label_text, choices = unique(df_augmented[[var]]))
      } else {
        min_val <- min(df_augmented[[var]], na.rm = TRUE)
        max_val <- max(df_augmented[[var]], na.rm = TRUE)
        mean_val <- round(mean(df_augmented[[var]], na.rm = TRUE), 2)
        sliderInput(inputId = var, label = label_text, min = min_val, max = max_val, value = mean_val)
      }
      
      tagList(
        input_ui,
        helpText(legend_text)
      )
    } else {
      h4("Ha respondido todas las preguntas.")
    }
  })

  output$actionButtonUI <- renderUI({
    idx <- current_question()
    if (idx <= length(predictor_variables)) {
      actionButton("nextOrPredict", ifelse(idx < length(predictor_variables), "Siguiente", "Predecir Nota"), class = "btn-primary")
    } else {
      actionButton("reset", "Reiniciar", class = "btn-secondary")
    }
  })

  observeEvent(input$nextOrPredict, {
    idx <- current_question()
    if (idx <= length(predictor_variables)) {
      var <- predictor_variables[idx]
      if (var %in% factor_vars) {
        responses[[var]] <- as.factor(input[[var]])
      } else {
        responses[[var]] <- as.numeric(input[[var]])
      }
      if (idx < length(predictor_variables)) {
        current_question(idx + 1)
      } else {
        input_list <- lapply(predictor_variables, function(v) { responses[[v]] })
        names(input_list) <- predictor_variables
        input_data <- as.data.frame(input_list, stringsAsFactors = FALSE)
        for (v in factor_vars) {
          if (v %in% names(input_data)) {
            input_data[[v]] <- as.factor(input_data[[v]])
          }
        }
        pred <- predict(lm_model, newdata = input_data)
        final_result(round(pred, 2))
        current_question(idx + 1)
      }
    }
  })

  observeEvent(input$reset, {
    current_question(1)
    for (v in predictor_variables) {
      responses[[v]] <- NULL
    }
    final_result(NULL)
  })

  output$predicted_score <- renderText({
    res <- final_result()
    if (!is.null(res)) {
      paste("Su nota estimada en el pr√≥ximo examen es:", res)
    } else {
      ""
    }
  })
}

shinyApp(ui = ui, server = server)
```


De esta forma, si al alumno, que har√° selectividad ese mismo a√±o, se le predice una mala calificaci√≥n, puede comenzarse a estudiar su caso m√°s a fondo y as√≠ intentar mejorarla. Adem√°s, esta herramienta permite ser usada durante todo el a√±o, permitiendo hacer un estudio, por ejemplo, cada vez que el alumno haga un nuevo examen.


## Conclusiones y Trabajo Futuro

Este estudio ha demostrado que la regresi√≥n lineal, combinada con data augmentation y feature engineering, ha sido el modelo m√°s efectivo para predecir el rendimiento acad√©mico de los estudiantes, alcanzando un R¬≤ de 0.7580. M√°s all√° del an√°lisis t√©cnico, uno de los mayores logros ha sido convertir estos modelos en una herramienta aplicable a la vida real, mediante el desarrollo de un dashboard interactivo que permite a orientadores y estudiantes obtener predicciones personalizadas y tomar decisiones informadas para mejorar el desempe√±o acad√©mico.

Sin embargo, el costo computacional limit√≥ la exploraci√≥n de modelos m√°s complejos. Como trabajo futuro, se propone utilizar infraestructura m√°s potente para evaluar t√©cnicas avanzadas y mejorar a√∫n m√°s la precisi√≥n del modelo. Adem√°s, se trabajar√° en optimizar el dashboard, haci√©ndolo m√°s profesional, intuitivo y con mejor integraci√≥n de datos en tiempo real.

En definitiva, este proyecto no solo ha demostrado la viabilidad del uso de machine learning en educaci√≥n, sino que ha dado un paso hacia su implementaci√≥n pr√°ctica, ofreciendo una herramienta √∫til con potencial para impactar positivamente en el entorno educativo.













