---
title: "Students Performance Factors"
author: "Claudia Teresa Heredia Ceballos"
---

# Students Performance Factors

**Trabajo Final Data Science**

*Master en Ingeniería del Software: Cloud, Datos y Gestión de TI*

## Descripción del dominio

### Enfoque del Trabajo

### Interés y motivación del estudio CAMBIO

### Importancia local/nacional y en el contexto actual

## Descripción del dataset

Para la resolución de esta pregunta se partirá de los datos preprocesados en 'global.rmd'.

```{r}
df_cleaned <- read.csv("data/df_cleaned.csv")
df_cleaned
```

SOLUCIÓN 1: PREDICCIÓN DE EXAM_SCORE MEDIANTE GENERACIÓN DE DATOS SINTÉTICOS

#### Análisis exploratorio de 'exam_score'

```{r}
# Cargar librerías necesarias
library(ggplot2)

# Histograma de exam_score
ggplot(df_cleaned, aes(x = Exam_Score)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Distribución de 'Exam_Score'", x = "Exam Score", y = "Frecuencia")

```

```{r}
# Calcular estadísticas descriptivas
summary(df_cleaned$Exam_Score)

# Calcular desviación estándar
sd_exam <- sd(df_cleaned$Exam_Score)
cat("Desviación estándar de exam_score:", sd_exam)

```

#### Generación de datos sintéticos para 'exam_score'

```{r}
# Calcular media y desviación estándar originales
media_exam <- mean(df_cleaned$Exam_Score)
sd_exam <- sd(df_cleaned$Exam_Score)

# Aumentar la desviación estándar para generar más variabilidad
sd_exam_aumentada <- sd_exam * 5  # Puedes ajustar el factor según necesites

# Generar datos sintéticos
set.seed(123)  # Para reproducibilidad
n_sintetico <- nrow(df_cleaned)
exam_score_sintetico <- rnorm(n_sintetico, mean = media_exam, sd = sd_exam_aumentada)

# Función para reflejar los valores fuera del rango 0-100
reflejar_valores <- function(x, min_val = 0, max_val = 100) {
  rango <- max_val - min_val
  x <- (x - min_val) %% (2 * rango)
  x <- ifelse(x > rango, 2 * rango - x, x) + min_val
  return(x)
}

# Aplicar la función a exam_score_sintetico
exam_score_sintetico_reflejado <- reflejar_valores(exam_score_sintetico)




# Verificar la nueva distribución
summary(exam_score_sintetico)
sd_exam_sintetico <- sd(exam_score_sintetico)
cat("Desviación estándar de exam_score sintético:", sd_exam_sintetico)

# Definir parámetros de la distribución Beta
a <- 2  # Puedes ajustar estos valores
b <- 5



```

```{r}
# Crear un dataframe para los datos sintéticos
df_sintetico <- df_cleaned
df_sintetico$Exam_Score <- exam_score_sintetico

# Combinar los dataframes
df_combined <- rbind(df_cleaned, df_sintetico)

# Verificar el nuevo dataframe
dim(df_combined)  # Debería tener el doble de filas que el original

```

```{r}
df_combined
```

```{r}
# Crear dataframe para los datos sintéticos
df_sintetico <- df_cleaned
df_sintetico$Exam_Score <- exam_score_sintetico

# Combinar dataframes
df_combined <- rbind(df_cleaned, df_sintetico)

# Generar histograma
ggplot(df_combined, aes(x = Exam_Score)) +
  geom_histogram(binwidth = 5, fill = "purple", color = "black") +
  theme_minimal() +
  labs(title = "Distribución de 'exam_score' Combinado", x = "Exam Score", y = "Frecuencia")

```

```{r}
# Limitar los valores al rango 0-100
exam_score_sintetico <- pmax(pmin(exam_score_sintetico, 100), 0)

# Verificar la nueva distribución
summary(exam_score_sintetico)
sd_exam_sintetico <- sd(exam_score_sintetico)
cat("Desviación estándar ajustada de exam_score sintético:", sd_exam_sintetico, "\n")

```

```{r}
# Crear dataframe para los datos sintéticos ajustados
df_sintetico <- df_cleaned
df_sintetico$Exam_Score <- exam_score_sintetico

# Combinar dataframes
df_combined <- rbind(df_cleaned, df_sintetico)

# Generar histograma
ggplot(df_combined, aes(x = Exam_Score)) +
  geom_histogram(binwidth = 5, fill = "purple", color = "black") +
  theme_minimal() +
  labs(title = "Distribución de 'exam_score' Combinado Ajustado", x = "Exam Score", y = "Frecuencia")

```

#### Feature Engineering

```{r}
# Mostrar los nombres de las columnas de df_combined
colnames(df_combined)

```

```{r}
# Crear nuevas variables en df_combined
df_combined$study_sleep_ratio <- df_combined$Hours_Studied / (df_combined$Sleep_Hours + 1)  # Evitar división por cero
df_combined$motivated_study <- df_combined$Hours_Studied * df_combined$Motivation_Level
df_combined$parent_peer_influence <- df_combined$Parental_Involvement * df_combined$Peer_Influence

# Verificar las nuevas variables
head(df_combined)
```

#### Modelo

```{r}
# Definir la variable objetivo
target_variable <- "Exam_Score"

# Obtener los nombres de todas las variables
all_variables <- names(df_combined)

# Excluir la variable objetivo y cualquier identificador
predictor_variables <- setdiff(all_variables, c(target_variable, "student_id"))

# Verificar las variables seleccionadas
print(predictor_variables)

```

Division en entrenamiento y prueba:

```{r}
# Cargar la librería necesaria
install.packages("lattice")

library(caret)
library(lattice)
# Definir la semilla para reproducibilidad
set.seed(123)

# Crear índices para dividir los datos
trainIndex <- createDataPartition(df_combined[[target_variable]], p = 0.8, list = FALSE)

# Crear los conjuntos de entrenamiento y prueba
train_data <- df_combined[trainIndex, ]
test_data <- df_combined[-trainIndex, ]

# Verificar las dimensiones
cat("Dimensiones del conjunto de entrenamiento:", dim(train_data), "\n")
cat("Dimensiones del conjunto de prueba:", dim(test_data), "\n")

```

```{r}
# Instalar las librerías si aún no las tienes
install.packages("randomForest")
install.packages("caret")
install.packages("ggplot2")

# Cargar las librerías
library(randomForest)
library(caret)
library(ggplot2)

```

Datos sin escalar:

```{r}
# Si decides usar los datos originales sin escalar
train_data_rf <- train_data
test_data_rf <- test_data

```


```{r}
# Definir la fórmula del modelo
modelo_formula <- as.formula(paste(target_variable, "~", paste(predictor_variables, collapse = " + ")))

# Configurar el control de entrenamiento
control <- trainControl(method = "cv", number = 5)  # Validación cruzada de 5 pliegues

```


entrenamiento RF

```{r}
# Entrenar el modelo Random Forest
set.seed(123)  # Para reproducibilidad
modelo_rf <- caret::train(
  form = modelo_formula,
  data = train_data_rf,
  method = "rf",
  trControl = control,
  importance = TRUE
)

```

evaluacion
```{r}
# Generar predicciones en el conjunto de prueba
predicciones_rf <- predict(modelo_rf, newdata = test_data)

# Calcular métricas de rendimiento
mae_rf <- MAE(predicciones_rf, test_data[[target_variable]])
rmse_rf <- RMSE(predicciones_rf, test_data[[target_variable]])

# Calcular R²
sst <- sum((test_data[[target_variable]] - mean(test_data[[target_variable]]))^2)
sse <- sum((test_data[[target_variable]] - predicciones_rf)^2)
r2_rf <- 1 - (sse / sst)

cat("Error Absoluto Medio (MAE):", mae_rf, "\n")
cat("Raíz del Error Cuadrático Medio (RMSE):", rmse_rf, "\n")
cat("Coeficiente de Determinación (R²):", r2_rf, "\n")

```
Predicciones vs Valores Reales
```{r}
# Crear un dataframe con los resultados
resultados_rf <- data.frame(
  Real = test_data[[target_variable]],
  Predicho = predicciones_rf
)

# Gráfico de Predicciones vs Valores Reales
ggplot(resultados_rf, aes(x = Real, y = Predicho)) +
  geom_point(color = 'darkgreen', alpha = 0.6) +
  geom_abline(intercept = 0, slope = 1, color = 'red', linetype = "dashed") +
  theme_minimal() +
  labs(title = "Random Forest: Comparación entre Valores Reales y Predicciones",
       x = "Valores Reales",
       y = "Predicciones del Modelo")

```


Distribución del Error Absoluto

```{r}
# Calcular el error absoluto
resultados_rf$Error_Absoluto <- abs(resultados_rf$Real - resultados_rf$Predicho)

# Histograma del Error Absoluto
ggplot(resultados_rf, aes(x = Error_Absoluto)) +
  geom_histogram(binwidth = 2, fill = 'skyblue', color = 'black', alpha = 0.7) +
  theme_minimal() +
  labs(title = "Random Forest: Distribución del Error Absoluto",
       x = "Error Absoluto",
       y = "Frecuencia")

```


importancia de variables:

```{r}
# Extraer la importancia de las variables
importancia <- varImp(modelo_rf, scale = FALSE)

# Visualizar la importancia
plot(importancia, main = "Importancia de las Variables en el Modelo Random Forest")

```

Regresion Lineal

```{r}
# Entrenar el modelo de regresión lineal
set.seed(123)
modelo_lm <- caret::train(
  form = modelo_formula,
  data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)

# Predicciones
predicciones_lm <- predict(modelo_lm, newdata = test_data)

# Métricas de rendimiento
mae_lm <- MAE(predicciones_lm, test_data[[target_variable]])
rmse_lm <- RMSE(predicciones_lm, test_data[[target_variable]])
r2_lm <- R2(predicciones_lm, test_data[[target_variable]])

cat("Regresión Lineal - MAE:", mae_lm, "\n")
cat("Regresión Lineal - RMSE:", rmse_lm, "\n")
cat("Regresión Lineal - R²:", r2_lm, "\n")

```
SVR
```{r}
# Entrenar el modelo SVR
set.seed(123)
modelo_svr <- caret::train(
  form = modelo_formula,
  data = train_data,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale"),
  tuneLength = 5
)

# Predicciones
predicciones_svr <- predict(modelo_svr, newdata = test_data)

# Métricas de rendimiento
mae_svr <- MAE(predicciones_svr, test_data[[target_variable]])
rmse_svr <- RMSE(predicciones_svr, test_data[[target_variable]])
r2_svr <- R2(predicciones_svr, test_data[[target_variable]])

cat("SVR - MAE:", mae_svr, "\n")
cat("SVR - RMSE:", rmse_svr, "\n")
cat("SVR - R²:", r2_svr, "\n")

```

