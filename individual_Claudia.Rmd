---
title: "Students Performance Factors"
author: "Claudia Teresa Heredia Ceballos"
---

# Students Performance Factors

**Trabajo Final Data Science**

*Master en Ingenier铆a del Software: Cloud, Datos y Gesti贸n de TI*

## Descripci贸n del dominio

El rendimiento acad茅mico es un factor clave en la educaci贸n, ya que impacta directamente en las oportunidades de los estudiantes y en el desarrollo de la sociedad. Este an谩lisis busca predecir cual ser谩 el rendimiento o las calificaciones de los estudiantes seg煤n las distintas variables que los rodean en su d铆a a d铆a. 

### Enfoque del Trabajo

### Inter茅s y motivaci贸n del estudio CAMBIO

### Importancia local/nacional y en el contexto actual

```{r}
library(magrittr)
library(dplyr)
library(tidyverse)
library(caret)
library(randomForest)
library(e1071)
library(ggplot2)

library(tidyverse)
library(caret)
library(randomForest)
library(e1071)
library(ggplot2)

library(tidyverse)
library(caret)
library(randomForest)
library(e1071)
library(ggplot2)
```





## Descripci贸n del dataset

Para la resoluci贸n de esta pregunta se partir谩 de los datos preprocesados en 'global.rmd'.

```{r}

df_cleaned <- read.csv("data/df_cleaned.csv")
df_cleaned_c <-  df_cleaned %>%
  select(-Previous_Scores_Category)
df_cleaned_c
```



#### An谩lisis exploratorio de 'exam_score'

```{r}

# Histograma de exam_score
ggplot(df_cleaned_c, aes(x = Exam_Score)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Distribuci贸n de 'Exam_Score'", x = "Exam Score", y = "Frecuencia")

```

```{r}
# Calcular estad铆sticas descriptivas
summary(df_cleaned_c$Exam_Score)

# Calcular desviaci贸n est谩ndar
sd_exam <- sd(df_cleaned_c$Exam_Score)
cat("Desviaci贸n est谩ndar de exam_score:", sd_exam)

```


## 驴Qu茅 modelo funcionar谩 mejor en la predicci贸n de exam Score?

## Primera prueba. Random Forest, SVR y Regresi贸n Lineal

###  Definir Variables Predictoras

Primero, se define la variable objetivo Exam_Score, que es la que se intenta predecir. Luego, se obtiene la lista de todas las variables en el DataFrame df_cleaned_c. Posteriormente, se excluyen Exam_Score, ya que es la variable objetivo, y student_id, puesto que es un identificador y no aporta informaci贸n predictiva. Finalmente, se imprime la lista de variables predictoras. 

```{r}
target_variable <- "Exam_Score"
all_variables <- names(df_cleaned_c)
predictor_variables <- setdiff(all_variables, c(target_variable, "student_id"))
print(predictor_variables)
```


###  Divisi贸n en Train/Test

Para la divisi贸n del conjutno primero, se usa set.seed(123) para asegurar la reproducibilidad del muestreo. Luego, createDataPartition() divide los datos en 80% de entrenamiento (train_data) y 20% de prueba (test_data), manteniendo la distribuci贸n de Exam_Score en ambas muestras.

```{r}
set.seed(123)
trainIndex <- createDataPartition(df_cleaned_c$Exam_Score, p = 0.8, list = FALSE)
train_data <- df_cleaned_c[trainIndex, ]
test_data <- df_cleaned_c[-trainIndex, ]

```



### Modelos de Machine Learning

Durante el estudio se comparar谩n 3 modelos distintos de machine learning para establecer cu谩l de ellos funciona mejor con el conjunto de datos que tenemos. 

#### Random Forest

Random Forest es 煤til porque combina m煤ltiples 谩rboles de decisi贸n, lo que mejora la precisi贸n y la capacidad de generalizaci贸n del modelo al reducir la varianza de las predicciones.

Este bloque entrena y eval煤a un modelo de Random Forest utilizando la librer铆a caret. 

* Se usa train() para entrenar el modelo y se emplea validaci贸n cruzada con 5 folds para evitar el sobreajuste y mejorar la generalizaci贸n. 

* Se habilita importance = TRUE para obtener la importancia de las variables predictoras. 

* El modelo se eval煤a haciendo predicciones en el conjunto de datos de prueba usando predict() y calculando el coeficiente de determinaci贸n 2, el cual mide qu茅 tan bien el modelo explica la variabilidad de la variable objetivo (Exam_Score). 

```{r}
set.seed(123)

rf_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "rf",
  trControl = trainControl(method = "cv", number = 5),
  importance = TRUE
)
rf_pred <- predict(rf_model, newdata = test_data)
r2_rf <- R2(rf_pred, test_data$Exam_Score)
```



##### Importancia de Variables en RF

```{r}
importance_df <- data.frame(
  Variable = rownames(importance(rf_model$finalModel)),
  Importance = importance(rf_model$finalModel)[, 1]
)
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]

# Gr谩fico
ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Importancia de las Variables en Random Forest", x = "Variable", y = "Incremento en MSE") +
  theme_minimal()
```

Como puede observarse en la gr谩fica de importancia de variables, "Attendance" y "Hours_Studied" son las m谩s influyentes con gran diferencia. 

#### Regresi贸n Lineal

La regresi贸n lineal se utiliza para modelar la relaci贸n entre una variable dependiente y una o m谩s variables independientes.


```{r}
lm_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)
lm_pred <- predict(lm_model, newdata = test_data)
r2_lm <- R2(lm_pred, test_data$Exam_Score)
```


#### SVR

Por 煤ltimo, en este apartado se entrana un modelo de Support Vector Regression. El modelo de SVR utiliza una funci贸n de n煤cleo radial (Radial Basis Function, RBF) para capturar relaciones no lineales en los datos.

En este caso tambi茅n se emplea validaci贸n cruzada con 5 folds (method = "cv", number = 5) para evitar el sobreajuste y mejorar la generalizaci贸n. Adem谩s, se preprocesan los datos centrando y escalando las variables predictoras (preProcess = c("center", "scale")) y se exploran diferentes configuraciones de hiperpar谩metros (tuneLength = 5).


```{r}

svr_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale"),
  tuneLength = 5
)
svr_pred <- predict(svr_model, newdata = test_data)
r2_svr <- R2(svr_pred, test_data$Exam_Score)
```


### Comparaci贸n de Modelos

```{r}
results_no_cluster_no_fe <- data.frame(Modelo = c("Random Forest", "Regresi贸n Lineal", "SVR"),
                              R2 = c(r2_rf, r2_lm, r2_svr))
print(results_no_cluster_no_fe)

```
La Regresi贸n Lineal obtuvo el mejor desempe帽o con un2 de 0.7299, superando a SVR y Random Forest.
SVR tambi茅n mostr贸 un rendimiento similar a la regresi贸n lineal, con un 2 de 0.7256.
Random Forest tuvo el peor desempe帽o (0.6523), lo que sugiere que el modelo no pudo captar bien la estructura de los datos en su forma actual.



Durante todo el an谩lisis (tanto grupal como individual), se ha demostrado que los la estructura de los datos dificultan en gran medida el funcionamiento de los modelos predictivos. Por ello, sirge la siguiente pregunta:


## 驴Podr铆an mejorar los modelos si se alteran los datos?

## Primera prueba. Comparaci贸n de Modelos aplicando Feature Engineering.:

```{r}

df_cleaned <- read.csv("data/df_cleaned.csv")

df_cleaned_c <- df_cleaned %>%
  select(-Previous_Scores_Category)  # Eliminamos una variable no utilizada
```


### Feature Engineering

Se crean nuevas variables derivadas de combinaciones l贸gicas de las existentes para mejorar la capacidad predictiva de los modelos.

* 'study_sleep_ratio': Relaci贸n entre horas de estudio y horas de sue帽o. Se introduce para medir el equilibrio entre descanso y preparaci贸n acad茅mica.

* 'motivated_study': Producto de horas de estudio y nivel de motivaci贸n. Representa el impacto de la motivaci贸n en el esfuerzo acad茅mico.

* 'parent_peer_influence': Combinaci贸n del involucramiento parental y la influencia de los pares. Se usa para medir el impacto del entorno social.

* 'distance_category': Agrupa la distancia a la escuela en tres categor铆as: Cerca, Media y Lejos.

* 'study_group': Clasifica las horas de estudio en tres categor铆as: Bajo, Medio y Alto.

* 'high_access_to_resources': Variable binaria que indica si el estudiante tiene acceso a recursos por encima de la media.

* 'social_influence': Suma de la influencia de pares, el involucramiento parental y la calidad del maestro, escalada para facilitar la comparaci贸n.

```{r}

df_cleaned_c <- df_cleaned_c %>% mutate(
  study_sleep_ratio = scale(Hours_Studied / (Sleep_Hours + 1)),
  motivated_study = scale(Hours_Studied * Motivation_Level),
  parent_peer_influence = scale(Parental_Involvement * Peer_Influence),
  distance_category = case_when(
    Distance_from_Home < quantile(Distance_from_Home, 0.33) ~ "Cerca",
    Distance_from_Home < quantile(Distance_from_Home, 0.66) ~ "Media",
    TRUE ~ "Lejos"
  ),
  study_group = case_when(
    Hours_Studied < quantile(Hours_Studied, 0.33) ~ "Bajo",
    Hours_Studied < quantile(Hours_Studied, 0.66) ~ "Medio",
    TRUE ~ "Alto"
  ),
  high_access_to_resources = ifelse(Access_to_Resources > mean(Access_to_Resources, na.rm = TRUE), 1, 0),
  social_influence = scale(Peer_Influence + Parental_Involvement + Teacher_Quality)
)

# Convertir variables categ贸ricas a factores
df_cleaned_c$distance_category <- as.factor(df_cleaned_c$distance_category)
df_cleaned_c$study_group <- as.factor(df_cleaned_c$study_group)


```


### Divisi贸n en Train Test

```{r}

set.seed(123)
trainIndex <- createDataPartition(df_cleaned_c$Exam_Score, p = 0.8, list = FALSE)
train_data <- df_cleaned_c[trainIndex, ]
test_data <- df_cleaned_c[-trainIndex, ]
```


### Entrenamiento de Modelos: Randon Forest vs SVR vs Regresi贸n Lineal:

```{r}

set.seed(123)

#  Random Forest
rf_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "rf",
  trControl = trainControl(method = "cv", number = 5),
  importance = TRUE
)
rf_pred <- predict(rf_model, newdata = test_data)
r2_rf <- R2(rf_pred, test_data$Exam_Score)


# Importancia de Variables en RF

importance_df <- data.frame(
  Variable = rownames(importance(rf_model$finalModel)),
  Importance = importance(rf_model$finalModel)[, 1]
)
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]

# Gr谩fico
ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Importancia de las Variables en Random Forest", x = "Variable", y = "Incremento en MSE") +
  theme_minimal()
#  Regresi贸n Lineal
lm_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)
lm_pred <- predict(lm_model, newdata = test_data)
r2_lm <- R2(lm_pred, test_data$Exam_Score)

#  SVR
svr_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale"),
  tuneLength = 5
)
svr_pred <- predict(svr_model, newdata = test_data)
r2_svr <- R2(svr_pred, test_data$Exam_Score)
```
La importancia de variables se mantiene similar, pero ahora aparecen algunas nuevas transformaciones de variables como "motivated_study" y "social_influence, que ya no se muestran tan alejadas de la importandia de Hours_Studied, aunque s铆 de la asistencia a clase. 

### Comparaci贸n de Modelos: 

```{r}

results_no_cluster <- data.frame(Modelo = c("Random Forest", "Regresi贸n Lineal", "SVR"),
                                 R2 = c(r2_rf, r2_lm, r2_svr))
print(results_no_cluster)



```
Los resultados son muy similares a la prueba anterior, lo que indica que el Feature Engineering no tuvo un impacto significativo en el rendimiento de los modelos.

Random Forest sigue con el peor desempe帽o (0.6473), e incluso mostr贸 una leve disminuci贸n en comparaci贸n con la prueba anterior.

La Regresi贸n Lineal y SVR no experimentaron cambios significativos.



## Segunda prueba. Comparaci贸n de Modelos con Data Augmentation y Feature Engineering.


En esta secci贸n, se eval煤a cu谩l modelo de machine learning predice mejor el 'Exam_Score' tras aplicar t茅cnicas de 'data augmentation' con ruido controlado y 'feature engineering'. El objetivo es verificar si estas mejoras incrementan la capacidad predictiva de los modelos previamente utilizados: Random Forest, Regresi贸n Lineal y Support Vector Regression (SVR).

Cargamos nuevamente los datos (eliminando la variable que no nos sirve):

```{r}
df_cleaned <- read.csv("data/df_cleaned.csv")

df_cleaned_c <- df_cleaned %>%
  select(-Previous_Scores_Category)  # Eliminamos una variable no utilizada
```


### Data Augmentation con Ruido Controlado

Para mejorar la variabilidad de los datos sin alterar significativamente la informaci贸n original, se introduce ruido controlado en la variable objetivo Exam_Score. Se genera una perturbaci贸n normal con media 0 y desviaci贸n est谩ndar del 10% de la desviaci贸n est谩ndar original. Adem谩s, los valores se limitan al rango [50, 100] para mantener la coherencia de los datos.

```{r}

set.seed(123)
df_augmented <- df_cleaned_c %>% mutate(
  Exam_Score = Exam_Score + rnorm(n(), mean = 0, sd = sd(df_cleaned_c$Exam_Score) * 0.1)  # Ruido moderado
)

# Limitar valores a 50-100
df_augmented$Exam_Score <- pmax(pmin(df_augmented$Exam_Score, 100), 50)

# Imprimir desviaci贸n est谩ndar despu茅s de Data Augmentation
cat("Desviaci贸n est谩ndar de Exam_Score despu茅s de Data Augmentation:", sd(df_augmented$Exam_Score), "\n")
```


### Feauture Engineering

En este apartado se mantienen las nuevas variables que se crearon durante la primera prueba. 

```{r}

df_augmented <- df_augmented %>% mutate(
  study_sleep_ratio = scale(Hours_Studied / (Sleep_Hours + 1)),
  motivated_study = scale(Hours_Studied * Motivation_Level),
  parent_peer_influence = scale(Parental_Involvement * Peer_Influence),
  distance_category = case_when(
    Distance_from_Home < quantile(Distance_from_Home, 0.33) ~ "Cerca",
    Distance_from_Home < quantile(Distance_from_Home, 0.66) ~ "Media",
    TRUE ~ "Lejos"
  ),
  study_group = case_when(
    Hours_Studied < quantile(Hours_Studied, 0.33) ~ "Bajo",
    Hours_Studied < quantile(Hours_Studied, 0.66) ~ "Medio",
    TRUE ~ "Alto"
  ),
  high_access_to_resources = ifelse(Access_to_Resources > mean(Access_to_Resources, na.rm = TRUE), 1, 0),
  social_influence = scale(Peer_Influence + Parental_Involvement + Teacher_Quality)
)

# Convertir variables categ贸ricas a factores
df_augmented$distance_category <- as.factor(df_augmented$distance_category)
df_augmented$study_group <- as.factor(df_augmented$study_group)
```


### Definici贸n de Variables Predictoras

```{r}

target_variable <- "Exam_Score"
all_variables <- names(df_augmented)
predictor_variables <- setdiff(all_variables, c(target_variable, "student_id"))
print(predictor_variables)
```

###  Divisi贸n en Train/Test

```{r}

set.seed(123)
trainIndex <- createDataPartition(df_augmented$Exam_Score, p = 0.8, list = FALSE)
train_data <- df_augmented[trainIndex, ]
test_data <- df_augmented[-trainIndex, ]
```


### Entrenamiento y Validaci贸n de los modelos:

```{r}

set.seed(123)

# Random Forest
rf_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "rf",
  trControl = trainControl(method = "cv", number = 5),
  importance = TRUE
)
rf_pred <- predict(rf_model, newdata = test_data)
r2_rf <- R2(rf_pred, test_data$Exam_Score)


importance_df <- data.frame(
  Variable = rownames(importance(rf_model$finalModel)),
  Importance = importance(rf_model$finalModel)[, 1]
)
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]

# Gr谩fico
ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Importancia de las Variables en Random Forest", x = "Variable", y = "Incremento en MSE") +
  theme_minimal()


# Regresi贸n Lineal
lm_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)
lm_pred <- predict(lm_model, newdata = test_data)
r2_lm <- R2(lm_pred, test_data$Exam_Score)

# SVR
svr_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale"),
  tuneLength = 5
)
svr_pred <- predict(svr_model, newdata = test_data)
r2_svr <- R2(svr_pred, test_data$Exam_Score)

```


### Comparaci贸n de los Modelos:

```{r}

results_data_augmentation <- data.frame(Modelo = c("Random Forest", "Regresi贸n Lineal", "SVR"),
                                        R2 = c(r2_rf, r2_lm, r2_svr))
print(results_data_augmentation)
```
Aqu铆 se observ贸 una mejora en todos los modelos despu茅s de aplicar Data Augmentation.

Regresi贸n Lineal sigue siendo el mejor modelo, alcanzando un 2 de 0.7504.

SVR tambi茅n mejor贸, con un 2 de 0.7452.

Random Forest experiment贸 la mayor mejora, aumentando su2 de 0.6473 a 0.6853, lo que sugiere que el Data Augmentation ayud贸 a reducir la variabilidad y mejorar el aprendizaje del modelo.

Agregar datos sint茅ticos con ruido moderado ayud贸 a mejorar la generalizaci贸n de los modelos.



## Tercera prueba. Comparaci贸n de Modelos con Interpolaci贸n y Feature Engineering.

En esta secci贸n, se eval煤a cu谩l modelo de machine learning predice mejor el Exam_Score tras aplicar interpolaci贸n en lugar de data augmentation con ruido controlado y manteniendo el feature engineering. La interpolaci贸n permite generar datos intermedios basados en los valores existentes, lo que puede reducir el sesgo en los modelos y mejorar la calidad del entrenamiento.


```{r}
df_cleaned <- read.csv("data/df_cleaned.csv")

df_cleaned_c <- df_cleaned %>%
  select(-Previous_Scores_Category)  # Eliminamos una variable no utilizada
```


###  Interpolaci贸n y generaci贸n de nuevos datos.

En lugar de a帽adir ruido aleatorio, utilizamos interpolaci贸n para generar valores intermedios a partir de la distribuci贸n existente de Exam_Score. La interpolaci贸n ayuda a mejorar la representatividad de los datos sin distorsionar demasiado la informaci贸n original.

En lugar de a帽adir ruido aleatorio, utilizamos interpolaci贸n para generar valores intermedios a partir de la distribuci贸n existente de Exam_Score. La interpolaci贸n consiste en estimar valores dentro del rango de los datos originales para simular una distribuci贸n m谩s continua y mejorar la representatividad de los datos.

Para lograrlo, se han realizado los siguientes pasos:

1. Generaci贸n de puntos intermedios: Se crean valores dentro del rango m铆nimo y m谩ximo de Exam_Score, asegurando una mayor densidad de datos en la distribuci贸n original.

2. Aleatorizaci贸n: Se seleccionan valores interpolados de forma aleatoria para evitar patrones artificiales.

3. Ajuste de la distribuci贸n: Se introduce un peque帽o ruido proporcional para reflejar la variabilidad natural de los datos.

4. Limitaci贸n de valores: Se restringen los valores interpolados al rango v谩lido de Exam_Score [55, 100].

```{r}

expandir_datos <- function(df) {
  n <- nrow(df)
  
  if (n < 2) return(df)  # Evitar problemas en conjuntos peque帽os
  
  # Generar nuevos valores interpolados
  nuevos_puntos <- seq(min(df$Exam_Score), max(df$Exam_Score), length.out = n * 2)
  nuevos_puntos <- sample(nuevos_puntos, size = n, replace = TRUE)  # Aleatorizar selecci贸n
  df$Exam_Score <- nuevos_puntos
  return(df)
}

# Aplicar interpolaci贸n
df_interpolado <- expandir_datos(df_cleaned_c)

# A帽adir ruido proporcional a la dispersi贸n
df_interpolado <- df_interpolado %>% mutate(
  Exam_Score = Exam_Score + rnorm(n(), mean = 0, sd = sd(df_interpolado$Exam_Score) * 0.5)
)

# Limitar valores a 50-100
df_interpolado$Exam_Score <- pmax(pmin(df_interpolado$Exam_Score, 100), 50)

# Imprimir desviaci贸n est谩ndar despu茅s de Interpolaci贸n
cat("Desviaci贸n est谩ndar de Exam_Score despu茅s de Interpolaci贸n:", sd(df_interpolado$Exam_Score), "\n")

```


###  Feature Engineering

Durante esta prueba se mantienen las transformaciones anteriores para mejorar la capacidad predictiva de los modelos.

```{r}

df_interpolado <- df_interpolado %>% mutate(
  study_sleep_ratio = scale(Hours_Studied / (Sleep_Hours + 1)),
  motivated_study = scale(Hours_Studied * Motivation_Level),
  parent_peer_influence = scale(Parental_Involvement * Peer_Influence),
  distance_category = case_when(
    Distance_from_Home < quantile(Distance_from_Home, 0.33) ~ "Cerca",
    Distance_from_Home < quantile(Distance_from_Home, 0.66) ~ "Media",
    TRUE ~ "Lejos"
  ),
  study_group = case_when(
    Hours_Studied < quantile(Hours_Studied, 0.33) ~ "Bajo",
    Hours_Studied < quantile(Hours_Studied, 0.66) ~ "Medio",
    TRUE ~ "Alto"
  ),
  high_access_to_resources = ifelse(Access_to_Resources > mean(Access_to_Resources, na.rm = TRUE), 1, 0),
  social_influence = scale(Peer_Influence + Parental_Involvement + Teacher_Quality)
)

# Convertir variables categ贸ricas a factores
df_interpolado$distance_category <- as.factor(df_interpolado$distance_category)
df_interpolado$study_group <- as.factor(df_interpolado$study_group)

```


### Definici贸n de Variables Predictoras y Divisi贸n del conjunto:
```{r}

target_variable <- "Exam_Score"
all_variables <- names(df_interpolado)
predictor_variables <- setdiff(all_variables, c(target_variable, "student_id"))
print(predictor_variables)


# Train/Test

set.seed(123)
trainIndex <- createDataPartition(df_interpolado$Exam_Score, p = 0.8, list = FALSE)
train_data <- df_interpolado[trainIndex, ]
test_data <- df_interpolado[-trainIndex, ]
```


### Entrenamiento y Validaci贸n de Modelos:

En este apartado se vuelven a entrenar los mismos modelos: Random Forest, SVR y Regresi贸n Lineal.

```{r}

set.seed(123)

# Random Forest
rf_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "rf",
  trControl = trainControl(method = "cv", number = 5),
  importance = TRUE
)
rf_pred <- predict(rf_model, newdata = test_data)
r2_rf <- R2(rf_pred, test_data$Exam_Score)

#  Importancia de Variables en RF

importance_df <- data.frame(
  Variable = rownames(importance(rf_model$finalModel)),
  Importance = importance(rf_model$finalModel)[, 1]
)
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]

# Gr谩fico
ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Importancia de las Variables en Random Forest", x = "Variable", y = "Incremento en MSE") +
  theme_minimal()

# Regresi贸n Lineal
lm_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)
lm_pred <- predict(lm_model, newdata = test_data)
r2_lm <- R2(lm_pred, test_data$Exam_Score)

#  SVR
svr_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "svmRadial",
  trControl = trainControl(method = "cv", number = 5),
  preProcess = c("center", "scale"),
  tuneLength = 5
)
svr_pred <- predict(svr_model, newdata = test_data)
r2_svr <- R2(svr_pred, test_data$Exam_Score)
```



### Comparaci贸n de Modelos:
```{r}

results_interpolation <- data.frame(Modelo = c("Random Forest", "Regresi贸n Lineal", "SVR"),
                                    R2 = c(r2_rf, r2_lm, r2_svr))
print(results_interpolation)

```

Los resultados se desplomaron dr谩sticamente.
Todos los modelos obtuvieron un 2 cercano a 0, lo que indica que no lograron captar ninguna relaci贸n entre las variables y el Exam_Score.

La interpolaci贸n alter贸 demasiado la estructura de los datos, haciendo que los modelos pierdan completamente su capacidad predictiva.

La desviaci贸n est谩ndar de Exam_Score se dispar贸 de 3.93 a 14.10, lo que sugiere que los valores interpolados introdujeron demasiada variabilidad artificial.
Con ello podemos concluir que la interpolaci贸n no fue una buena estrategia para este conjunto de datos, de hecho, ha sido la prueba con peores resultados. 


### Tabla Comparativa y Conclusi贸n Final:

# Comparaci贸n Final de Modelos

| Prueba                                        | Random Forest | Regresi贸n Lineal | SVR  |
|-----------------------------------------------|--------------|-----------------|------|
| Primera Prueba                                | 0.6523       | **0.7299**      | 0.7256 |
| Feature Engineering                           | 0.6473       | **0.7292**      | 0.7259 |
| Data Augmentation + Feature Engineering       | 0.6853       | **0.7504**      | 0.7452 |
| Interpolaci贸n + Feature Engineering           | 0.0001       | **0.0005**      | 0.0002 |


Como puede observarse en la tabla y despu茅s de las distintas pruebas, la mejor estrategia fue aplicar Data Augmentation junto con Feature Engineering. La interpolaci贸n, en cambio, fue una estrategia fallida. La Regresi贸n Lineal fue el mejor modelo en general.


## 驴C贸mo podr铆amos aplicar estos resultados a la vida real?



```{r}
library(shiny)
library(tidyverse)
library(caret)
library(ggplot2)
library(plotly)

# -------------------------------
# 1锔 Cargar los datos
# -------------------------------
df_cleaned <- read.csv("data/df_cleaned.csv")

df_cleaned_c <- df_cleaned %>%
  select(-Previous_Scores_Category)

# -------------------------------
# 2锔 Data Augmentation con Ruido Controlado
# -------------------------------
set.seed(123)
df_augmented <- df_cleaned_c %>% mutate(
  Exam_Score = Exam_Score + rnorm(n(), mean = 0, sd = sd(df_cleaned_c$Exam_Score) * 0.1)
)

# Limitar valores a 55-100
df_augmented$Exam_Score <- pmax(pmin(df_augmented$Exam_Score, 100), 55)

# Imprimir desviaci贸n est谩ndar despu茅s de agregar ruido
cat("Desviaci贸n est谩ndar despu茅s de agregar ruido:", sd(df_augmented$Exam_Score), "\n")

# -------------------------------
# 3锔 Feature Engineering
# -------------------------------
df_augmented <- df_augmented %>% mutate(
  study_sleep_ratio = as.numeric(scale(Hours_Studied / (Sleep_Hours + 1))),
  motivated_study = as.numeric(scale(Hours_Studied * Motivation_Level)),
  parent_peer_influence = as.numeric(scale(Parental_Involvement * Peer_Influence)),
  distance_category = as.factor(case_when(
    Distance_from_Home < quantile(Distance_from_Home, 0.33) ~ "Cerca",
    Distance_from_Home < quantile(Distance_from_Home, 0.66) ~ "Media",
    TRUE ~ "Lejos"
  )),
  study_group = as.factor(case_when(
    Hours_Studied < quantile(Hours_Studied, 0.33) ~ "Bajo",
    Hours_Studied < quantile(Hours_Studied, 0.66) ~ "Medio",
    TRUE ~ "Alto"
  )),
  high_access_to_resources = as.factor(ifelse(Access_to_Resources > mean(Access_to_Resources, na.rm = TRUE), 1, 0)),
  social_influence = as.numeric(scale(Peer_Influence + Parental_Involvement + Teacher_Quality))
)

# -------------------------------
# 4锔 Definir Variables Predictoras
# -------------------------------
target_variable <- "Exam_Score"
all_variables <- names(df_augmented)
predictor_variables <- setdiff(all_variables, c(target_variable, "student_id"))
print(predictor_variables)

# -------------------------------
# 5锔 Divisi贸n en Train/Test
# -------------------------------
set.seed(123)
trainIndex <- createDataPartition(df_augmented$Exam_Score, p = 0.8, list = FALSE)
train_data <- df_augmented[trainIndex, ]
test_data <- df_augmented[-trainIndex, ]

# -------------------------------
# 6锔 Modelo de Regresi贸n Lineal
# -------------------------------
set.seed(123)
lm_model <- train(
  Exam_Score ~ ., data = train_data,
  method = "lm",
  trControl = trainControl(method = "cv", number = 5)
)

lm_pred <- predict(lm_model, newdata = test_data)
r2_lm <- R2(lm_pred, test_data$Exam_Score)

# Guardar el modelo de Regresi贸n Lineal
save(lm_model, file = "best_model_lm.RData")





```


```{r}
# -------------------------------
# 7锔 Dashboard en Shiny
# -------------------------------
load("best_model_lm.RData")

# UI - Interfaz de Usuario
iu <- fluidPage(
  titlePanel("Predicci贸n de Nota en el Examen"),
  sidebarLayout(
    sidebarPanel(
      h4("Ingrese sus datos para predecir su nota"),
      lapply(predictor_variables, function(var) {
        if (var %in% c("distance_category", "study_group", "high_access_to_resources")) {
          selectInput(var, var, choices = unique(df_augmented[[var]]))
        } else {
          sliderInput(var, var, min = min(df_augmented[[var]], na.rm = TRUE), max = max(df_augmented[[var]], na.rm = TRUE), value = mean(df_augmented[[var]], na.rm = TRUE))
        }
      }),
      actionButton("predict", "Predecir Nota", class = "btn-primary")
    ),
    mainPanel(
      h3("Predicci贸n de su Nota"),
      verbatimTextOutput("predicted_score")
    )
  )
)

# Server - L贸gica del Dashboard
server <- function(input, output) {
  predicted_score <- eventReactive(input$predict, {
    input_data <- data.frame(
      lapply(predictor_variables, function(var) {
        if (var %in% c("distance_category", "study_group", "high_access_to_resources")) {
          as.factor(input[[var]])
        } else {
          as.numeric(input[[var]])
        }
      })
    )
    colnames(input_data) <- predictor_variables
    print(input_data)
    predict(lm_model, newdata = input_data)
  })
  
  output$predicted_score <- renderText({
    paste("Su nota estimada en el pr贸ximo examen es:", round(predicted_score(), 2))
  })
}

shinyApp(ui = iu, server = server)
```




